Formal Verification of Safety Properties for Ownership Authentication Transfer Protocol
In ubiquitous computing devices , users tend to store some valuable information in their device . Even though the device can be borrowed by the other user temporarily , it is not safe for any user to borrow or lend the device as it may cause private data of the user to be public . To safeguard the user data and also to preserve user privacy we propose and model the technique of ownership authentication transfer . The user who is willing to sell the device has to transfer the ownership of the device under sale . Once the device is sold and the ownership has been transferred , the old owner will not be able to use that device at any cost . Either of the users will not be able to use the device if the process of ownership has not been carried out properly . This also takes care of the scenario when the device has been stolen or lost , avoiding the impersonation attack . The aim of this paper is to model basic process of proposed ownership authentication transfer protocol and check its safety properties by representing it using CSP and model checking approach . For model checking we have used a symbolic model checker tool called NuSMV . The safety properties of ownership transfer protocol has been modeled in terms of CTL specification and it is observed that the system satisfies all the protocol constraint and is safe to be deployed .
Expressive Completeness of Metric Temporal Logic
Metric Temporal Logic ( MTL ) is a generalisation of Linear Temporal Logic in which the Until and Since modalities are annotated with intervals that express metric constraints . A seminal result of Hirshfeld and Rabinovich shows that over the reals , first - order logic with binary order relation < and unary function + 1 is strictly more expressive than MTL with integer constants . Indeed they prove that no temporal logic whose modalities are definable by formulas of bounded quantifier depth can be expressively complete for FO(<,+1 ) . In this paper we show the surprising result that if we allow unary functions + q , ( q rational ) , in first - order logic and correspondingly allow rational constants in MTL , then the two logics have the same expressive power . This gives the first generalisation of Kamp 's theorem on the expressive completeness of LTL for FO ( < ) to the quantitative setting . The proof of this result involves a generalisation of Gabbay 's notion of separation .
On Reducing Linearizability to State Reachability
Efficient implementations of atomic objects such as concurrent stacks and queues are especially susceptible to programming errors , and necessitate automatic verification . Unfortunately their correctness criteria - linearizability with respect to given ADT specifications - are hard to verify . Even on classes of implementations where the usual temporal safety properties like control - state reachability are decidable , linearizability is undecidable . In this work we demonstrate that verifying linearizability for certain fixed ADT specifications is reducible to control - state reachability , despite being harder for arbitrary ADTs . We effectuate this reduction for several of the most popular atomic objects . This reduction yields the first decidability results for verification without bounding the number of concurrent threads . Furthermore , it enables the application of existing safety - verification tools to linearizability verification .
Distributed Diagnosability Analysis with Petri Nets
We propose a framework to distributed diagnos- ability analysis of concurrent systems modeled with Petri nets as a collection of components synchronizing on common observable transitions , where faults can occur in several components . The diagnosability analysis of the entire system is done in parallel by verifying the interaction of each component with the fault free versions of the other components . Furthermore , we use existing efficient methods and tools , in particular parallel LTL - X model checking based on unfoldings , for diagnosability verification .
A finite basis theorem for the description logic $ { \cal ALC}$
The main result of this paper is to prove the existence of a finite basis in the description logic $ { \cal ALC}$. We show that the set of General Concept Inclusions ( GCIs ) holding in a finite model has always a finite basis , i.e. these GCIs can be derived from finitely many of the GCIs . This result extends a previous result from Baader and Distel , which showed the existence of a finite basis for GCIs holding in a finite model but for the inexpressive description logics $ { \cal EL}$ and $ { \cal EL}_{gfp}$. We also provide an algorithm for computing this finite basis , and prove its correctness . As a byproduct , we extend our finite basis theorem to any finitely generated complete covariety ( i.e. any class of models closed under morphism domain , coproduct and quotient , and generated from a finite set of finite models ) .
On stratified regions
Type and effect systems are a tool to analyse statically the behaviour of programs with effects . We present a proof based on the so called reducibility candidates that a suitable stratification of the type and effect system entails the termination of the typable programs . The proof technique covers a simply typed , multi - threaded , call - by - value lambda - calculus , equipped with a variety of scheduling ( preemptive , cooperative ) and interaction mechanisms ( references , channels , signals ) .
On FO2 quantifier alternation over words
We show that each level of the quantifier alternation hierarchy within FO^2 [ < ] -- the 2-variable fragment of the first order logic of order on words -- is a variety of languages . We then use the notion of condensed rankers , a refinement of the rankers defined by Weis and Immerman , to produce a decidable hierarchy of varieties which is interwoven with the quantifier alternation hierarchy -- and conjecturally equal to it . It follows that the latter hierarchy is decidable within one unit : given a formula alpha in FO^2 [ < ] , one can effectively compute an integer m such that alpha is equivalent to a formula with at most m+1 alternating blocks of quantifiers , but not to a formula with only m-1 blocks . This is a much more precise result than what is known about the quantifier alternation hierarchy within FO [ < ] , where no decidability result is known beyond the very first levels .
Inconsistency Robustness in Logic Programs
Inconsistency robustness is " information system performance in the face of continually pervasive inconsistencies . " A fundamental principle of Inconsistency Robustness is to make contradictions explicit so that arguments for and against propositions can be formalized . This paper explores the role of Inconsistency Robustness in the history and theory of Logic Programs . Robert Kowalski put forward a bold thesis : " Looking back on our early discoveries , I value most the discovery that computation could be subsumed by deduction . " However , mathematical logic can not always infer computational steps because computational systems make use of arbitration for determining which message is processed next by a recipient that is sent multiple messages concurrently . Since reception orders are in general indeterminate , they can not be inferred from prior information by mathematical logic alone . Therefore mathematical logic can not in general implement computation . Over the course of history , the term " Functional Program " has grown more precise and technical as the field has matured . " Logic Program " should be on a similar trajectory . Accordingly , " Logic Program " should have a general precise characterization . In the fall of 1972 , different characterizations of Logic Programs that have continued to this day : * A Logic Program uses Horn - Clause syntax for forward and backward chaining * Each computational step ( according to Actor Model ) of a Logic Program is deductively inferred ( e.g. in Direct Logic ) . The above examples are illustrative of how issues of inconsistency robustness have repeatedly arisen in Logic Programs .
A Constructive Epistemic Logic with Public Announcement ( Non - Predetermined Possibilities )
We argue that the notion of epistemic \emph{possible worlds } in constructivism ( intuitionism ) is not as the same as it is in classic view , and there are possibilities , called non - predetermined worlds , which are ignored in ( classic ) Epistemic Logic . Regarding non - predetermined possibilities , we propose a constructive epistemic logic and prove soundness and completeness theorems for it . We extend the proposed logic by adding a public announcement operator . To declare the significance of our work , we formulate the well - known Surprise Exam Paradox , $ \mathbf{SEP}$ , via the proposed constructive epistemic logic and then put forward a solution for the paradox . We clarify that the puzzle in the $ \mathbf{SEP}$ is because of students'(wrong ) assumption that the day of the exam is necessarily predetermined .
Monadic Datalog Containment on Trees Using the Descendant - Axis
In their AMW14-paper , Frochaux , Grohe , and Schweikardt showed that the query containment problem for monadic datalog on finite unranked labeled trees is Exptime - complete when ( a ) considering unordered trees using the child - axis , and when ( b ) considering ordered trees using the axes firstchild , nextsibling , and child . Furthermore , when allowing to use also the descendant - axis , the query containment problem was shown to be solvable in 2-fold exponential time , but it remained open to determine the problems exact complexity in presence of the descendant - axis . The present paper closes this gap by showing that , in the presence of the descendant - axis , the problem is 2Exptime - hard .
Completeness for a First - order Abstract Separation Logic
Existing work on theorem proving for the assertion language of separation logic ( SL ) either focuses on abstract semantics which are not readily available in most applications of program verification , or on concrete models for which completeness is not possible . An important element in concrete SL is the points - to predicate which denotes a singleton heap . SL with the points - to predicate has been shown to be non - recursively enumerable . In this paper , we develop a first - order SL , called FOASL , with an abstracted version of the points - to predicate . We prove that FOASL is sound and complete with respect to an abstract semantics , of which the standard SL semantics is an instance . We also show that some reasoning principles involving the points - to predicate can be approximated as FOASL theories , thus allowing our logic to be used for reasoning about concrete program verification problems . We give some example theories that are sound with respect to different variants of separation logics from the literature , including those that are incompatible with Reynolds 's semantics . In the experiment we demonstrate our FOASL based theorem prover which is able to handle a large fragment of separation logic with heap semantics as well as non - standard semantics .
Formalization of Fault Trees in Higher - order Logic : A Deep Embedding Approach
Fault Tree ( FT ) is a standard failure modeling technique that has been extensively used to predict reliability , availability and safety of many complex engineering systems . In order to facilitate the formal analysis of FT based analyses , a higher - order - logic formalization of FTs has been recently proposed . However , this formalization is quite limited in terms of handling large systems and transformation of FT models into their corresponding Reliability Block Diagram ( RBD ) structures , i.e. , a frequently used transformation in reliability and availability analyses . In order to overcome these limitations , we present a deep embedding based formalization of FTs . In particular , the paper presents a formalization of AND , OR and NOT FT gates , which are in turn used to formalize other commonly used FT gates , i.e. , NAND , NOR , XOR , Inhibit , Comparator and majority Voting , and the formal verification of their failure probability expressions . For illustration purposes , we present a formal failure analysis of a communication gateway software for the next generation air traffic management system .
Efficient Description Logic Reasoning in Prolog : The DLog system
This paper describes a resolution based Description Logic reasoning system called DLog . DLog transforms Description Logic axioms into a Prolog program and uses the standard Prolog execution for efficiently answering instance retrieval queries . From the Description Logic point of view , DLog is an ABox reasoning engine for the full SHIQ language . The DLog approach makes it possible to store the individuals in a database instead of memory , which results in better scalability and helps using description logic ontologies directly on top of existing information sources . To appear in Theory and Practice of Logic Programming ( TPLP ) .
Random generation of closed simply - typed $ l$-terms : a synergy between logic programming and Boltzmann samplers
A natural approach to software quality assurance consists in writing unit tests securing programmer - declared code invariants . Throughout the literature a great body of work has been devoted to tools and techniques automating this labour - intensive process . A prominent example is the successful use of randomness , in particular random typeable $ \lambda$-terms , in testing functional programming compilers such as the Glasgow Haskell Compiler . Unfortunately , due to the intrinsically difficult combinatorial structure of typeable $ \lambda$-terms no effective uniform sampling method is known , setting it as a fundamental open problem in the random software testing approach . In this paper we combine the framework of Boltzmann samplers , a powerful technique of random combinatorial structure generation , with today 's Prolog systems offering a synergy between logic variables , unification with occurs check and efficient backtracking . This allows us to develop a novel sampling mechanism able to construct uniformly random closed simply - typed $ \lambda$-terms of up size 120 . We apply our techniques to the generation of uniformly random closed simply - typed normal forms and design a parallel execution mechanism pushing forward the achievable term size to 140 .
A Coalgebraic Approach to Quantitative Linear Time Logics
We define quantitative fixpoint logics for reasoning about linear time properties of states in systems with branching behaviour . We model such systems as coalgebras whose type arises as the composition of a branching monad with one or more polynomial endofunctors on the category of sets . The domain of truth values for our logics is determined by the choice of branching monad , as is the special modality used to abstract away branching in the semantics of the logics . To justify our choice of syntax and semantics for the logics , we prove the equivalence between their step - wise semantics and an alternative path - based semantics for the fixpoint - free fragments of the logics . Instances of these logics support reasoning about the possibility , probability or minimal cost of exhibiting a given linear time property . We conclude with two examples of logics that have a linear time flavour but do not admit a path - based semantics , namely a logic for reasoning about resource usage in infinitely - running computations , and a quantitative logic for reasoning about component interaction .
The expressiveness of MTL with counting
It is well known that MTL with integer endpoints is unable to express all of monadic first - order logic of order and metric ( FO(<,+1 ) ) . Indeed , MTL is unable to express the counting modalities $ C_n$ that assert a properties holds $ n$ times in the next time interval . We show that MTL with the counting modalities , MTL+C , is expressively complete for FO(<,+1 ) . This result strongly supports the assertion of Hirshfeld and Rabinovich that Q2MLO is the most expressive decidable fragments of FO(<,+1 ) .
When is Metric Temporal Logic Expressively Complete ?
A seminal result of Kamp is that over the reals Linear Temporal Logic ( LTL ) has the same expressive power as first - order logic with binary order relation < and monadic predicates . A key question is whether there exists an analogue of Kamp 's theorem for Metric Temporal Logic ( MTL ) -- a generalization of LTL in which the Until and Since modalities are annotated with intervals that express metric constraints . Hirshfeld and Rabinovich gave a negative answer , showing that first - order logic with binary order relation < and unary function + 1 is strictly more expressive than MTL with integer constants . However , a recent result of Hunter , Ouaknine and Worrell shows that with rational timing constants , MTL has the same expressive power as first - order logic , giving a positive answer . In this paper we generalize these results by giving a precise characterization of those sets of constants for which MTL and first - order logic have the same expressive power . We also show that full first - order expressiveness can be recovered with the addition of counting modalities , strongly supporting the assertion of Hirshfeld and Rabinovich that Q2MLO is one of the most expressive decidable fragments of FO(<,+1 ) .
Reachability of Communicating Timed Processes
We study the reachability problem for communicating timed processes , both in discrete and dense time . Our model comprises automata with local timing constraints communicating over unbounded FIFO channels . Each automaton can only access its set of local clocks ; all clocks evolve at the same rate . Our main contribution is a complete characterization of decidable and undecidable communication topologies , for both discrete and dense time . We also obtain complexity results , by showing that communicating timed processes are at least as hard as Petri nets ; in the discrete time , we also show equivalence with Petri nets . Our results follow from mutual topology - preserving reductions between timed automata and ( untimed ) counter automata .
Linear Types Can Change the Blockchain
We give an interpretation of full classical linear logic , and linear proofs in terms of operations on the blockchain .
The decision problem for a three - sorted fragment of set theory with restricted quantification and finite enumerations
We solve the satisfiability problem for a three - sorted fragment of set theory ( denoted $ 3LQST_0^R$ ) , which admits a restricted form of quantification over individual and set variables and the finite enumeration operator $ \{\text{- } , \text{- } , \ldots , \text{-}\}$ over individual variables , by showing that it enjoys a small model property , i.e. , any satisfiable formula $ \psi$ of $ 3LQST_0^R$ has a finite model whose size depends solely on the length of $ \psi$ itself . Several set - theoretic constructs are expressible by $ 3LQST_0^R$-formulae , such as some variants of the power set operator and the unordered Cartesian product . In particular , concerning the unordered Cartesian product , we show that when finite enumerations are used to represent the construct , the resulting formula is exponentially shorter than the one that can be constructed without resorting to such terms .
A Concurrency Problem with Exponential DPLL(T ) Proofs
Many satisfiability modulo theories solvers implement a variant of the DPLL(T ) framework which separates theory - specific reasoning from reasoning on the propositional abstraction of the formula . Such solvers conclude that a formula is unsatisfiable once they have learned enough theory conflicts to derive a propositional contradiction . However some problems , such as the diamonds problem , require learning exponentially many conflicts . We give a general criterion for establishing lower bounds on the number of theory conflicts in any DPLL(T ) proof for a given problem . We apply our criterion to two different state - of - the - art symbolic partial - order encodings of a simple , yet representative concurrency problem . Even though one of the encodings is asymptotically smaller than the other , we establish the same exponential lower bound proof complexity for both . Our experiments confirm this theoretical lower bound across multiple solvers and theory combinations .
Characteristics of Minimal Effective Programming Systems
The Rogers semilattice of effective programming systems ( epses ) is the collection of all effective numberings of the partial computable functions ordered such that \theta\ is less than or equal to \psi\ whenever \theta - programs can be algorithmically translated into \psi - programs . Herein , it is shown that an eps \psi\ is minimal in this ordering if and only if , for each translation function t into \psi , there exists a computably enumerable equivalence relation ( ceer ) R such that ( i ) R is a subrelation of \psi 's program equivalence relation , and ( ii ) R equates each \psi - program to some program in the range of t. It is also shown that there exists a minimal eps for which no single such R does the work for all such t. In fact , there exists a minimal eps \psi\ such that , for each ceer R , either R contradicts \psi 's program equivalence relation , or there exists a translation function t into \psi\ such that the range of t fails to intersect infinitely many of R 's equivalence classes .
Modelling Probabilistic Wireless Networks
We propose a process calculus to model high level wireless systems , where the topology of a network is described by a digraph . The calculus enjoys features which are proper of wireless networks , namely broadcast communication and probabilistic behaviour . We first focus on the problem of composing wireless networks , then we present a compositional theory based on a probabilistic generalisation of the well known may - testing and must - testing pre- orders . Also , we define an extensional semantics for our calculus , which will be used to define both simulation and deadlock simulation preorders for wireless networks . We prove that our simulation preorder is sound with respect to the may - testing preorder ; similarly , the deadlock simulation pre- order is sound with respect to the must - testing preorder , for a large class of networks . We also provide a counterexample showing that completeness of the simulation preorder , with respect to the may testing one , does not hold . We conclude the paper with an application of our theory to probabilistic routing protocols .
A Survey on Product Operators in Abstract Interpretation
The aim of this paper is to provide a general overview of the product operators introduced in the literature as a tool to enhance the analysis accuracy in the Abstract Interpretation framework . In particular we focus on the Cartesian and reduced products , as well as on the reduced cardinal power , an under - used technique whose features deserve to be stressed for their potential impact in practical applications .
A Proof System with Names for Modal Mu - calculus
Fixpoints are an important ingredient in semantics , abstract interpretation and program logics . Their addition to a logic can add considerable expressive power . One general issue is how to define proof systems for such logics . Here we examine proof systems for modal logic with fixpoints . We present a tableau proof system for checking validity of formulas which uses names to keep track of unfoldings of fixpoint variables as devised by Jungteerapanich .
Model Checking in Bits and Pieces
Fully automated verification of concurrent programs is a difficult problem , primarily because of state explosion : the exponential growth of a program state space with the number of its concurrently active components . It is natural to apply a divide and conquer strategy to ameliorate state explosion , by analyzing only a single component at a time . We show that this strategy leads to the notion of a " split " invariant , an assertion which is globally inductive , while being structured as the conjunction of a number of local , per - component invariants . This formulation is closely connected to the classical Owicki - Gries method and to Rely - Guarantee reasoning . We show how the division of an invariant into a number of pieces with limited scope makes it possible to apply new , localized forms of symmetry and abstraction to drastically simplify its computation . Split invariance also has interesting connections to parametric verification . A quantified invariant for a parametric system is a split invariant for every instance . We show how it is possible , in some cases , to invert this connection , and to automatically generalize from a split invariant for a small instance of a system to a quantified invariant which holds for the entire family of instances .
Interaction Grammars
Interaction Grammar ( IG ) is a grammatical formalism based on the notion of polarity . Polarities express the resource sensitivity of natural languages by modelling the distinction between saturated and unsaturated syntactic structures . Syntactic composition is represented as a chemical reaction guided by the saturation of polarities . It is expressed in a model - theoretic framework where grammars are constraint systems using the notion of tree description and parsing appears as a process of building tree description models satisfying criteria of saturation and minimality .
Bounded Underapproximations
We show a new and constructive proof of the following language - theoretic result : for every context - free language L , there is a bounded context - free language L ' included in L which has the same Parikh ( commutative ) image as L. Bounded languages , introduced by Ginsburg and Spanier , are subsets of regular languages of the form w1*w2* ... wk * for some finite words w1, ... ,wk . In particular bounded subsets of context - free languages have nice structural and decidability properties . Our proof proceeds in two parts . First , using Newton 's iterations on the language semiring , we construct a context - free subset Ls of L that can be represented as a sequence of substitutions on a linear language and has the same Parikh image as L. Second , we inductively construct a Parikh - equivalent bounded context - free subset of Ls . We show two applications of this result in model checking : to underapproximate the reachable state space of multithreaded procedural programs and to underapproximate the reachable state space of recursive counter programs . The bounded language constructed above provides a decidable underapproximation for the original problems . By iterating the construction , we get a semi - algorithm for the original problems that constructs a sequence of underapproximations such that no two underapproximations of the sequence can be compared . This provides a progress guarantee : every word w in L is in some underapproximation of the sequence . In addition , we show that our approach subsumes context - bounded reachability for multithreaded programs .
Reasoning About Higher - Order Relational Specifications
The logic of hereditary Harrop formulas ( HH ) has proven useful for specifying a wide range of formal systems . This logic includes a form of hypothetical judgment that leads to dynamically changing sets of assumptions and that is key to encoding side conditions and contexts that occur frequently in structural operational semantics ( SOS ) style presentations . Specifications are often useful in reasoning about the systems they describe . The Abella theorem prover supports such reasoning by explicitly embedding the specification logic within a rich reasoning logic ; specifications are then reasoned about through this embedding . However , realizing an induction principle in the face of dynamically changing assumption sets is nontrivial and the original Abella system uses only a subset of the HH specification logic for this reason . We develop a method here for supporting inductive reasoning over all of HH . Our approach takes advantage of a focusing property of HH to isolate the use of an assumption and the ability to finitely characterize the structure of any such assumption in the reasoning logic . We demonstrate the effectiveness of these ideas via several specification and meta - theoretic reasoning examples that have been implemented in an extended version of Abella .
Polarities & Focussing : a journey from Realisability to Automated Reasoning
This dissertation explores the roles of polarities and focussing in various aspects of Computational Logic . These concepts play a key role in the the interpretation of proofs as programs , a.k.a . the Curry - Howard correspondence , in the context of classical logic . Arising from linear logic , they allow the construction of meaningful semantics for cut - elimination in classical logic , some of which relate to the Call - by - Name and Call - by - Value disciplines of functional programming . The first part of this dissertation provides an introduction to these interpretations , highlighting the roles of polarities and focussing . For instance : proofs of positive formulae provide structured data , while proofs of negative formulae consume such data ; focussing allows the description of the interaction between the two kinds of proofs as pure pattern - matching . This idea is pushed further in the second part of this dissertation , and connected to realisability semantics , where the structured data is interpreted algebraically , and the consumption of such data is modelled with the use of an orthogonality relation . Most of this part has been proved in the Coq proof assistant . Polarities and focussing were also introduced with applications to logic programming in mind , where computation is proof - search . In the third part of this dissertation , we push this idea further by exploring the roles that these concepts can play in other applications of proof - search , such as theorem proving and more particularly automated reasoning . We use these concepts to describe the main algorithm of SAT - solvers and SMT - solvers : DPLL . We then describe the implementation of a proof - search engine called Psyche . Its architecture , based on the concept of focussing , offers a platform where smart techniques from automated reasoning ( or a user interface ) can safely and trustworthily be implemented via the use of an API .
Axiomatic constraint systems for proof search modulo theories
Goal - directed proof search in first - order logic uses meta - variables to delay the choice of witnesses ; substitutions for such variables are produced when closing proof - tree branches , using first - order unification or a theory - specific background reasoner . This paper investigates a generalisation of such mechanisms whereby theory - specific constraints are produced instead of substitutions . In order to design modular proof - search procedures over such mechanisms , we provide a sequent calculus with meta - variables , which manipulates such constraints abstractly . Proving soundness and completeness of the calculus leads to an axiomatisation that identifies the conditions under which abstract constraints can be generated and propagated in the same way unifiers usually are . We then extract from our abstract framework a component interface and a specification for concrete implementations of background reasoners .
A Hoare logic for the coinductive trace - based big - step semantics of While
In search for a foundational framework for reasoning about observable behavior of programs that may not terminate , we have previously devised a trace - based big - step semantics for While . In this semantics , both traces and evaluation ( relating initial states of program runs to traces they produce ) are defined coinductively . On terminating runs , this semantics agrees with the standard inductive state - based semantics . Here we present a Hoare logic counterpart of our coinductive trace - based semantics and prove it sound and complete . Our logic subsumes the standard partial - correctness state - based Hoare logic as well as the total - correctness variation : they are embeddable . In the converse direction , projections can be constructed : a derivation of a Hoare triple in our trace - based logic can be translated into a derivation in the state - based logic of a translated , weaker Hoare triple . Since we work with a constructive underlying logic , the range of program properties we can reason about has a fine structure ; in particular , we can distinguish between termination and nondivergence , e.g. , unbounded classically total search fails to be terminating , but is nonetheless nondivergent . Our meta - theory is entirely constructive as well , and we have formalized it in Coq .
Expected - Delay - Summing Weak Bisimilarity for Markov Automata
A new weak bisimulation semantics is defined for Markov automata that , in addition to abstracting from internal actions , sums up the expected values of consecutive exponentially distributed delays possibly intertwined with internal actions . The resulting equivalence is shown to be a congruence with respect to parallel composition for Markov automata . Moreover , it turns out to be comparable with weak bisimilarity for timed labeled transition systems , thus constituting a step towards reconciling the semantics for stochastic time and deterministic time .
The Attack as Intuitionistic Negation
We translate the argumentation networks $ { \cal A}=(S , R)$ into a theory $ D$ of intuitionistic logic , retaining $ S$ as the domain and using intuitionistic negation to model the attack $ R$ in $ { \cal A}$ : the attack $ xRy$ is translated to $ x\to\neg y$. The intuitionistic models of $ D$ characterise the complete extensions of $ { \cal A}$. The reduction of argumentation networks to intuitionistic logic yields , in addition to a representation theorem , some additional benefits : it allows us to give semantics to higher level attacks , where an attack " $ xRy$ " can itself attack another attack " $ uRv$ " ; one can make higher level meta - statements $ W$ on $ ( S , R)$ and such meta - statements can attack and be attacked in the domain .
Satisfiability for two - variable logic with two successor relations on finite linear orders
We study the finitary satisfiability problem for first order logic with two variables and two binary relations , corresponding to the induced successor relations of two finite linear orders . We show that the problem is decidable in NEXPTIME .
A recursive normalizing one - step reduction strategy for the distributive lambda calculus
We positively answer the question A.1.6 in J. Klop 's " Ustica Notes " : " Is there a recursive normalizing one - step reduction strategy for micro $ \lambda$-calculus ? " Micro $ \lambda$-calculus refers to an implementation of the $ \lambda$-calculus due to Revesz , implementing $ \beta$-reduction by means of " micro steps " recursively distributing a $ \beta$-redex $ ( \lambda x . M)\ N$ over its body $ M$.
Characterizing perfect recall using next - step temporal operators in S5 and sub - S5 Epistemic Temporal Logic
We review the notion of perfect recall in the literature on interpreted systems , game theory , and epistemic logic . In the context of Epistemic Temporal Logic ( ETL ) , we give a ( to our knowledge ) novel frame condition for perfect recall , which is local and can straightforwardly be translated to a defining formula in a language that only has next - step temporal operators . This frame condition also gives rise to a complete axiomatization for S5 ETL frames with perfect recall . We then consider how to extend and consolidate the notion of perfect recall in sub - S5 settings , where the various notions discussed are no longer equivalent .
Computational Higher Type Theory II : Dependent Cubical Realizability
This is the second in a series of papers extending Martin - L\"{o}f 's meaning explanation of dependent type theory to account for higher - dimensional types . We build on the cubical realizability framework for simple types developed in Part I , and extend it to a meaning explanation of dependent higher - dimensional type theory . This extension requires generalizing the computational Kan condition given in Part I , and considering the action of type families on paths . We define identification types , which classify identifications ( paths ) in a type , and dependent function and product types . The main result is a canonicity theorem , which states that a closed term of boolean type evaluates to either true or false . This result establishes the first computational interpretation of higher dependent type theory by giving a deterministic operational semantics for its programs , including operations that realize the Kan condition .
Coalgebraic Trace Semantics for Buechi and Parity Automata
Despite its success in producing numerous general results on state - based dynamics , the theory of coalgebra has struggled to accommodate the Buechi acceptance condition --- a basic notion in the theory of automata for infinite words or trees . In this paper we present a clean answer to the question that builds on the " maximality " characterization of infinite traces ( by Jacobs and Cirstea ) : the accepted language of a Buechi automaton is characterized by two commuting diagrams , one for a least homomorphism and the other for a greatest , much like in a system of ( least and greatest ) fixed - point equations . This characterization works uniformly for the nondeterministic branching and the probabilistic one ; and for words and trees alike . We present our results in terms of the parity acceptance condition that generalizes Buechi 's .
A Fully Abstract Semantics for Value - passing CCS for Trees
This paper provides a fully abstract semantics for value - passing CCS for trees ( VCCTS ) . The operational semantics is given both in terms of a reduction semantics and in terms of a labelled transition semantics . The labelled transition semantics is non - sequential , allowing more than one action occurring simultaneously . We develop the theory of behavioral equivalence by introducing both weak barbed congruence and weak bisimilarity . In particular , we show that weak barbed congruence coincides with weak bisimilarity on image - finite processes . This is the first such result for a concurrent model with tree structures . Distributed systems can be naturally modeled by means of this graph - based system , and some examples are given to illustrate this .
Optimizing the Expected Mean Payoff in Energy Markov Decision Processes
Energy Markov Decision Processes ( EMDPs ) are finite - state Markov decision processes where each transition is assigned an integer counter update and a rational payoff . An EMDP configuration is a pair s(n ) , where s is a control state and n is the current counter value . The configurations are changed by performing transitions in the standard way . We consider the problem of computing a safe strategy ( i.e. , a strategy that keeps the counter non - negative ) which maximizes the expected mean payoff .
On Computational Paths and the Fundamental Groupoid of a Type
The main objective of this work is to study mathematical properties of computational paths . Originally proposed by de Queiroz \ & Gabbay ( 1994 ) as ` sequences of rewrites ' , computational paths can be seen as the grounds on which the propositional equality between two computational objects stand . Using computational paths and categorical semantics , we take any type $ A$ of type theory and construct a groupoid for this type . We call this groupoid the fundamental groupoid of a type $ A$ , since it is similar to the one obtained using the homotopical interpretation of the identity type . The main difference is that instead of being just a semantical interpretation , computational paths are entities of the syntax of type theory . We also expand our results , using computational paths to construct fundamental groupoids of higher levels .
Improvement in Small Progress Measures
Small Progress Measures is one of the classical parity game solving algorithms . For games with n vertices , m edges and d different priorities , the original algorithm computes the winning regions and a winning strategy for one of the players in O(dm.(n / floor(d/2))^floor(d/2 ) ) time . Computing a winning strategy for the other player requires a re - run of the algorithm on that player 's winning region , thus increasing the runtime complexity to O(dm.(n / ceil(d/2))^ceil(d/2 ) ) for computing the winning regions and winning strategies for both players . We modify the algorithm so that it derives the winning strategy for both players in one pass . This reduces the upper bound on strategy derivation for SPM to O(dm.(n / floor(d/2))^floor(d/2 ) ) . At the basis of our modification is a novel operational interpretation of the least progress measure that we provide .
Negotiation Games
Negotiations , a model of concurrency with multi party negotiation as primitive , have been recently introduced by J. Desel and J. Esparza . We initiate the study of games for this model . We study coalition problems : can a given coalition of agents force that a negotiation terminates ( resp . block the negotiation so that it goes on forever ) ? ; can the coalition force a given outcome of the negotiation ? We show that for arbitrary negotiations the problems are EXPTIME - complete . Then we show that for sound and deterministic or even weakly deterministic negotiations the problems can be solved in PTIME . Notice that the input of the problems is a negotiation , which can be exponentially more compact than its state space .
Parameterized Linear Temporal Logics Meet Costs : Still not Costlier than LTL
We continue the investigation of parameterized extensions of Linear Temporal Logic ( LTL ) that retain the attractive algorithmic properties of LTL : a polynomial space model checking algorithm and a doubly - exponential time algorithm for solving games . Alur et al . and Kupferman et al . showed that this is the case for Parametric LTL ( PLTL ) and PROMPT - LTL respectively , which have temporal operators equipped with variables that bound their scope in time . Later , this was also shown to be true for Parametric LDL ( PLDL ) , which extends PLTL to be able to express all omega - regular properties . Here , we generalize PLTL to systems with costs , i.e. , we do not bound the scope of operators in time , but bound the scope in terms of the cost accumulated during time . Again , we show that model checking and solving games for specifications in PLTL with costs is not harder than the corresponding problems for LTL . Finally , we discuss PLDL with costs and extensions to multiple cost functions .
Robustness of a bisimulation - type faster - than preorder
TACS is an extension of CCS where upper time bounds for delays can be specified . Luettgen and Vogler defined three variants of bismulation - type faster - than relations and showed that they all three lead to the same preorder , demonstrating the robustness of their approach . In the present paper , the operational semantics of TACS is extended ; it is shown that two of the variants still give the same preorder as before , underlining robustness . An explanation is given why this result fails for the third variant . It is also shown that another variant , which mixes old and new operational semantics , can lead to smaller relations that prove the same preorder .
NP Datalog : a Logic Language for Expressing NP Search and Optimization Problems
This paper presents a logic language for expressing NP search and optimization problems . Specifically , first a language obtained by extending ( positive ) Datalog with intuitive and efficient constructs ( namely , stratified negation , constraints and exclusive disjunction ) is introduced . Next , a further restricted language only using a restricted form of disjunction to define ( non - deterministically ) subsets ( or partitions ) of relations is investigated . This language , called NP Datalog , captures the power of Datalog with unstratified negation in expressing search and optimization problems . A system prototype implementing NP Datalog is presented . The system translates NP Datalog queries into OPL programs which are executed by the ILOG OPL Development Studio . Our proposal combines easy formulation of problems , expressed by means of a declarative logic language , with the efficiency of the ILOG System . Several experiments show the effectiveness of this approach .
The Last Paper on the Halpern - Shoham Interval Temporal Logic
The Halpern - Shoham logic is a modal logic of time intervals . Some effort has been put in last ten years to classify fragments of this beautiful logic with respect to decidability of its satisfiability problem . We contribute to this effort by showing - what we believe is quite an unexpected result - that the logic of subintervals , the fragment of the Halpern - Shoham where only the operator " during " , or D , is allowed , is undecidable over discrete structures . This is surprising as this logic is decidable over dense orders and its reflexive variant is known to be decidable over discrete structures .
The Name - Passing Calculus
Name - passing calculi are foundational models for mobile computing . Research into these models has produced a wealth of results ranging from relative expressiveness to programming pragmatics . The diversity of these results call for clarification and reorganization . This paper applies a model independent approach to the study of the name - passing calculi , leading to a uniform treatment and simplification . The technical tools and the results presented in the paper form the foundation for a theory of name - passing calculus .
A New Representation Theorem for Many - valued Modal Logics
We propose a new definition of the representation theorem for many - valued logics , with modal operators as well , and define the stronger relationship between algebraic models of a given logic and relational structures used to define the Kripke possible - world semantics for it . Such a new framework offers a new semantics for many - valued logics based on the truth - invariance entailment . Consequently , it is substantially different from current definitions based on a matrix with a designated subset of logic values , used for the satisfaction relation , often difficult to fix . In the case when the many - valued modal logics are based on the set of truth - values that are complete distributive lattices we obtain a compact autoreferential Kripke - style canonical representation . The Kripke - style semantics for this subclass of modal logics have the joint - irreducible subset of the carrier set of many - valued algebras as set of possible worlds . A significant member of this subclass is the paraconsistent fuzzy logic extended by new logic values in order to also deal with incomplete and inconsistent information . This new theory is applied for the case of autoepistemic intuitionistic many - valued logic , based on Belnap 's 4-valued bilattice , as a minimal extension of classical logic used to manage incomplete and inconsistent information as well .
Probabilistic Logic : Many - valuedness and Intensionality
The probability theory is a well - studied branch of mathematics , in order to carry out formal reasoning about probability . Thus , it is important to have a logic , both for computation of probabilities and for reasoning about probabilities , with a well - defined syntax and semantics . Both current approaches , based on Nilsson 's probability structures / logics , and on linear inequalities in order to reason about probabilities , have some weak points . In this paper we have presented the complete revision of both approaches . We have shown that the full embedding of Nilsson'probabilistic structure into propositional logic results in a truth - functional many - valued logic , differently from Nilsson 's intuition and current considerations about propositional probabilistic logic . Than we have shown that the logic for reasoning about probabilities can be naturally embedded into a 2-valued intensional FOL with intensional abstraction , by avoiding current ad - hoc system composed of two different 2-valued logics : one for the classical propositional logic at lower - level , and a new one at higher - level for probabilistic constraints with probabilistic variables . The obtained theoretical results are applied to Probabilistic Logic Programming .
The Equivalence Problem for Deterministic MSO Tree Transducers is Decidable
It is decidable for deterministic MSO definable graph - to - string or graph - to - tree transducers whether they are equivalent on a context - free set of graphs .
Coalgebraic Infinite Traces and Kleisli Simulations
Kleisli simulation is a categorical notion introduced by Hasuo to verify finite trace inclusion . They allow us to give definitions of forward and backward simulation for various types of systems . A generic categorical theory behind Kleisli simulation has been developed and it guarantees the soundness of those simulations wrt . finite trace semantics . Moreover , those simulations can be aided by forward partial execution ( FPE)---a categorical transformation of systems previously introduced by the authors . In this paper , we give Kleisli simulation a theoretical foundation that assures its soundness also wrt . infinite trace . There , following Jacobs ' work , infinite trace semantics is characterized as the " largest homomorphism . " It turns out that soundness of forward simulations is rather straightforward ; that of backward simulation holds too , although it requires certain additional conditions and its proof is more involved . We also show that FPE can be successfully employed in the infinite trace setting to enhance the applicability of Kleisli simulations as witnesses of trace inclusion . Our framework is parameterized in the monad for branching as well as in the functor for linear - time behaviors ; for the former we use the powerset monad ( for nondeterminism ) as well as the sub - Giry monad ( for probability ) .
On Nested Sequents for Constructive Modal Logics
We present deductive systems for various modal logics that can be obtained from the constructive variant of the normal modal logic CK by adding combinations of the axioms d , t , b , 4 , and 5 . This includes the constructive variants of the standard modal logics K4 , S4 , and S5 . We use for our presentation the formalism of nested sequents and give a syntactic proof of cut elimination .
Detecting Unrealizability of Distributed Fault - tolerant Systems
Writing formal specifications for distributed systems is difficult . Even simple consistency requirements often turn out to be unrealizable because of the complicated information flow in the distributed system : not all information is available in every component , and information transmitted from other components may arrive with a delay or not at all , especially in the presence of faults . The problem of checking the distributed realizability of a temporal specification is , in general , undecidable . Semi - algorithms for synthesis , such as bounded synthesis , are only useful in the positive case , where they construct an implementation for a realizable specification , but not in the negative case : if the specification is unrealizable , the search for the implementation never terminates . In this paper , we introduce counterexamples to distributed realizability and present a method for the detection of such counterexamples for specifications given in linear - time temporal logic ( LTL ) . A counterexample consists of a set of paths , each representing a different sequence of inputs from the environment , such that , no matter how the components are implemented , the specification is violated on at least one of these paths . We present a method for finding such counterexamples both for the classic distributed realizability problem and for the fault - tolerant realizability problem . Our method considers , incrementally , larger and larger sets of paths until a counterexample is found . For safety specifications in weakly ordered architectures we obtain a decision procedure , while counterexamples for full LTL and arbitrary architectures may consist of infinitely many paths . Experimental results , obtained with a QBF - based prototype implementation , show that our method finds simple errors very quickly , and even problems with high combinatorial complexity , like the Byzantine Generals ' Problem , are tractable .
Presenting Finite Posets
We introduce a monoidal category whose morphisms are finite partial orders , with chosen minimal and maximal elements as source and target respectively . After recalling the notion of presentation of a monoidal category by the means of generators and relations , we construct a presentation of our category , which corresponds to a variant of the notion of bialgebra .
Automatic Generation of Proof Tactics for Finite - Valued Logics
A number of flexible tactic - based logical frameworks are nowadays available that can implement a wide range of mathematical theories using a common higher - order metalanguage . Used as proof assistants , one of the advantages of such powerful systems resides in their responsiveness to extensibility of their reasoning capabilities , being designed over rule - based programming languages that allow the user to build her own ` programs to construct proofs ' - the so - called proof tactics . The present contribution discusses the implementation of an algorithm that generates sound and complete tableau systems for a very inclusive class of sufficiently expressive finite - valued propositional logics , and then illustrates some of the challenges and difficulties related to the algorithmic formation of automated theorem proving tactics for such logics . The procedure on whose implementation we will report is based on a generalized notion of analyticity of proof systems that is intended to guarantee termination of the corresponding automated tactics on what concerns theoremhood in our targeted logics .
Verifying Temporal Regular Properties of Abstractions of Term Rewriting Systems
The tree automaton completion is an algorithm used for proving safety properties of systems that can be modeled by a term rewriting system . This representation and verification technique works well for proving properties of infinite systems like cryptographic protocols or more recently on Java Bytecode programs . This algorithm computes a tree automaton which represents a ( regular ) over approximation of the set of reachable terms by rewriting initial terms . This approach is limited by the lack of information about rewriting relation between terms . Actually , terms in relation by rewriting are in the same equivalence class : there are recognized by the same state in the tree automaton . Our objective is to produce an automaton embedding an abstraction of the rewriting relation sufficient to prove temporal properties of the term rewriting system . We propose to extend the algorithm to produce an automaton having more equivalence classes to distinguish a term or a subterm from its successors w.r.t . rewriting . While ground transitions are used to recognize equivalence classes of terms , epsilon - transitions represent the rewriting relation between terms . From the completed automaton , it is possible to automatically build a Kripke structure abstracting the rewriting sequence . States of the Kripke structure are states of the tree automaton and the transition relation is given by the set of epsilon - transitions . States of the Kripke structure are labelled by the set of terms recognized using ground transitions . On this Kripke structure , we define the Regular Linear Temporal Logic ( R - LTL ) for expressing properties . Such properties can then be checked using standard model checking algorithms . The only difference between LTL and R - LTL is that predicates are replaced by regular sets of acceptable terms .
Bisimulation Relations Between Automata , Stochastic Differential Equations and Petri Nets
Two formal stochastic models are said to be bisimilar if their solutions as a stochastic process are probabilistically equivalent . Bisimilarity between two stochastic model formalisms means that the strengths of one stochastic model formalism can be used by the other stochastic model formalism . The aim of this paper is to explain bisimilarity relations between stochastic hybrid automata , stochastic differential equations on hybrid space and stochastic hybrid Petri nets . These bisimilarity relations make it possible to combine the formal verification power of automata with the analysis power of stochastic differential equations and the compositional specification power of Petri nets . The relations and their combined strengths are illustrated for an air traffic example .
A Complete Decision Procedure for Univariate Polynomial Problems in Isabelle / HOL
We present a complete , certificate - based decision procedure for first - order univariate polynomial problems in Isabelle . It is built around an executable function to decide the sign of a univariate polynomial at a real algebraic point . The procedure relies on no trusted code except for Isabelle 's kernel and code generation . This work is the first step towards integrating the MetiTarski theorem prover into Isabelle .
Synthesis of AMBA AHB from Formal Specification
The standard procedure for hardware design consists of describing circuit in a hardware description language at logic level followed by extensive verification and logic - synthesis . However , this process consumes significant time and needs a lot of effort . An alternative is to use formal specification language as a high - level hardware description language and synthesize hardware from formal specification . Bloem et.al . gave formal specifications and synthesize the AMBA AHB Arbiter . Our contributions are as follows:(1 ) We present more complete and compact formal specifications for the AMBA AHB Arbiter , and obtain significant ( order of magnitude ) improvement in synthesis results ( both with respect to time and the number of gates of the synthesize circuit ) ; ( 2 ) we present formal specification and synthesize to generate compact circuits for the remaining two components of the AMBA AHB protocol , namely , the AMBA AHB Master and AMBA AHB Slave ; and ( 3 ) from the lessons learnt we present few principles for writing formal specifications for efficient hardware synthesis . Thus with intelligently written complete formal specifications we are able to automatically synthesize an important and widely used industrial protocol .
A finiteness structure on resource terms
In our paper " Uniformity and the Taylor expansion of ordinary lambda - terms " ( with Laurent Regnier ) , we studied a translation of lambda - terms as infinite linear combinations of resource lambda - terms , from a calculus similar to Boudol 's lambda - calculus with resources and based on ideas coming from differential linear logic and differential lambda - calculus . The good properties of this translation wrt . beta - reduction were guaranteed by a coherence relation on resource terms : normalization is " linear and stable " ( in the sense of the coherence space semantics of linear logic ) wrt . this coherence relation . Such coherence properties are lost when one considers non - deterministic or algebraic extensions of the lambda - calculus ( the algebraic lambda - calculus is an extension of the lambda - calculus where terms can be linearly combined ) . We introduce a " finiteness structure " on resource terms which induces a linearly topologized vector space structure on terms and prevents the appearance of infinite coefficients during reduction , in typed settings .
Logics of Essence and Accident
In the literature , essence is formalized in two different ways , either de dicto , or de re . Following \cite{Marcos:2005 } , we adopt its de dicto formalization : a formula is essential , if once it is true , it is necessarily true ; otherwise , it is accidental . In this article , we study the model theory and axiomatization of the logic of essence and accident , i.e. the logic with essence operator ( or accident operator ) as the only primitive modality . We show that the logic of essence and accident is less expressive than modal logic on non - reflexive models , but the two logics are equally expressive on reflexive models . We prove that some frame properties are undefinable in the logic of essence and accident , while some are . We propose the suitable bisimulation for this logic , based on which we characterize the expressive power of this logic within modal logic and within first - order logic . We axiomatize this logic over various frame classes , among which the symmetric case is missing , and our method is more suitable than those in the literature . We also find a method to compute certain axioms used to axiomatize this logic over special frames in the literature . As a side effect , we answer some open questions raised in \cite{Marcos:2005}.
A study on central soft sets : Definitions and basic operations
In this paper , a new kind of soft sets related with some common decision making problems in real life called central soft sets is introduced . Properties of some basic operations on central soft sets are shown . It is investigated that some classic operations between soft sets can be obtained by central soft sets with selecting different central sets . We initiate the concepts of an evaluation system for a parameters set and its optional solutions . An algorithm is presented to solve such decision making problems .
Double Successive Rough Set Approximations
We examine double successive approximations on a set , which we denote by $ L_2L_1 , \ U_2U_1 , U_2L_1,$ $ L_2U_1 $ where $ L_1 , U_1 $ and $ L_2 , U_2 $ are based on generally non - equivalent equivalence relations $ E_1 $ and $ E_2 $ respectively , on a finite non - empty set $ V.$ We consider the case of these operators being given fully defined on its powerset $ \mathscr{P}(V).$ Then , we investigate if we can reconstruct the equivalence relations which they may be based on . Directly related to this , is the question of whether there are unique solutions for a given defined operator and the existence of conditions which may characterise this . We find and prove these characterising conditions that equivalence relation pairs should satisfy in order to generate unique such operators .
What is a categorical model of the differential and the resource lambda - calculi ?
In this paper we provide an abstract model theory for the untyped differential lambda - calculus and the resource calculus . In particular we propose a general definition of model of these calculi , namely the notion of linear reflexive object in a Cartesian closed differential category . Examples of models based on relations are provided .
Verifying Safety Properties With the TLA+ Proof System
TLAPS , the TLA+ proof system , is a platform for the development and mechanical verification of TLA+ proofs written in a declarative style requiring little background beyond elementary mathematics . The language supports hierarchical and non - linear proof construction and verification , and it is independent of any verification tool or strategy . A Proof Manager uses backend verifiers such as theorem provers , proof assistants , SMT solvers , and decision procedures to check TLA+ proofs . This paper documents the first public release of TLAPS , distributed with a BSD - like license . It handles almost all the non - temporal part of TLA+ as well as the temporal reasoning needed to prove standard safety properties , in particular invariance and step simulation , but not liveness properties .
An Algebraic Treatment of Recursion
I review the three principal methods to assign meaning to recursion in process algebra : the denotational , the operational and the algebraic approach , and I extend the latter to unguarded recursion .
DepQBF 6.0 : A Search - Based QBF Solver Beyond Traditional QCDCL
We present the latest version 6.0 of the quantified Boolean formula ( QBF ) solver DepQBF , which is based on QCDCL . QCDCL is an extension of the conflict - driven clause learning ( CDCL ) paradigm implemented in state of the art propositional satisfiability ( SAT ) solvers . The Q - resolution calculus ( QRES ) is a QBF proof system which underlies QCDCL . QCDCL solvers can produce QRES proofs of QBFs in prenex conjunctive normal form ( PCNF ) as a byproduct of the solving process . In contrast to traditional QCDCL based on QRES , DepQBF 6.0 implements a variant of QCDCL which is based on a generalization of QRES . This generalization is due to a set of additional axioms and leaves the original Q - resolution rules unchanged . The generalization of QRES enables QCDCL to potentially produce exponentially shorter proofs than traditional QCDCL . We present an overview of the features implemented in DepQBF and report on experimental results which demonstrate the effectiveness of generalized QRES in QCDCL .
A New Execution Model for the logic of hereditary Harrop formulas
The class of first - order Hereditary Harrop formulas ( $ fohh$ ) is a well - established extension of first - order Horn clauses . Its operational semantics is based on intuitionistic provability . We propose another operational semantics for $ fohh$ which is based on game semantics . This new semantics has several interesting aspects : in particular , it gives a logical status to the $ read$ predicate in Prolog .
A Framework to Handle Linear Temporal Properties in ( o-)Regular Model Checking
Since the topic emerged several years ago , work on regular model checking has mostly been devoted to the verification of state reachability and safety properties . Though it was known that linear temporal properties could also be checked within this framework , little has been done about working out the corresponding details . This paper addresses this issue in the context of regular model checking based on the encoding of states by finite or infinite words . It works out the exact constructions to be used in both cases , and proposes a partial solution to the problem resulting from the fact that infinite computations of unbounded configurations might never contain the same configuration twice , thus making cycle detection problematic .
Comparison of Algorithms for Checking Emptiness on Buechi Automata
We re - investigate the problem of LTL model - checking for finite - state systems . Typical solutions , like in Spin , work on the fly , reducing the problem to Buechi emptiness . This can be done in linear time , and a variety of algorithms with this property exist . Nonetheless , subtle design decisions can make a great difference to their actual performance in practice , especially when used on - the - fly . We compare a number of algorithms experimentally on a large benchmark suite , measure their actual run - time performance , and propose improvements . Compared with the algorithm implemented in Spin , our best algorithm is faster by about 33 % on average . We therefore recommend that , for on - the - fly explicit - state model checking , nested DFS should be replaced by better solutions .
Modular Complexity Analysis for Term Rewriting
All current investigations to analyze the derivational complexity of term rewrite systems are based on a single termination method , possibly preceded by transformations . However , the exclusive use of direct criteria is problematic due to their restricted power . To overcome this limitation the article introduces a modular framework which allows to infer ( polynomial ) upper bounds on the complexity of term rewrite systems by combining different criteria . Since the fundamental idea is based on relative rewriting , we study how matrix interpretations and match - bounds can be used and extended to measure complexity for relative rewriting , respectively . The modular framework is proved strictly more powerful than the conventional setting . Furthermore , the results have been implemented and experiments show significant gains in power .
Proof Pattern Search in Coq / SSReflect
ML4PG is an extension of the Proof General interface , allowing the user to invoke machine - learning algorithms and find proof similarities in Coq / SSReect libraries . In this paper , we present three new improvements to ML4PG . First , a new method of " recurrent clustering " is introduced to collect statistical features from Coq terms . Now the user can receive suggestions about similar definitions , types and lemma statements , in addition to proof strategies . Second , Coq proofs are split into patches to capture proof strategies that could arise at different stages of a proof . Finally , we improve ML4PG 's output introducing an automaton - shape representation for proof patterns .
Branching Bisimilarity Checking for PRS
Recent studies reveal that branching bisimilarity is decidable for both nBPP ( normed Basic Parallel Process ) and nBPA ( normed Basic Process Algebra ) . These results lead to the question if there are any other models in the hierarchy of PRS ( Process Rewrite System ) whose branching bisimilarity is decidable . It is shown in this paper that the branching bisimilarity for both nOCN ( normed One Counter Net ) and nPA ( normed Process Algebra ) is undecidable . These results essentially imply that the question has a negative answer .
An Intuitionisticaly based Description Logic
This article presents iALC , an intuitionistic version of the classical description logic ALC , based on the framework for constructive modal logics presented by Simpson \cite{simpson95 } and related to description languages , via hybrid logics , by dePaiva \cite{depaiva2003}. This article correcta and extends the presentation of iALC appearing in \cite{PHR:2010}. It points out the difference between iALC and the intuitionistic hybrid logic presented in \cite{depaiva2003}. Completeness and soundness proofs are provided . A brief discussion on the computacional complexity of iALC provability is taken . It is worth mentioning that iALC is used to formalize legal knowledge \cite{HPR:2010a , HPR:2010ab , Jurix , HPR:2011 } , and in fact , was specifically designed to this goal .
The Completeness Problem for Modal Logic
We examine the completeness problem for Modal Logic : given a formula , is it complete ? We discover that for most cases , completeness and validity have the same complexity , with certain exceptions for which there are , in general , no complete formulas . To prove upper bounds , we give a game which combines bisimulation games and tableaux , and which determines whether a formula is complete . The game then easily turns into an alternating algorithm .
Wave - Style Token Machines and Quantum Lambda Calculi ( Long Version )
Particle - style token machines are a way to interpret proofs and programs , when the latter are defined according to the principles of linear logic . In this paper , we show that token machines also make sense when the programs at hand are those of a simple linear quantum $ \lambda$-calculus . This , however , requires generalizing the concept of a token machine to one in which more than one particle can possibly travel around the term at the same time . This is intimately related to entanglement and allows to give a simple operational semantics to the calculus coherently with the principles of quantum computation .
Epistemic Updates on Algebras
We develop the mathematical theory of epistemic updates with the tools of duality theory . We focus on the Logic of Epistemic Actions and Knowledge ( EAK ) , introduced by Baltag - Moss- Solecki , without the common knowledge operator . We dually characterize the product update construction of EAK as a certain construction transforming the complex algebras associated with the given model into the complex algebra associated with the updated model . This dual characterization naturally generalizes to much wider classes of algebras , which include , but are not limited to , arbitrary BAOs and arbitrary modal expansions of Heyting algebras ( HAOs ) . As an application of this dual characterization , we axiomatize the intuitionistic analogue of the logic of epistemic knowledge and actions , which we refer to as IEAK , prove soundness and completeness of IEAK w.r.t . both algebraic and relational models , and illustrate how IEAK encodes the reasoning of agents in a concrete epistemic scenario .
Incarnation in Ludics and maximal cliques of paths
Ludics is a reconstruction of logic with interaction as a primitive notion , in the sense that the primary logical concepts are no more formulas and proofs but cut - elimination interpreted as an interaction between objects called designs . When the interaction between two designs goes well , such two designs are said to be orthogonal . A behaviour is a set of designs closed under bi - orthogonality . Logical formulas are then denoted by behaviours . Finally proofs are interpreted as designs satisfying particular properties . In that way , designs are more general than proofs and we may notice in particular that they are not typed objects . Incarnation is introduced by Girard in Ludics as a characterization of " useful " designs in a behaviour . The incarnation of a design is defined as its subdesign that is the smallest one in the behaviour ordered by inclusion . It is useful in particular because being " incarnated " is one of the conditions for a design to denote a proof of a formula . The computation of incarnation is important also as it gives a minimal denotation for a formula , and more generally for a behaviour . We give here a constructive way to capture the incarnation of the behaviour of a set of designs , without computing the behaviour itself . The method we follow uses an alternative definition of designs : rather than defining them as sets of chronicles , we consider them as sets of paths , a concept very close to that of play in game semantics that allows an easier handling of the interaction : the unfolding of interaction is a path common to two interacting designs .
Resolution Proof Transformation for Compression and Interpolation
Verification methods based on SAT , SMT , and Theorem Proving often rely on proofs of unsatisfiability as a powerful tool to extract information in order to reduce the overall effort . For example a proof may be traversed to identify a minimal reason that led to unsatisfiability , for computing abstractions , or for deriving Craig interpolants . In this paper we focus on two important aspects that concern efficient handling of proofs of unsatisfiability : compression and manipulation . First of all , since the proof size can be very large in general ( exponential in the size of the input problem ) , it is indeed beneficial to adopt techniques to compress it for further processing . Secondly , proofs can be manipulated as a flexible preprocessing step in preparation for interpolant computation . Both these techniques are implemented in a framework that makes use of local rewriting rules to transform the proofs . We show that a careful use of the rules , combined with existing algorithms , can result in an effective simplification of the original proofs . We have evaluated several heuristics on a wide range of unsatisfiable problems deriving from SAT and SMT test cases .
Towards Reasoning About Properties of Imperative Programs using Linear Logic
In this paper we propose an approach to reasoning about properties of imperative programs . We assume in this context that the meanings of program constructs are described using rules in the natural semantics style with the additional observation that these rules may involve the treatment of state . Our approach involves modeling natural semantics style rules within a logic and then reasoning about the behavior of particular programs by reasoning about proofs in that logic . A key aspect of our proposal is to use a fragment of linear logic called Lolli ( invented by Hodas and Miller ) to model natural semantics style descriptions . Being based on linear logic , Lolli can provide logical expression to resources such as state . Lolli additionally possesses proof - theoretic properties that allow it to encode natural semantics style descriptions in such a way that proofs in Lolli mimic the structure of derivations based on the natural semantics rules . We will discuss these properties of Lolli and demonstrate how they can be exploited in modeling the semantics of imperative programs and in reasoning about such models .
Demystifying Reachability in Vector Addition Systems
More than 30 years after their inception , the decidability proofs for reachability in vector addition systems ( VAS ) still retain much of their mystery . These proofs rely crucially on a decomposition of runs successively refined by Mayr , Kosaraju , and Lambert , which appears rather magical , and for which no complexity upper bound is known . We first offer a justification for this decomposition technique , by showing that it computes the ideal decomposition of the set of runs , using the natural embedding relation between runs as well quasi ordering . In a second part , we apply recent results on the complexity of termination thanks to well quasi orders and well orders to obtain a cubic Ackermann upper bound for the decomposition algorithms , thus providing the first known upper bounds for general VAS reachability .
Tractability Frontier of Data Complexity in Team Semantics
We study the data complexity of model - checking for logics with team semantics . For dependence and independence logic , we completely characterize the tractability / intractability frontier of data complexity of both quantifier - free and quantified formulas . For inclusion logic formulas , we reduce the model - checking problem to the satisfiability problem of so - called Dual - Horn propositional formulas . Via this reduction , we give an alternative proof for the recent result showing that the data complexity of inclusion logic is in PTIME .
Better Quasi - Ordered Transition Systems
Many existing algorithms for model checking of infinite - state systems operate on constraints which are used to represent ( potentially infinite ) sets of states . A general powerful technique which can be employed for proving termination of these algorithms is that of well quasi - orderings . Several methodologies have been proposed for derivation of new well quasi - ordered constraint systems . However , many of these constraint systems suffer from a " constraint explosion problem " , as the number of the generated constraints grows exponentially with the size of the problem . In this paper , we demonstrate that a refinement of the theory of well quasi - orderings , called the theory of better quasi - orderings , is more appropriate for symbolic model checking , since it allows inventing constraint systems which are both well quasi - ordered and compact . As a main application , we introduce existential zones , a constraint system for verification of systems with unboundedly many clocks and use our methodology to prove that existential zones are better quasi - ordered . We show how to use existential zones in verification of timed Petri nets and present some experimental results . Also , we apply our methodology to derive new constraint systems for verification of broadcast protocols , lossy channel systems , and integral relational automata . The new constraint systems are exponentially more succinct than existing ones , and their well quasi - ordering can not be shown by previous methods in the literature .
Exploiting the Temporal Logic Hierarchy and the Non - Confluence Property for Efficient LTL Synthesis
The classic approaches to synthesize a reactive system from a linear temporal logic ( LTL ) specification first translate the given LTL formula to an equivalent omega - automaton and then compute a winning strategy for the corresponding omega - regular game . To this end , the obtained omega - automata have to be ( pseudo)-determinized where typically a variant of Safra 's determinization procedure is used . In this paper , we show that this determinization step can be significantly improved for tool implementations by replacing Safra 's determinization by simpler determinization procedures . In particular , we exploit ( 1 ) the temporal logic hierarchy that corresponds to the well - known automata hierarchy consisting of safety , liveness , Buechi , and co - Buechi automata as well as their boolean closures , ( 2 ) the non - confluence property of omega - automata that result from certain translations of LTL formulas , and ( 3 ) symbolic implementations of determinization procedures for the Rabin - Scott and the Miyano - Hayashi breakpoint construction . In particular , we present convincing experimental results that demonstrate the practical applicability of our new synthesis procedure .
Efficient Symmetry Reduction and the Use of State Symmetries for Symbolic Model Checking
One technique to reduce the state - space explosion problem in temporal logic model checking is symmetry reduction . The combination of symmetry reduction and symbolic model checking by using BDDs suffered a long time from the prohibitively large BDD for the orbit relation . Dynamic symmetry reduction calculates representatives of equivalence classes of states dynamically and thus avoids the construction of the orbit relation . In this paper , we present a new efficient model checking algorithm based on dynamic symmetry reduction . Our experiments show that the algorithm is very fast and allows the verification of larger systems . We additionally implemented the use of state symmetries for symbolic symmetry reduction . To our knowledge we are the first who investigated state symmetries in combination with BDD based symbolic model checking .
Equilibrium and Termination
We present a reduction of the termination problem for a Turing machine ( in the simplified form of the Post correspondence problem ) to the problem of determining whether a continuous - time Markov chain presented as a set of Kappa graph - rewriting rules has an equilibrium . It follows that the problem of whether a computable CTMC is dissipative ( ie does not have an equilibrium ) is undecidable .
The space of measurement outcomes as a spectrum for non - commutative algebras
Bohrification defines a locale of hidden variables internal in a topos . We find that externally this is the space of partial measurement outcomes . By considering the double negation sheafification , we obtain the space of measurement outcomes which coincides with the spectrum for commutative C*-algebras .
Mean - payoff Automaton Expressions
Quantitative languages are an extension of boolean languages that assign to each word a real number . Mean - payoff automata are finite automata with numerical weights on transitions that assign to each infinite path the long - run average of the transition weights . When the mode of branching of the automaton is deterministic , nondeterministic , or alternating , the corresponding class of quantitative languages is not robust as it is not closed under the pointwise operations of max , min , sum , and numerical complement . Nondeterministic and alternating mean - payoff automata are not decidable either , as the quantitative generalization of the problems of universality and language inclusion is undecidable . We introduce a new class of quantitative languages , defined by mean - payoff automaton expressions , which is robust and decidable : it is closed under the four pointwise operations , and we show that all decision problems are decidable for this class . Mean - payoff automaton expressions subsume deterministic mean - payoff automata , and we show that they have expressive power incomparable to nondeterministic and alternating mean - payoff automata . We also present for the first time an algorithm to compute distance between two quantitative languages , and in our case the quantitative languages are given as mean - payoff automaton expressions .
The duality of computation under focus
We review the close relationship between abstract machines for ( call - by - name or call - by - value ) lambda - calculi ( extended with Felleisen 's C ) and sequent calculus , reintroducing on the way Curien - Herbelin 's syntactic kit expressing the duality of computation . We use this kit to provide a term language for a presentation of LK ( with conjunction , disjunction , and negation ) , and to transcribe cut elimination as ( non confluent ) rewriting . A key slogan here , which may appear here in print for the first time , is that commutative cut elimination rules are explicit substitution propagation rules . We then describe the focalised proof search discipline ( in the classical setting ) , and narrow down the language and the rewriting rules to a confluent calculus ( a variant of the second author 's focalising system L ) . We then define a game of patterns and counterpatterns , leading us to a fully focalised finitary syntax for a synthetic presentation of classical logic , that provides a quotient on ( focalised ) proofs , abstracting out the order of decomposition of negative connectives .
Exposition : Synthesis via Functional Interpretation
The aim of this short paper is to give a practical introduction to functional interpretation of proofs for computer scientists interested in synthesis .
A general translation from nested Petri nets into PROMELA
Nested Petri nets have been applied for modeling interaction protocols , mobility , adaptive systems and interorganizational workflows . However , few results have been reported on the use of automated tools for analyzing the behavior of these nets . In this paper we present a general translation from nested Petri nets into PROMELA and explain how some properties of these nets can be studied using SPIN model checker . Besides , we discuss how to deal with the main limitations that may influence SPIN performance when verifying practical examples .
Synthesizing Multiple Boolean Functions using Interpolation on a Single Proof
It is often difficult to correctly implement a Boolean controller for a complex system , especially when concurrency is involved . Yet , it may be easy to formally specify a controller . For instance , for a pipelined processor it suffices to state that the visible behavior of the pipelined system should be identical to a non - pipelined reference system ( Burch - Dill paradigm ) . We present a novel procedure to efficiently synthesize multiple Boolean control signals from a specification given as a quantified first - order formula ( with a specific quantifier structure ) . Our approach uses uninterpreted functions to abstract details of the design . We construct an unsatisfiable SMT formula from the given specification . Then , from just one proof of unsatisfiability , we use a variant of Craig interpolation to compute multiple coordinated interpolants that implement the Boolean control signals . Our method avoids iterative learning and back - substitution of the control functions . We applied our approach to synthesize a controller for a simple two - stage pipelined processor , and present first experimental results .
Satisfiability Games for Branching - Time Logics
The satisfiability problem for branching - time temporal logics like CTL * , CTL and CTL+ has important applications in program specification and verification . Their computational complexities are known : CTL * and CTL+ are complete for doubly exponential time , CTL is complete for single exponential time . Some decision procedures for these logics are known ; they use tree automata , tableaux or axiom systems . In this paper we present a uniform game - theoretic framework for the satisfiability problem of these branching - time temporal logics . We define satisfiability games for the full branching - time temporal logic CTL * using a high - level definition of winning condition that captures the essence of well - foundedness of least fixpoint unfoldings . These winning conditions form formal languages of \omega - words . We analyse which kinds of deterministic { \omega}-automata are needed in which case in order to recognise these languages . We then obtain a reduction to the problem of solving parity or B\"uchi games . The worst - case complexity of the obtained algorithms matches the known lower bounds for these logics . This approach provides a uniform , yet complexity - theoretically optimal treatment of satisfiability for branching - time temporal logics . It separates the use of temporal logic machinery from the use of automata thus preserving a syntactical relationship between the input formula and the object that represents satisfiability , i.e. a winning strategy in a parity or B\"uchi game . The games presented here work on a Fischer - Ladner closure of the input formula only . Last but not least , the games presented here come with an attempt at providing tool support for the satisfiability problem of complex branching - time logics like CTL * and CTL+ .
Implicit Resolution
Let \Omega be a set of unsatisfiable clauses , an implicit resolution refutation of \Omega is a circuit \beta with a resolution proof { \alpha } of the statement " \beta describes a correct tree - like resolution refutation of \Omega " . We show that such system is p - equivalent to Extended Frege . More generally , let { \tau } be a tautology , a [ P , Q]-proof of { \tau } is a pair ( \alpha,\beta ) s.t . \alpha is a P - proof of the statement " \beta is a circuit describing a correct Q - proof of \tau " . We prove that [ EF , P ] \leq p [ R , P ] for arbitrary Cook - Reckhow proof system P.
Homomorphism Preservation on Quasi - Wide Classes
A class of structures is said to have the homomorphism - preservation property just in case every first - order formula that is preserved by homomorphisms on this class is equivalent to an existential - positive formula . It is known by a result of Rossman that the class of finite structures has this property and by previous work of Atserias et al . that various of its subclasses do . We extend the latter results by introducing the notion of a quasi - wide class and showing that any quasi - wide class that is closed under taking substructures and disjoint unions has the homomorphism - preservation property . We show , in particular , that classes of structures of bounded expansion and that locally exclude minors are quasi - wide . We also construct an example of a class of finite structures which is closed under substructures and disjoint unions but does not admit the homomorphism - preservation property .
ACL2(ml ) : Machine - Learning for ACL2
ACL2(ml ) is an extension for the Emacs interface of ACL2 . This tool uses machine - learning to help the ACL2 user during the proof - development . Namely , ACL2(ml ) gives hints to the user in the form of families of similar theorems , and generates auxiliary lemmas automatically . In this paper , we present the two most recent extensions for ACL2(ml ) . First , ACL2(ml ) can suggest now families of similar function definitions , in addition to the families of similar theorems . Second , the lemma generation tool implemented in ACL2(ml ) has been improved with a method to generate preconditions using the guard mechanism of ACL2 . The user of ACL2(ml ) can also invoke directly the latter extension to obtain preconditions for his own conjectures .
A Branching Time Model of CSP
I present a branching time model of CSP that is finer than all other models of CSP proposed thus far . It is obtained by taking a semantic equivalence from the linear time - branching time spectrum , namely divergence - preserving coupled similarity , and showing that it is a congruence for the operators of CSP . This equivalence belongs to the bisimulation family of semantic equivalences , in the sense that on transition systems without internal actions it coincides with strong bisimilarity . Nevertheless , enough of the equational laws of CSP remain to obtain a complete axiomatisation for closed , recursion - free terms .
Inductive and Coinductive Components of Corecursive Functions in Coq
In Constructive Type Theory , recursive and corecursive definitions are subject to syntactic restrictions which guarantee termination for recursive functions and productivity for corecursive functions . However , many terminating and productive functions do not pass the syntactic tests . Bove proposed in her thesis an elegant reformulation of the method of accessibility predicates that widens the range of terminative recursive functions formalisable in Constructive Type Theory . In this paper , we pursue the same goal for productive corecursive functions . Notably , our method of formalisation of coinductive definitions of productive functions in Coq requires not only the use of ad - hoc predicates , but also a systematic algorithm that separates the inductive and coinductive parts of functions .
Alternating Timed Automata
A notion of alternating timed automata is proposed . It is shown that such automata with only one clock have decidable emptiness problem over finite words . This gives a new class of timed languages which is closed under boolean operations and which has an effective presentation . We prove that the complexity of the emptiness problem for alternating timed automata with one clock is non - primitive recursive . The proof gives also the same lower bound for the universality problem for nondeterministic timed automata with one clock . We investigate extension of the model with epsilon - transitions and prove that emptiness is undecidable . Over infinite words , we show undecidability of the universality problem .
A Fixpoint Semantics of Event Systems with and without Fairness Assumptions
We present a fixpoint semantics of event systems . The semantics is presented in a general framework without concerns of fairness . Soundness and completeness of rules for deriving " leads - to " properties are proved in this general framework . The general framework is instantiated to minimal progress and weak fairness assumptions and similar results are obtained . We show the power of these results by deriving sufficient conditions for " leads - to " under minimal progress proving soundness of proof obligations without reasoning over state - traces .
On the Axiomatisation of Boolean Categories with and without Medial
The term `` Boolean category '' should be used for describing an object that is to categories what a Boolean algebra is to posets . More specifically , a Boolean category should provide the abstract algebraic structure underlying the proofs in Boolean Logic , in the same sense as a Cartesian closed category captures the proofs in intuitionistic logic and a * -autonomous category captures the proofs in linear logic . However , recent work has shown that there is no canonical axiomatisation of a Boolean category . In this work , we will see a series ( with increasing strength ) of possible such axiomatisations , all based on the notion of * -autonomous category . We will particularly focus on the medial map , which has its origin in an inference rule in KS , a cut - free deductive system for Boolean logic in the calculus of structures . Finally , we will present a category of proof nets as a particularly well - behaved example of a Boolean category .
Games for Dependent Types
We present a model of dependent type theory ( DTT ) with Pi- , 1- , Sigma- and intensional Id - types , which is based on a slight variation of the category of AJM - games and history - free winning strategies . The model satisfies Streicher 's criteria of intensionality and refutes function extensionality . The principle of uniqueness of identity proofs is satisfied . We show it contains a submodel as a full subcategory which gives a faithful model of DTT with Pi- , 1- , Sigma- and intensional Id - types and , additionally , finite inductive type families . This smaller model is fully ( and faithfully ) complete with respect to the syntax at the type hierarchy built without Id - types , as well as at the class of types where we allow for one strictly positive occurrence of an Id - type . Definability for the full type hierarchy with Id - types remains to be investigated .
Coalgebraic completeness - via - canonicity for distributive substructural logics
We prove strong completeness of a range of substructural logics with respect to a natural poset - based relational semantics using a coalgebraic version of completeness - via - canonicity . By formalizing the problem in the language of coalgebraic logics , we develop a modular theory which covers a wide variety of different logics under a single framework , and lends itself to further extensions . Moreover , we believe that the coalgebraic framework provides a systematic and principled way to study the relationship between resource models on the semantics side , and substructural logics on the syntactic side .
An affine - intuitionistic system of types and effects : confluence and termination
We present an affine - intuitionistic system of types and effects which can be regarded as an extension of Barber - Plotkin Dual Intuitionistic Linear Logic to multi - threaded programs with effects . In the system , dynamically generated values such as references or channels are abstracted into a finite set of regions . We introduce a discipline of region usage that entails the confluence ( and hence determinacy ) of the typable programs . Further , we show that a discipline of region stratification guarantees termination .
A study of set - sharing analysis via cliques
We study the problem of efficient , scalable set - sharing analysis of logic programs . We use the idea of representing sharing information as a pair of abstract substitutions , one of which is a worst - case sharing representation called a clique set , which was previously proposed for the case of inferring pair - sharing . We use the clique - set representation for ( 1 ) inferring actual set - sharing information , and ( 2 ) analysis within a top - down framework . In particular , we define the abstract functions required by standard top - down analyses , both for sharing alone and also for the case of including freeness in addition to sharing . Our experimental evaluation supports the conclusion that , for inferring set - sharing , as it was the case for inferring pair - sharing , precision losses are limited , while useful efficiency gains are obtained . At the limit , the clique - set representation allowed analyzing some programs that exceeded memory capacity using classical sharing representations .
A Coinductive Calculus for Asynchronous Side - effecting Processes
We present an abstract framework for concurrent processes in which atomic steps have generic side effects , handled according to the principle of monadic encapsulation of effects . Processes in this framework are potentially infinite resumptions , modelled using final coalgebras over the monadic base . As a calculus for such processes , we introduce a concurrent extension of Moggi 's monadic metalanguage of effects . We establish soundness and completeness of a natural equational axiomatisation of this calculus . Moreover , we identify a corecursion scheme that is explicitly definable over the base language and provides flexible expressive means for the definition of new operators on processes , such as parallel composition . As a worked example , we prove the safety of a generic mutual exclusion scheme using a verification logic built on top of the equational calculus .
Symmetry Breaking for Distributed Multi - Context Systems
Heterogeneous nonmonotonic multi - context systems ( MCS ) permit different logics to be used in different contexts , and link them via bridge rules . We investigate the role of symmetry detection and symmetry breaking in such systems to eliminate symmetric parts of the search space and , thereby , simplify the evaluation process . We propose a distributed algorithm that takes a local stance , i.e. , computes independently the partial symmetries of a context and , in order to construct potential symmetries of the whole , combines them with those partial symmetries returned by neighbouring contexts . We prove the correctness of our methods . We instantiate such symmetry detection and symmetry breaking in a multi - context system with contexts that use answer set programs , and demonstrate computational benefit on some recently proposed benchmarks .
Trees over Infinite Structures and Path Logics with Synchronization
We provide decidability and undecidability results on the model - checking problem for infinite tree structures . These tree structures are built from sequences of elements of infinite relational structures . More precisely , we deal with the tree iteration of a relational structure M in the sense of Shelah - Stupp . In contrast to classical results where model - checking is shown decidable for MSO - logic , we show decidability of the tree model - checking problem for logics that allow only path quantifiers and chain quantifiers ( where chains are subsets of paths ) , as they appear in branching time logics ; however , at the same time the tree is enriched by the equal - level relation ( which holds between vertices u , v if they are on the same tree level ) . We separate cleanly the tree logic from the logic used for expressing properties of the underlying structure M. We illustrate the scope of the decidability results by showing that two slight extensions of the framework lead to undecidability . In particular , this applies to the ( stronger ) tree iteration in the sense of Muchnik - Walukiewicz .
A coinductive semantics of the Unlimited Register Machine
We exploit ( co)inductive specifications and proofs to approach the evaluation of low - level programs for the Unlimited Register Machine ( URM ) within the Coq system , a proof assistant based on the Calculus of ( Co)Inductive Constructions type theory . Our formalization allows us to certify the implementation of partial functions , thus it can be regarded as a first step towards the development of a workbench for the formal analysis and verification of both converging and diverging computations .
A Probabilistic Temporal Logic with Frequency Operators and Its Model Checking
Probabilistic Computation Tree Logic ( PCTL ) and Continuous Stochastic Logic ( CSL ) are often used to describe specifications of probabilistic properties for discrete time and continuous time , respectively . In PCTL and CSL , the possibility of executions satisfying some temporal properties can be quantitatively represented by the probabilistic extension of the path quantifiers in their basic Computation Tree Logic ( CTL ) , however , path formulae of them are expressed via the same operators in CTL . For this reason , both of them can not represent formulae with quantitative temporal properties , such as those of the form " some properties hold to more than 80% of time points ( in a certain bounded interval ) on the path . " In this paper , we introduce a new temporal operator which expressed the notion of frequency of events , and define probabilistic frequency temporal logic ( PFTL ) based on CTL\star . As a result , we can easily represent the temporal properties of behavior in probabilistic systems . However , it is difficult to develop a model checker for the full PFTL , due to rich expressiveness . Accordingly , we develop a model - checking algorithm for the CTL - like fragment of PFTL against finite - state Markov chains , and an approximate model - checking algorithm for the bounded Linear Temporal Logic ( LTL ) -like fragment of PFTL against countable - state Markov chains .
On paths - based criteria for polynomial time complexity in proof - nets
Girard 's Light linear logic ( LLL ) characterized polynomial time in the proof - as - program paradigm with a bound on cut elimination . This logic relied on a stratification principle and a " one - door " principle which were generalized later respectively in the systems L^4 and L^3a . Each system was brought with its own complex proof of Ptime soundness . In this paper we propose a broad sufficient criterion for Ptime soundness for linear logic subsystems , based on the study of paths inside the proof - nets , which factorizes proofs of soundness of existing systems and may be used for future systems . As an additional gain , our bound stands for any reduction strategy whereas most bounds in the literature only stand for a particular strategy .
A Ghost at $ o_1 $
In the final chain of the countable powerset functor , we show that the set at index $ \omega_1 $ , regarded as a transition system , is not strongly extensional because it contains a " ghost " element that has no successor even though its component at index 1 is nonempty .
A Note on the Topologicity of Quantale - Valued Topological Spaces
For a quantale $ \sf V$ , the category $ \sf V\text{-}{\bf Top}$ of $ \sf V$-valued topological spaces may be introduced as a full subcategory of those $ \sf V$-valued closure spaces whose closure operation preserves finite joins . In generalization of Barr 's characterization of topological spaces as the lax algebras of a lax extension of the ultrafilter monad from maps to relations of sets , for $ \sf V$ completely distributive , $ \sf V$-topological spaces have recently been shown to be characterizable by a lax extension of the ultrafilter monad to $ \sf V$-valued relations . As a consequence , $ \sf V\text{-}{\bf Top}$ is seen to be a topological category over $ \bf Set$ , provided that $ \sf V$ is completely distributive . In this paper we give a choice - free proof that $ \sf V\text{-}{\bf Top}$ is a topological category over $ \bf Set$ under the considerably milder provision that $ \sf V$ be a spatial coframe . When $ \sf V$ is a continuous lattice , that provision yields complete distributivity of $ \sf V$ in the constructive sense , hence also in the ordinary sense whenever the axiom of choice is granted .
Parameterized Verification of Safety Properties in Ad Hoc Network Protocols
We summarize the main results proved in recent work on the parameterized verification of safety properties for ad hoc network protocols . We consider a model in which the communication topology of a network is represented as a graph . Nodes represent states of individual processes . Adjacent nodes represent single - hop neighbors . Processes are finite state automata that communicate via selective broadcast messages . Reception of a broadcast is restricted to single - hop neighbors . For this model we consider a decision problem that can be expressed as the verification of the existence of an initial topology in which the execution of the protocol can lead to a configuration with at least one node in a certain state . The decision problem is parametric both on the size and on the form of the communication topology of the initial configurations . We draw a complete picture of the decidability and complexity boundaries of this problem according to various assumptions on the possible topologies .
Towards reduction of Paradigm coordination models
The coordination modelling language Paradigm addresses collaboration between components in terms of dynamic constraints . Within a Paradigm model , component dynamics are consistently specified at a detailed and a global level of abstraction . To enable automated verification of Paradigm models , a translation of Paradigm into process algebra has been defined in previous work . In this paper we investigate , guided by a client - server example , reduction of Paradigm models based on a notion of global inertness . Representation of Paradigm models as process algebraic specifications helps to establish a property - preserving equivalence relation between the original and the reduced Paradigm model . Experiments indicate that in this way larger Paradigm models can be analyzed .
Formal Component - Based Semantics
One of the proposed solutions for improving the scalability of semantics of programming languages is Component - Based Semantics , introduced by Peter D. Mosses . It is expected that this framework can also be used effectively for modular meta theoretic reasoning . This paper presents a formalization of Component - Based Semantics in the theorem prover Coq . It is based on Modular SOS , a variant of SOS , and makes essential use of dependent types , while profiting from type classes . This formalization constitutes a contribution towards modular meta theoretic formalizations in theorem provers . As a small example , a modular proof of determinism of a mini - language is developed .
Axiomatizing GSOS with Predicates
In this paper , we introduce an extension of the GSOS rule format with predicates such as termination , convergence and divergence . For this format we generalize the technique proposed by Aceto , Bloom and Vaandrager for the automatic generation of ground - complete axiomatizations of bisimilarity over GSOS systems . Our procedure is implemented in a tool that receives SOS specifications as input and derives the corresponding axiomatizations automatically . This paves the way to checking strong bisimilarity over process terms by means of theorem - proving techniques .
Regular Expression Matching and Operational Semantics
Many programming languages and tools , ranging from grep to the Java String library , contain regular expression matchers . Rather than first translating a regular expression into a deterministic finite automaton , such implementations typically match the regular expression on the fly . Thus they can be seen as virtual machines interpreting the regular expression much as if it were a program with some non - deterministic constructs such as the Kleene star . We formalize this implementation technique for regular expression matching using operational semantics . Specifically , we derive a series of abstract machines , moving from the abstract definition of matching to increasingly realistic machines . First a continuation is added to the operational semantics to describe what remains to be matched after the current expression . Next , we represent the expression as a data structure using pointers , which enables redundant searches to be eliminated via testing for pointer equality . From there , we arrive both at Thompson 's lockstep construction and a machine that performs some operations in parallel , suitable for implementation on a large number of cores , such as a GPU . We formalize the parallel machine using process algebra and report some preliminary experiments with an implementation on a graphics processor using CUDA .
A Proof Carrying Code Framework for Inlined Reference Monitors in Java Bytecode
We propose a light - weight approach for certification of monitor inlining for sequential Java bytecode using proof - carrying code . The goal is to enable the use of monitoring for quality assurance at development time , while minimizing the need for post - shipping code rewrites as well as changes to the end - host TCB . Standard automaton - based security policies express constraints on allowed API call / return sequences . Proofs are represented as JML - style program annotations . This is adequate in our case as all proofs generated in our framework are recognized in time polynomial in the size of the program . Policy adherence is proved by comparing the transitions of an inlined monitor with those of a trusted " ghost " monitor represented using JML - style annotations . At time of receiving a program with proof annotations , it is sufficient for the receiver to plug in its own trusted ghost monitor and check the resulting verification conditions , to verify that inlining has been performed correctly , of the correct policy . We have proved correctness of the approach at the Java bytecode level and formalized the proof of soundness in Coq . An implementation , including an application loader running on a mobile device , is available , and we conclude by giving benchmarks for two sample applications .
Numerically Representing A Stochastic Process Algebra
The syntactic nature and compositionality characteristic of stochastic process algebras make models to be easily understood by human beings , but not convenient for machines as well as people to directly carry out mathematical analysis and stochastic simulation . This paper presents a numerical representation schema for the stochastic process algebra PEPA , which can provide a platform to directly and conveniently employ a variety of computational approaches to both qualitatively and quantitatively analyse the models . Moreover , these approaches developed on the basis of the schema are demonstrated and discussed . In particular , algorithms for automatically deriving the schema from a general PEPA model and simulating the model based on the derived schema to derive performance measures are presented .
Computing in Coq with Infinite Algebraic Data Structures
Computational content encoded into constructive type theory proofs can be used to make computing experiments over concrete data structures . In this paper , we explore this possibility when working in Coq with chain complexes of infinite type ( that is to say , generated by infinite sets ) as a part of the formalization of a hierarchy of homological algebra structures .
Interface Building for Software by Modular Three - Valued Abstraction Refinement
Verification of software systems is a very hard problem due to the large size of program state - space . The traditional techniques ( like model checking ) do not scale ; since they include the whole state - space by inlining the library function codes . Current research avoids these problem by creating a lightweight representation of the library in form of an " interface graph " ( call sequence graph ) . In this paper we introduce a new algorithm to compute a safe , permissive interface graph for C - type functions . In this modular analysis , each function transition is summarized following three - valued abstraction semantics . There are two kinds of abstraction used here . The global abstraction contains predicates over global variables only ; however the local abstraction inside each function may also contain the local variables . The abstract summary needs refinement to guarantee safety and permissiveness . We have implemented the algorithms in TICC tool and compared this algorithm with some related interface generation algorithms . We also discuss the application of interface as an offline test - suite . We create an interface from the model program ( specification ) and the interface will act as a test - suite for the new implementation - under - test ( IUT ) .
Smart matching
One of the most annoying aspects in the formalization of mathematics is the need of transforming notions to match a given , existing result . This kind of transformations , often based on a conspicuous background knowledge in the given scientific domain ( mostly expressed in the form of equalities or isomorphisms ) , are usually implicit in the mathematical discourse , and it would be highly desirable to obtain a similar behavior in interactive provers . The paper describes the superposition - based implementation of this feature inside the Matita interactive theorem prover , focusing in particular on the so called smart application tactic , supporting smart matching between a goal and a given result .
The Heap Lambda Machine
This paper introduces a new machine architecture for evaluating lambda expressions using the normal - order reduction , which guarantees that every lambda expression will be evaluated if the expression has its normal form and the system has enough memory . The architecture considered here operates using heap memory only . Lambda expressions are represented as graphs , and all algorithms used in the processing unit of this machine are non - recursive .
Higher Dimensional Modal Logic
Higher dimensional automata ( HDA ) are a model of concurrency that can express most of the traditional partial order models like Mazurkiewicz traces , pomsets , event structures , or Petri nets . Modal logics , interpreted over Kripke structures , are the logics for reasoning about sequential behavior and interleaved concurrency . Modal logic is a well behaved subset of first - order logic ; many variants of modal logic are decidable . However , there are no modal - like logics for the more expressive HDA models . In this paper we introduce and investigate a modal logic over HDAs which incorporates two modalities for reasoning about " during " and " after " . We prove that this general higher dimensional modal logic ( HDML ) is decidable and we define an axiomatic system for it . We also show how , when the HDA model is restricted to Kripke structures , a syntactic restriction of HDML becomes the standard modal logic . Then we isolate the class of HDAs that encode Mazurkiewicz traces and show how HDML , with natural definitions of corresponding Until operators , can be restricted to LTrL ( the linear time temporal logic over Mazurkiewicz traces ) or the branching time ISTL . We also study the expressiveness of the basic HDML language wrt . bisimulations and conclude that HDML captures the split - bisimulation .
Formalization of Complex Vectors in Higher - Order Logic
Complex vector analysis is widely used to analyze continuous systems in many disciplines , including physics and engineering . In this paper , we present a higher - order - logic formalization of the complex vector space to facilitate conducting this analysis within the sound core of a theorem prover : HOL Light . Our definition of complex vector builds upon the definitions of complex numbers and real vectors . This extension allows us to extensively benefit from the already verified theorems based on complex analysis and real vector analysis . To show the practical usefulness of our library we adopt it to formalize electromagnetic fields and to prove the law of reflection for the planar waves .
Intuitionistic PUC - Logic for Constructive Counterfactuals
We present the intuitionistic version of PUC - Logic . After that , we present a constructive approach to Lewis ' counterfactual abstraction to show that it does not require the classical absurd rule .
Non - termination using Regular Languages
We describe a method for proving non - looping non - termination , that is , of term rewriting systems that do not admit looping reductions . As certificates of non - termination , we employ regular ( tree ) automata .
Towards an Effective Decision Procedure for LTL formulas with Constraints
This paper presents an ongoing work that is part of a more wide - ranging project whose final scope is to define a method to validate LTL formulas w.r.t . a program written in the timed concurrent constraint language tccp , which is a logic concurrent constraint language based on the concurrent constraint paradigm of Saraswat . Some inherent notions to tccp processes are non - determinism , dealing with partial information in states and the monotonic evolution of the information . In order to check an LTL property for a process , our approach is based on the abstract diagnosis technique . The concluding step of this technique needs to check the validity of an LTL formula ( with constraints ) in an effective way . In this paper , we present a decision method for the validity of temporal logic formulas ( with constraints ) built by our abstract diagnosis technique .
Efficient Approximation of Well - Founded Justification and Well - Founded Domination ( Corrected and Extended Version )
Many native ASP solvers exploit unfounded sets to compute consequences of a logic program via some form of well - founded negation , but disregard its contrapositive , well - founded justification ( WFJ ) , due to computational cost . However , we demonstrate that this can hinder propagation of many relevant conditions such as reachability . In order to perform WFJ with low computational cost , we devise a method that approximates its consequences by computing dominators in a flowgraph , a problem for which linear - time algorithms exist . Furthermore , our method allows for additional unfounded set inference , called well - founded domination ( WFD ) . We show that the effect of WFJ and WFD can be simulated for a important classes of logic programs that include reachability . This paper is a corrected and extended version of a paper published at the 12th International Conference on Logic Programming and Nonmonotonic Reasoning ( LPNMR 2013 ) . It has been adapted to exclude Theorem 10 and its consequences , but provides all missing proofs .
Modeling and Reasoning About Wireless Networks : A Graph - based Calculus Approach
We propose a graph - based process calculus for modelling and reasoning about wireless networks with local broadcast . To study the behavioural theory of wireless networks , we develop both a reduction semantics and a labelled transition semantics . Then we derive weak barbed congruence and weak bisimilarity based on these semantics , respectively . We prove that there is a correspondence between the two semantics and weak bisimilarity implies weak barbed congruence . Some examples are given to illustrate potential applications of this calculus .
MDPs with Energy - Parity Objectives
Energy - parity objectives combine $ \omega$-regular with quantitative objectives of reward MDPs . The controller needs to avoid to run out of energy while satisfying a parity objective . We refute the common belief that , if an energy - parity objective holds almost - surely , then this can be realised by some finite memory strategy . We provide a surprisingly simple counterexample that only uses coB\"uchi conditions . We introduce the new class of bounded ( energy ) storage objectives that , when combined with parity objectives , preserve the finite memory property . Based on these , we show that almost - sure and limit - sure energy - parity objectives , as well as almost - sure and limit - sure storage parity objectives , are in $ \mathit{NP}\cap \mathit{coNP}$ and can be solved in pseudo - polynomial time for energy - parity MDPs .
Automatic verification and interactive theorem proving
Automatic verification deals with the validation by means of computers of correctness certificates . The related tools , usually called proof assistants or interactive provers , provide an interactive environment for the creation of formal certificates whose correctness can be assessed in a purely automatic way . Such systems have applications both in mathematics , where certificates are proofs of theorems , and in computer science , where certificates testify the correctness of a given software with respect to its specification .
Towards a Decidable LogicWeb via Length - Bounded Derivations
LogicWeb has traditionally lacked devices for dealing with intractable queries . We address this limitation by adopting length - bounded inference , a form of approximate reasoning . A { \it length - bounded } inference is of the form $ prov(P , G , n)$ which is a success if a query $ G$ can be proved from the web page $ P$ { \it within } $ n$ proof steps . It thus makes LogicWeb decidable and more tractable .
A Calculus of Cyber - Physical Systems
We propose a hybrid process calculus for modelling and reasoning on cyber - physical systems ( CPS{s } ) . The dynamics of the calculus is expressed in terms of a labelled transition system in the SOS style of Plotkin . This is used to define a bisimulation - based behavioural semantics which support compositional reasonings . Finally , we prove run - time properties and system equalities for a non - trivial case study .
A new rule for almost - certain termination of probabilistic- and demonic programs
Extending our own and others ' earlier approaches to reasoning about termination of probabilistic programs , we propose and prove a new rule for termination with probability one , also known as " almost - certain termination " . The rule uses both ( non - strict ) super martingales and guarantees of progress , together , and it seems to cover significant cases that earlier methods do not . In particular , it suffices for termination of the unbounded symmetric random walk in both one- and two dimensions : for the first , we give a proof ; for the second , we use a theorem of Foster to argue that a proof exists . Non - determinism ( i.e. demonic choice ) is supported ; but we do currently restrict to discrete distributions .
On the Complexity of the Quantified Bit - Vector Arithmetic with Binary Encoded Bit - Widths
In this paper , we prove the precise computational complexity of deciding satisfiability of first - order quantified formulas over the theory of fixed - size bit - vectors . This problem is known to be solvable in exponential space and to be NEXPTIME - hard . We show that this problem is complete for the complexity class AEXP(poly ) -- the class of problems decidable by an alternating Turing machine using exponential space and polynomial number of alternations between existential and universal states .
Mixed powerdomains for probability and nondeterminism
We consider mixed powerdomains combining ordinary nondeterminism and probabilistic nondeterminism . We characterise them as free algebras for suitable ( in)equation - al theories ; we establish functional representation theorems ; and we show equivalencies between state transformers and appropriately healthy predicate transformers . The extended nonnegative reals serve as ` truth - values ' . As usual with powerdomains , everything comes in three flavours : lower , upper , and order - convex . The powerdomains are suitable convex sets of subprobability valuations , corresponding to resolving nondeterministic choice before probabilistic choice . Algebraically this corresponds to the probabilistic choice operator distributing over the nondeterministic choice operator . ( An alternative approach to combining the two forms of nondeterminism would be to resolve probabilistic choice first , arriving at a domain - theoretic version of random sets . However , as we also show , the algebraic approach then runs into difficulties . ) Rather than working directly with valuations , we take a domain - theoretic functional - analytic approach , employing domain - theoretic abstract convex sets called Kegelspitzen ; these are equivalent to the abstract probabilistic algebras of Graham and Jones , but are more convenient to work with . So we define power Kegelspitzen , and consider free algebras , functional representations , and predicate transformers . To do so we make use of previous work on domain - theoretic cones ( d - cones ) , with the bridge between the two of them being provided by a free d - cone construction on Kegelspitzen .
Resolution Simulates Ordered Binary Decision Diagrams for Formulas in Conjunctive Normal Form
A classical question of propositional logic is one of the shortest proof of a tautology . A related fundamental problem is to determine the relative efficiency of standard proof systems , where the relative complexity is measured using the notion of polynomial simulation . Presently , the state - of - the - art satisfiability algorithms are based on resolution in combination with search . An Ordered Binary Decision Diagram ( OBDD ) is a data structure that is used to represent Boolean functions . Groote and Zantema have proved that there is exponential separation between resolution and a proof system based on limited OBDD derivations . However , formal comparison of these methods is not straightforward because OBDDs work on arbitrary formulas , whereas resolution can only be applied to formulas in Conjunctive Normal Form ( CNFs ) . Contrary to popular belief , we argue that resolution simulates OBDDs polynomially if we limit both to CNFs and thus answer negatively the open question of Groote and Zantema whether there exist unsatisfiable CNFs having polynomial OBDD refutations and requiring exponentially long resolution refutations .
Finding AND - OR Hierarchies in Workflow Nets
This paper presents the notion of AND - OR reduction , which reduces a WF net to a smaller net by iteratively contracting certain well - formed subnets into single nodes until no more such contractions are possible . This reduction can reveal the hierarchical structure of a WF net , and since it preserves certain semantical properties such as soundness , it can help with analysing and understanding why a WF net is sound or not . The reduction can also be used to verify if a WF net is an AND - OR net . This class of WF nets was introduced in earlier work , and arguably describes nets that follow good hierarchical design principles . It is shown that the AND - OR reduction is confluent up to isomorphism , which means that despite the inherent non - determinism that comes from the choice of subnets that are contracted , the final result of the reduction is always the same up to the choice of the identity of the nodes . Based on this result , a polynomial - time algorithm is presented that computes this unique result of the AND - OR reduction . Finally , it is shown how this algorithm can be used to verify if a WF net is an AND - OR net .
Type homogeneity is not a restriction for safe recursion schemes
Knapik et al . introduced the safety restriction which constrains both the types and syntax of the production rules defining a higher - order recursion scheme . This restriction gives rise to an equi - expressivity result between order - n pushdown automata and order - n safe recursion schemes , when such devices are used as tree generators . We show that the typing constraint of safety , called homogeneity , is unnecessary in the sense that imposing the syntactic restriction alone is sufficient to prove the equi - expressivity result for trees .
Constraint Satisfaction Problems over semilattice block Mal'tsev algebras
There are two well known types of algorithms for solving CSPs : local propagation and generating a basis of the solution space . For several years the focus of the CSP research has been on ` hybrid ' algorithms that somehow combine the two approaches . In this paper we present a new method of such hybridization that allows us to solve certain CSPs that has been out of reach for a quite a while . We consider these method on a fairly restricted class of CSPs given by algebras we will call semilattice block Mal'tsev . An algebra A is called semilattice block Mal'tsev if it has a binary operation f , a ternary operation m , and a congruence s such that the quotient A / s with operation $ f$ is a semilattice , $ f$ is a projection on every block of s , and every block of s is a Mal'tsev algebra with Mal'tsev operation m. We show that the constraint satisfaction problem over a semilattice block Mal'tsev algebra is solvable in polynomial time .
On the Complexity of Temporal - Logic Path Checking
Given a formula in a temporal logic such as LTL or MTL , a fundamental problem is the complexity of evaluating the formula on a given finite word . For LTL , the complexity of this task was recently shown to be in NC . In this paper , we present an NC algorithm for MTL , a quantitative ( or metric ) extension of LTL , and give an NCC algorithm for UTL , the unary fragment of LTL . At the time of writing , MTL is the most expressive logic with an NC path - checking algorithm , and UTL is the most expressive fragment of LTL with a more efficient path - checking algorithm than for full LTL ( subject to standard complexity - theoretic assumptions ) . We then establish a connection between LTL path checking and planar circuits , which we exploit to show that any further progress in determining the precise complexity of LTL path checking would immediately entail more efficient evaluation algorithms than are known for a certain class of planar circuits . The connection further implies that the complexity of LTL path checking depends on the Boolean connectives allowed : adding Boolean exclusive or yields a temporal logic with P - complete path - checking problem .
What 's Decidable About Sequences ?
We present a first - order theory of sequences with integer elements , Presburger arithmetic , and regular constraints , which can model significant properties of data structures such as arrays and lists . We give a decision procedure for the quantifier - free fragment , based on an encoding into the first - order theory of concatenation ; the procedure has PSPACE complexity . The quantifier - free fragment of the theory of sequences can express properties such as sortedness and injectivity , as well as Boolean combinations of periodic and arithmetic facts relating the elements of the sequence and their positions ( e.g. , " for all even i 's , the element at position i has value i+3 or 2i " ) . The resulting expressive power is orthogonal to that of the most expressive decidable logics for arrays . Some examples demonstrate that the fragment is also suitable to reason about sequence - manipulating programs within the standard framework of axiomatic semantics .
Satisfiability of CTL * with constraints
We show that satisfiability for CTL * with equality- , order- , and modulo - constraints over Z is decidable . Previously , decidability was only known for certain fragments of CTL * , e.g. , the existential and positive fragments and EF .
Hennessy - Milner Logic with Greatest Fixed Points as a Complete Behavioural Specification Theory
There are two fundamentally different approaches to specifying and verifying properties of systems . The logical approach makes use of specifications given as formulae of temporal or modal logics and relies on efficient model checking algorithms ; the behavioural approach exploits various equivalence or refinement checking methods , provided the specifications are given in the same formalism as implementations . In this paper we provide translations between the logical formalism of Hennessy - Milner logic with greatest fixed points and the behavioural formalism of disjunctive modal transition systems . We also introduce a new operation of quotient for the above equivalent formalisms , which is adjoint to structural composition and allows synthesis of missing specifications from partial implementations . This is a substantial generalisation of the quotient for deterministic modal transition systems defined in earlier papers .
Certified HLints with Isabelle / HOLCF - Prelude
We present the HOLCF - Prelude , a formalization of a large part of Haskell 's standard prelude in Isabelle / HOLCF . Applying this formalization to the hints suggested by HLint allows us to certify them formally .
Extending E Prover with Similarity Based Clause Selection Strategies
E prover is a state - of - the - art theorem prover for first - order logic with equality . E prover is built around a saturation loop , where new clauses are derived by inference rules from previously derived clauses . Selection of clauses for the inference provides the main source of non - determinism and an important choice - point of the loop where the right choice can dramatically influence the proof search . In this work we extend E Prover with several new clause selection strategies based on similarity of a clause with the conjecture . In particular , clauses which are more related to the conjecture are preferred . We implement different strategies that define the relationship with a conjecture in different ways . We provide an implementation of the proposed selection strategies and we evaluate their efficiency on an extensive benchmark set .
Fair Simulation for Nondeterministic and Probabilistic Buechi Automata : a Coalgebraic Perspective
Notions of \emph{simulation } , among other uses , provide a computationally tractable and sound ( but not necessarily complete ) proof method for language inclusion . They have been comprehensively studied by Lynch and Vaandrager for nondeterministic and timed systems ; for \emph{B\"{u}chi } automata the notion of \emph{fair simulation } has been introduced by Henzinger , Kupferman and Rajamani . We contribute to generalization of fair simulation in two different directions : one for nondeterministic \emph{tree } automata previously studied by Bomhard ; and the other for \emph{probabilistic } word automata with finite state spaces , both under the B\"{u}chi acceptance condition . The former nondeterministic definition is formulated in terms of systems of fixed - point equations , hence is readily translated to parity games and then amenable to Jurdzi\'{n}ski 's algorithm ; the latter probabilistic definition bears a strong ranking - function flavor . These two different - looking definitions are derived from one source , namely our \emph{coalgebraic } modeling of B\"{u}chi automata . Based on these coalgebraic observations , we also prove their soundness : a simulation indeed witnesses language inclusion .
Simple strategies for Banach - Mazur games and fairly correct systems
In 2006 , Varacca and V\"olzer proved that on finite graphs , omega - regular large sets coincide with omega - regular sets of probability 1 , by using the existence of positional strategies in the related Banach - Mazur games . Motivated by this result , we try to understand relations between sets of probability 1 and various notions of simple strategies ( including those introduced in a recent paper of Gr\"adel and Lessenich ) . Then , we introduce a generalisation of the classical Banach - Mazur game and in particular , a probabilistic version whose goal is to characterise sets of probability 1 ( as classical Banach - Mazur games characterise large sets ) . We obtain a determinacy result for these games , when the winning set is a countable intersection of open sets .
Bisimulation - Based Comparisons for Interpretations in Description Logics
We study comparisons between interpretations in description logics with respect to " logical consequences " of the form of semi - positive concepts ( like semi - positive concept assertions ) . Such comparisons are characterized by conditions similar to the ones of bisimulations . The simplest among the considered logics is a variant of PDL ( propositional dynamic logic ) . The others extend that logic with inverse roles , nominals , quantified number restrictions , the universal role , and/or the concept constructor for expressing the local reflexivity of a role . The studied problems are : preservation of semi - positive concepts with respect to comparisons , the Hennessy - Milner property for comparisons , and minimization of interpretations that preserves semi - positive concepts .
On Refinements of Boolean and Parametric Modal Transition Systems
We consider the extensions of modal transition systems ( MTS ) , namely Boolean MTS and parametric MTS and we investigate the refinement problems over both classes . Firstly , we reduce the problem of modal refinement over both classes to a problem solvable by a QBF solver and provide experimental results showing our technique scales well . Secondly , we extend the algorithm for thorough refinement of MTS providing better complexity then via reductions to previously studied problems . Finally , we investigate the relationship between modal and thorough refinement on the two classes and show how the thorough refinement can be approximated by the modal refinement .
On the Complexity of Verifying Regular Properties on Flat Counter Systems
Among the approximation methods for the verification of counter systems , one of them consists in model - checking their flat unfoldings . Unfortunately , the complexity characterization of model - checking problems for such operational models is not always well studied except for reachability queries or for Past LTL . In this paper , we characterize the complexity of model - checking problems on flat counter systems for the specification languages including first - order logic , linear mu - calculus , infinite automata , and related formalisms . Our results span different complexity classes ( mainly from PTime to PSpace ) and they apply to languages in which arithmetical constraints on counter values are systematically allowed . As far as the proof techniques are concerned , we provide a uniform approach that focuses on the main issues .
Improved Static Analysis of Parameterised Boolean Equation Systems using Control Flow Reconstruction
We present a sound static analysis technique for fighting the combinatorial explosion of parameterised Boolean equation systems ( PBESs ) . These essentially are systems of mutually recursive fixed point equations ranging over first - order logic formulae . Our method detects parameters that are not live by analysing a control flow graph of a PBES , and it subsequently eliminates such parameters . We show that a naive approach to constructing a control flow graph , needed for the analysis , may suffer from an exponential blow - up , and we define an approximate analysis that avoids this problem . The effectiveness of our techniques is evaluated using a number of case studies .
Unifying the Linear Time - Branching Time Spectrum of Process Semantics
Van Glabbeek 's linear time - branching time spectrum is one of the most relevant work on comparative study on process semantics , in which semantics are partially ordered by their discrimination power . In this paper we bring forward a refinement of this classification and show how the process semantics can be dealt with in a uniform way : based on the very natural concept of constrained simulation we show how we can classify the spectrum in layers ; for the families lying in the same layer we show how to obtain in a generic way equational , observational , logical and operational characterizations ; relations among layers are also very natural and differences just stem from the constraint imposed on the simulations that rule the layers . Our methodology also shows how to achieve a uniform treatment of semantic preorders and equivalences .
Sequent Calculi with procedure calls
In this paper , we introduce two focussed sequent calculi , LKp(T ) and LK+(T ) , that are based on Miller - Liang 's LKF system for polarised classical logic . The novelty is that those sequent calculi integrate the possibility to call a decision procedure for some background theory T , and the possibility to polarise literals " on the fly " during proof - search . These features are used in our other works to simulate the DPLL(T ) procedure as proof - search in the extension of LKp(T ) with a cut - rule . In this report we therefore prove cut - elimination in LKp(T ) . Contrary to what happens in the empty theory , the polarity of literals affects the provability of formulae in presence of a theory T. On the other hand , changing the polarities of connectives does not change the provability of formulae , only the shape of proofs . In order to prove this , we introduce a second sequent calculus , LK+(T ) that extends LKp(T ) with a relaxed focussing discipline , but we then show an encoding of LK+(T ) back into the more restrictive system LK(T ) . We then prove completeness of LKp(T ) ( and therefore of LK+(T ) ) with respect to first - order reasoning modulo the ground propositional lemmas of the background theory T .
A simple sequent calculus for nominal logic
Nominal logic is a variant of first - order logic that provides support for reasoning about bound names in abstract syntax . A key feature of nominal logic is the new - quantifier , which quantifies over fresh names ( names not appearing in any values considered so far ) . Previous attempts have been made to develop convenient rules for reasoning with the new - quantifier , but we argue that none of these attempts is completely satisfactory . In this article we develop a new sequent calculus for nominal logic in which the rules for the new- quantifier are much simpler than in previous attempts . We also prove several structural and metatheoretic properties , including cut - elimination , consistency , and equivalence to Pitts ' axiomatization of nominal logic .
Polarizing Double Negation Translations
Double - negation translations are used to encode and decode classical proofs in intuitionistic logic . We show that , in the cut - free fragment , we can simplify the translations and introduce fewer negations . To achieve this , we consider the polarization of the formul{\ae } { } and adapt those translation to the different connectives and quantifiers . We show that the embedding results still hold , using a customized version of the focused classical sequent calculus . We also prove the latter equivalent to more usual versions of the sequent calculus . This polarization process allows lighter embeddings , and sheds some light on the relationship between intuitionistic and classical connectives .
Notes on axiomatising Hurkens 's Paradox
An axiomatisation of Hurkens 's paradox in dependent type theory is given without assuming any impredicative feature of said type theory .
Forward Invariant Cuts to Simplify Proofs of Safety
The use of deductive techniques , such as theorem provers , has several advantages in safety verification of hybrid sys- tems ; however , state - of - the - art theorem provers require ex- tensive manual intervention . Furthermore , there is often a gap between the type of assistance that a theorem prover requires to make progress on a proof task and the assis- tance that a system designer is able to provide . This paper presents an extension to KeYmaera , a deductive verification tool for differential dynamic logic ; the new technique allows local reasoning using system designer intuition about per- formance within particular modes as part of a proof task . Our approach allows the theorem prover to leverage for- ward invariants , discovered using numerical techniques , as part of a proof of safety . We introduce a new inference rule into the proof calculus of KeYmaera , the forward invariant cut rule , and we present a methodology to discover useful forward invariants , which are then used with the new cut rule to complete verification tasks . We demonstrate how our new approach can be used to complete verification tasks that lie out of the reach of existing deductive approaches us- ing several examples , including one involving an automotive powertrain control system .
Finite - Degree Predicates and Two - Variable First - Order Logic
We consider two - variable first - order logic on finite words with a fixed number of quantifier alternations . We show that all languages with a neutral letter definable using the order and finite - degree predicates are also definable with the order predicate only . From this result we derive the separation of the alternation hierarchy of two - variable logic on this signature .
An Improved Decision Procedure for Linear Time Mu - Calculus
An improved Present Future form ( PF form ) for linear time $ \mu$-calculus ( $ \nu$TL ) is presented in this paper . In particular , the future part of the new version turns into the conjunction of elements in the closure of a formula . We show that every closed $ \nu$TL formula can be transformed into the new PF form . Additionally , based on the PF form , an algorithm for constructing Present Future form Graph ( PFG ) , which can be utilized to describe models of a formula , is given . Further , an intuitive and efficient decision procedure for checking satisfiability of the guarded fragment of $ \nu$TL formulas based on PFG is proposed and implemented in C++ . The new decision procedure has the best time complexity over the existing ones despite the cost of exponential space . Finally , a PFG - based model checking approach for $ \nu$TL is discussed where a counterexample can be obtained visually when a model violates a property .
On the complexity of probabilistic justification logic
The logic PJ is a probabilistic logic over the basic justification logic J. In this paper we establish upper and lower bounds for the complexity of PJ . The main result of the paper is that the complexity of the logic PJ remains the same as the complexity of the logic J.
Putting Logic - Based Distributed Systems on Stable Grounds
In the Declarative Networking paradigm , Datalog - like languages are used to express distributed computations . Whereas recently formal operational semantics for these languages have been developed , a corresponding declarative semantics has been lacking so far . The challenge is to capture precisely the amount of nondeterminism that is inherent to distributed computations due to concurrency , networking delays , and asynchronous communication . This paper shows how a declarative , model - based semantics can be obtained by simply using the well - known stable model semantics for Datalog with negation . We show that the model - based semantics matches previously proposed formal operational semantics .
On absorption in semigroups and $ n$-ary semigroups
The notion of absorption was developed a few years ago by Barto and Kozik and immediately found many applications , particularly in topics related to the constraint satisfaction problem . We investigate the behavior of absorption in semigroups and n - ary semigroups ( that is , algebras with one n - ary associative operation ) . In the case of semigroups , we give a simple necessary and sufficient condition for a semigroup to be absorbed by its subsemigroup . We then proceed to n - ary semigroups , where we conjecture an analogue of this necessary and sufficient condition , and prove that the conjectured condition is indeed necessary and sufficient for B to absorb A ( where A is an n - ary semigroup and B is its n - ary subsemigroup ) in the following three cases : when A is commutative , when |A - B|=1 and when A is an idempotent ternary semigroup .
Quantitative Redundancy in Partial Implications
We survey the different properties of an intuitive notion of redundancy , as a function of the precise semantics given to the notion of partial implication . The final version of this survey will appear in the Proceedings of the Int . Conf . Formal Concept Analysis , 2015 .
Triggered Clause Pushing for IC3
We propose an improvement of the famous IC3 algorithm for model checking safety properties of finite state systems . We collect models computed by the SAT - solver during the clause propagation phase of the algorithm and use them as witnesses for why the respective clauses could not be pushed forward . It only makes sense to recheck a particular clause for pushing when its witnessing model falsifies a newly added clause . Since this trigger test is both computationally cheap and sufficiently precise , we can afford to keep clauses pushed as far as possible at all times . Experiments indicate that this strategy considerably improves IC3 's performance .
Proof search for propositional abstract separation logics via labelled sequents
Separation logics are a family of extensions of Hoare logic for reasoning about programs that mutate memory . These logics are " abstract " because they are independent of any particular concrete memory model . Their assertion languages , called propositional abstract separation logics , extend the logic of ( Boolean ) Bunched Implications ( BBI ) in various ways . We develop a modular proof theory for various propositional abstract separation logics using cut - free labelled sequent calculi . We first extend the cut - fee labelled sequent calculus for BBI of Hou et al to handle Calcagno et al 's original logic of separation algebras by adding sound rules for partial - determinism and cancellativity , while preserving cut - elimination . We prove the completeness of our calculus via a sound intermediate calculus that enables us to construct counter - models from the failure to find a proof . We then capture other propositional abstract separation logics by adding sound rules for indivisible unit and disjointness , while maintaining completeness . We present a theorem prover based on our labelled calculus for these propositional abstract separation logics .
Connection and Dispersion of Computation
This paper talk about the influence of Connection and Dispersion on Computational Complexity . And talk about the HornCNF 's connection and CNF 's dispersion , and show the difference between CNFSAT and HornSAT . First , I talk the relation between MUC decision problem and classifying the truth value assignment . Second , I define the two inner products ( " inner product " and " inner harmony " ) and talk about the influence of orthogonal and correlation to MUC . And we can not reduce MUC to Orthogonalization MUC by using HornMUC in polynomial size because HornMUC have high orthogonal of inner harmony and MUC do not . So DP is not P , and NP is not P.
On the greatest solution of equations in $ \text{CLL}_R$
It is shown that , for any equation $ X=_{RS } t_X$ in the LLTS - oriented process calculus $ \text{CLL}_R$ , if $ X$ is strongly guarded in $ t_X$ , then the recursive term $ \langle X|X = t_X \rangle$ is the greatest solution of this equation w.r.t L\"{u}ttgen and Vogler 's ready simulation .
The MSO+U theory of ( N , < ) is undecidable
We consider the logic MSO+U , which is monadic second - order logic extended with the unbounding quantifier . The unbounding quantifier is used to say that a property of finite sets holds for sets of arbitrarily large size . We prove that the logic is undecidable on infinite words , i.e. the MSO+U theory of ( N , < ) is undecidable . This settles an open problem about the logic , and improves a previous undecidability result , which used infinite trees and additional axioms from set theory .
On Counterexample Guided Quantifier Instantiation for Synthesis in CVC4
We introduce the first program synthesis engine implemented inside an SMT solver . We present an approach that extracts solution functions from unsatisfiability proofs of the negated form of synthesis conjectures . We also discuss novel counterexample - guided techniques for quantifier instantiation that we use to make finding such proofs practically feasible . A particularly important class of specifications are single - invocation properties , for which we present a dedicated algorithm . To support syntax restrictions on generated solutions , our approach can transform a solution found without restrictions into the desired syntactic form . As an alternative , we show how to use evaluation function axioms to embed syntactic restrictions into constraints over algebraic datatypes , and then use an algebraic datatype decision procedure to drive synthesis . Our experimental evaluation on syntax - guided synthesis benchmarks shows that our implementation in the CVC4 SMT solver is competitive with state - of - the - art tools for synthesis .
A survey of proof nets and matrices for substructural logics
This paper is a survey of two kinds of " compressed " proof schemes , the \emph{matrix method } and \emph{proof nets } , as applied to a variety of logics ranging along the substructural hierarchy from classical all the way down to the nonassociative Lambek system . A novel treatment of proof nets for the latter is provided . Descriptions of proof nets and matrices are given in a uniform notation based on sequents , so that the properties of the schemes for the various logics can be easily compared .
Generating Bijections between HOAS and the Natural Numbers
A provably correct bijection between higher - order abstract syntax ( HOAS ) and the natural numbers enables one to define a " not equals " relationship between terms and also to have an adequate encoding of sets of terms , and maps from one term family to another . Sets and maps are useful in many situations and are preferably provided in a library of some sort . I have released a map and set library for use with Twelf which can be used with any type for which a bijection to the natural numbers exists . Since creating such bijections is tedious and error - prone , I have created a " bijection generator " that generates such bijections automatically together with proofs of correctness , all in the context of Twelf .
Pure Type Systems without Explicit Contexts
We present an approach to type theory in which the typing judgments do not have explicit contexts . Instead of judgments of shape " Gamma |- A : B " , our systems just have judgments of shape " A : B " . A key feature is that we distinguish free and bound variables even in pseudo - terms . Specifically we give the rules of the " Pure Type System " class of type theories in this style . We prove that the typing judgments of these systems correspond in a natural way with those of Pure Type Systems as traditionally formulated . I.e. , our systems have exactly the same well - typed terms as traditional presentations of type theory . Our system can be seen as a type theory in which all type judgments share an identical , infinite , typing context that has infinitely many variables for each possible type . For this reason we call our system " Gamma_infinity " . This name means to suggest that our type judgment " A : B " should be read as " Gamma_infinity |- A : B " , with a fixed infinite type context called " Gamma_infinity " .
Representing Isabelle in LF
LF has been designed and successfully used as a meta - logical framework to represent and reason about object logics . Here we design a representation of the Isabelle logical framework in LF using the recently introduced module system for LF . The major novelty of our approach is that we can naturally represent the advanced Isabelle features of type classes and locales . Our representation of type classes relies on a feature so far lacking in the LF module system : morphism variables and abstraction over them . While conservative over the present system in terms of expressivity , this feature is needed for a representation of type classes that preserves the modular structure . Therefore , we also design the necessary extension of the LF module system .
Tableaux Modulo Theories Using Superdeduction
We propose a method that allows us to develop tableaux modulo theories using the principles of superdeduction , among which the theory is used to enrich the deduction system with new deduction rules . This method is presented in the framework of the Zenon automated theorem prover , and is applied to the set theory of the B method . This allows us to provide another prover to Atelier B , which can be used to verify B proof rules in particular . We also propose some benchmarks , in which this prover is able to automatically verify a part of the rules coming from the database maintained by Siemens IC - MOL . Finally , we describe another extension of Zenon with superdeduction , which is able to deal with any first order theory , and provide a benchmark coming from the TPTP library , which contains a large set of first order problems .
Canonicity for Cubical Type Theory
Cubical type theory is an extension of Martin - L\"of type theory recently proposed by Cohen , Coquand , M\"ortberg and the author which allows for direct manipulation of $ n$-dimensional cubes and where Voevodsky 's Univalence Axiom is provable . In this paper we prove canonicity for cubical type theory : any natural number in a context build from only name variables is judgmentally equal to a numeral . To achieve this we formulate a typed and deterministic operational semantics and employ a computability argument adapted to a presheaf - like setting .
The recursion hierarchy for PCF is strict
Let $ PCF_k$ denote the sublanguage of Plotkin 's PCF in which fixed point operators $ Y_\sigma$ are admitted only for types $ \sigma$ of level $ \leq k$. We show that the languages $ PCF_k$ form a strict hierarchy , in the sense that none of the $ Y_\sigma$ for $ \sigma$ of level $ k+1 $ are definable in $ PCF_k$ up to observational equivalence . This answers a question posed by Berger in 1999 . Our proof makes substantial use of the theory of nested sequential procedures ( also called PCF B\"ohm trees ) as expounded in the recent book of Longley and Normann .
On the likelihood of normalisation in combinatory logic
We present a quantitative basis - independent analysis of combinatory logic . Using a general argument regarding plane binary trees with labelled leaves , we generalise the results of David et al . and Bendkowski et al . to all Turing - complete combinator bases proving , inter alia , that asymptotically almost no combinator is strongly normalising nor typeable . We exploit the structure of recently discovered normal - order reduction grammars showing that for each positive $ n$ , the set of $ \mathbf{S } \mathbf{K}$-combinators reducing in $ n$ normal - order reduction steps has positive asymptotic density in the set of all combinators . Our approach is constructive , allowing us to systematically find new asymptotically significant fractions of normalising combinators . We show that the density of normalising combinators can not be less than $ 34\%$ , improving the previously best lower bound of approximately $ 3\%$. Finally , we present some super - computer experimental results , conjecturing that the density of normalising combinators is close to $ 85\%$.
Port Protocols for Deadlock - Freedom of Component Systems
In component - based development , approaches for property verification exist that avoid building the global system behavior of the component model . Typically , these approaches rely on the analysis of the local behavior of fixed sized subsystems of components . In our approach , we want to avoid not only the analysis of the global behavior but also of the local behaviors of the components . Instead , we consider very small parts of the local behaviors called port protocols that suffice to verify properties .
A theory of desynchronisable closed loop system
The task of implementing a supervisory controller is non - trivial , even though different theories exist that allow automatic synthesis of these controllers in the form of automata . One of the reasons for this discord is due to the asynchronous interaction between a plant and its controller in implementations , whereas the existing supervisory control theories assume synchronous interaction . As a consequence the implementation suffer from the so - called inexact synchronisation problem . In this paper we address the issue of inexact synchronisation in a process algebraic setting , by solving a more general problem of refinement . We construct an asynchronous closed loop system by introducing a communication medium in a given synchronous closed loop system . Our goal is to find sufficient conditions under which a synchronous closed loop system is branching bisimilar to its corresponding asynchronous closed loop system .
Safety - Guarantee Controller Synthesis for Cyber - Physical Systems
The verification and validation of cyber - physical systems is known to be a difficult problem due to the different modeling abstractions used for control components and for software components . A recent trend to address this difficulty is to reduce the need for verification by adopting correct - by - design methodologies . According to the correct - by - design paradigm , one seeks to automatically synthesize a controller that can be refined into code and that enforces temporal specifications on the cyber - physical system . In this paper we consider an instance of this problem where the specifications are given by a fragment of Linear Temporal Logic ( LTL ) and the physical environment is described by a smooth differential equation . The contribution of this paper is to show that synthesis for cyber - physical systems is viable by considering a fragment of LTL that is expressive enough to describe interesting properties but simple enough to avoid Safra 's construction . We report on two examples illustrating a preliminary implementation of these techniques on the tool PESSOALTL .
Proof equivalence in MLL is PSPACE - complete
MLL proof equivalence is the problem of deciding whether two proofs in multiplicative linear logic are related by a series of inference permutations . It is also known as the word problem for star - autonomous categories . Previous work has shown the problem to be equivalent to a rewiring problem on proof nets , which are not canonical for full MLL due to the presence of the two units . Drawing from recent work on reconfiguration problems , in this paper it is shown that MLL proof equivalence is PSPACE - complete , using a reduction from Nondeterministic Constraint Logic . An important consequence of the result is that the existence of a satisfactory notion of proof nets for MLL with units is ruled out ( under current complexity assumptions ) . The PSPACE - hardness result extends to equivalence of normal forms in MELL without units , where the weakening rule for the exponentials induces a similar rewiring problem .
Type - checking Liveness for Collaborative Processes with Bounded and Unbounded Recursion
We present the first session typing system guaranteeing request - response liveness properties for possibly non - terminating communicating processes . The types augment the branch and select types of the standard binary session types with a set of required responses , indicating that whenever a particular label is selected , a set of other labels , its responses , must eventually also be selected . We prove that these extended types are strictly more expressive than standard session types . We provide a type system for a process calculus similar to a subset of collaborative BPMN processes with internal ( data - based ) and external ( event - based ) branching , message passing , bounded and unbounded looping . We prove that this type system is sound , i.e. , it guarantees request - response liveness for dead - lock free processes . We exemplify the use of the calculus and type system on a concrete example of an infinite state system .
Switchability and collapsibility of Gap Algebras
Let A be an idempotent algebra on a 3-element domain D that omits a G - set for a factor . Suppose A is not \alpha\beta - projective ( for some alpha , beta subsets of D ) and is not collapsible . It follows that A is switchable . We prove that , for every finite subset Delta of Inv(A ) , Pol(Delta ) is collapsible . We also exhibit an algebra that is collapsible from a non - singleton source but is not collapsible from any singleton source .
Characteristic Formulae for Session Types ( extended version )
Subtyping is a crucial ingredient of session type theory and its applications , notably to programming language implementations . In this paper , we study effective ways to check whether a session type is a subtype of another by applying a characteristic formulae approach to the problem . Our core contribution is an algorithm to generate a modal mu - calculus formula that characterises all the supertypes ( or subtypes ) of a given type . Subtyping checks can then be off - loaded to model checkers , thus incidentally yielding an efficient algorithm to check safety of session types , soundly and completely . We have implemented our theory and compared its cost with other classical subtyping algorithms .
On the toggling - branching recurrence of Computability Logic
We introduce a new , substantially simplified version of the toggling - branching recurrence operation of Computability Logic , prove its equivalence to Japaridze 's old , " canonical " version , and also prove that both versions preserve the static property of their arguments .
Efficient computation of exact solutions for quantitative model checking
Quantitative model checkers for Markov Decision Processes typically use finite - precision arithmetic . If all the coefficients in the process are rational numbers , then the model checking results are rational , and so they can be computed exactly . However , exact techniques are generally too expensive or limited in scalability . In this paper we propose a method for obtaining exact results starting from an approximated solution in finite - precision arithmetic . The input of the method is a description of a scheduler , which can be obtained by a model checker using finite precision . Given a scheduler , we show how to obtain a corresponding basis in a linear - programming problem , in such a way that the basis is optimal whenever the scheduler attains the worst - case probability . This correspondence is already known for discounted MDPs , we show how to apply it in the undiscounted case provided that some preprocessing is done . Using the correspondence , the linear - programming problem can be solved in exact arithmetic starting from the basis obtained . As a consequence , the method finds the worst - case probability even if the scheduler provided by the model checker was not optimal . In our experiments , the calculation of exact solutions from a candidate scheduler is significantly faster than the calculation using the simplex method under exact arithmetic starting from a default basis .
Weak Markovian Bisimulation Congruences and Exact CTMC - Level Aggregations for Concurrent Processes
We have recently defined a weak Markovian bisimulation equivalence in an integrated - time setting , which reduces sequences of exponentially timed internal actions to individual exponentially timed internal actions having the same average duration and execution probability as the corresponding sequences . This weak Markovian bisimulation equivalence is a congruence for sequential processes with abstraction and turns out to induce an exact CTMC - level aggregation at steady state for all the considered processes . However , it is not a congruence with respect to parallel composition . In this paper , we show how to generalize the equivalence in a way that a reasonable tradeoff among abstraction , compositionality , and exactness is achieved for concurrent processes . We will see that , by enhancing the abstraction capability in the presence of concurrent computations , it is possible to retrieve the congruence property with respect to parallel composition , with the resulting CTMC - level aggregation being exact at steady state only for a certain subset of the considered processes .
Quasi - reductivity of Logically Constrained Term Rewriting Systems
This paper considers quasi - reductivity - essentially , the property that an evaluation can not get " stuck " due to a missing case in pattern matching - in the context of term rewriting with logical constraints .
Refining Trace Abstraction using Abstract Interpretation
The CEGAR loop in software model checking notoriously diverges when the abstraction refinement procedure does not derive a loop invariant . An abstraction refinement procedure based on an SMT solver is applied to a trace , i.e. , a restricted form of a program ( without loops ) . In this paper , we present a new abstraction refinement procedure that aims at circumventing this restriction whenever possible . We apply abstract interpretation to a program that we derive from the given trace . If the program contains a loop , we are guaranteed to obtain a loop invariant . We call an SMT solver only in the case where the abstract interpretation returns an indefinite answer . That is , the idea is to use abstract interpretation and an SMT solver in tandem . An experimental evaluation in the setting of trace abstraction indicates the practical potential of this idea .
On Optimization Modulo Theories , MaxSMT and Sorting Networks
Optimization Modulo Theories ( OMT ) is an extension of SMT which allows for finding models that optimize given objectives . ( Partial weighted ) MaxSMT --or equivalently OMT with Pseudo - Boolean objective functions , OMT+PB-- is a very - relevant strict subcase of OMT . We classify existing approaches for MaxSMT or OMT+PB in two groups : MaxSAT - based approaches exploit the efficiency of state - of - the - art MAXSAT solvers , but they are specific - purpose and not always applicable ; OMT - based approaches are general - purpose , but they suffer from intrinsic inefficiencies on MaxSMT / OMT+PB problems . We identify a major source of such inefficiencies , and we address it by enhancing OMT by means of bidirectional sorting networks . We implemented this idea on top of the OptiMathSAT OMT solver . We run an extensive empirical evaluation on a variety of problems , comparing MaxSAT - based and OMT - based techniques , with and without sorting networks , implemented on top of OptiMathSAT and { \nu}Z. The results support the effectiveness of this idea , and provide interesting insights about the different approaches .
A Complete Quantitative Deduction System for the Bisimilarity Distance on Markov Chains
In this paper we propose a complete axiomatization of the bisimilarity distance of Desharnais et al . for the class of finite labelled Markov chains . Our axiomatization is given in the style of a quantitative extension of equational logic recently proposed by Mardare , Panangaden , and Plotkin ( LICS 2016 ) that uses equality relations $ t \equiv_\varepsilon s$ indexed by rationals , expressing that ` $ t$ is approximately equal to $ s$ up to an error $ \varepsilon$ ' . Notably , our quantitative deduction system extends in a natural way the equational system for probabilistic bisimilarity given by Stark and Smolka by introducing an axiom for dealing with the Kantorovich distance between probability distributions . The axiomatization is then used to propose a metric extension of a Kleene 's style representation theorem for finite labelled Markov chains , that was proposed ( in a more general coalgebraic fashion ) by Silva et al . ( Inf . Comput . 2011 ) .
A set - theoretical approach for ABox reasoning services ( Extended Version )
In this paper we consider the most common ABox reasoning services for the description logic $ \dlssx$ ( $ \shdlssx$ , for short ) and prove their decidability via a reduction to the satisfiability problem for the set - theoretic fragment \flqsr . The description logic $ \shdlssx$ is very expressive , as it admits various concept and role constructs , and data types , that allow one to represent rule - based languages such as SWRL . Decidability results are achieved by defining a generalization of the conjunctive query answering problem , called HOCQA ( Higher Order Conjunctive Query Answering ) , that can be instantiated to the most wide\-spread ABox reasoning tasks . We also present a \ke\space based procedure for calculating the answer set from $ \shdlssx$ knowledge bases and higher order $ \shdlssx$ conjunctive queries , thus providing means for reasoning on several well - known ABox reasoning tasks . Our calculus extends a previously introduced \ke\space based decision procedure for the CQA problem .
A More Sensitive Context
Logic of Behaviour in Context ( LBC ) is a spatio - temporal logic for expressing properties of continuous - state processes , such as biochemical reaction networks . LBC builds on the existing Metric Interval Temporal Logic ( MITL ) and adds a " context modality " that explores the behaviour of a system when composed with an external process . LBC models are terms of the Continuous { \pi}-Calculus ( c{\pi } ) , a process algebra with continuous state space . Our previously published LBC model - checking technique required examining many points along the behavioural trajectory of a process ; and potentially computing further trajectories branching off at every such point . This raised two difficulties : mixing temporal and spatial modalities could require computing a large number of trajectories , with costly numerical solution of differential equations ; and might still fail to check intermediate values between discrete points on those trajectories . In this paper we make progress against both of these problems using techniques from signal temporal logic and from sensitivity analysis . Boolean signals aggressively compress trace information , allowing more efficient computation ; and sensitivity analysis lets us reliably check formulae over a region by calculating a smaller number of sample trajectories .
Local Lexing
We introduce a novel parsing concept called local lexing . It integrates the classically separated stages of lexing and parsing by allowing lexing to be dependent upon the parsing progress and by providing a simple mechanism for constraining lexical ambiguity . This makes it possible for language design to be composable not only at the level of context - free grammars , but also at the lexical level . It also makes it possible to include lightweight error - handling directly as part of the language specification instead of leaving it up to the implementation . We present a high - level algorithm for local lexing , which is an extension of Earley 's algorithm . We have formally verified the correctness of our algorithm with respect to its local lexing semantics in Isabelle / HOL .
Finite Satisfiability of the Two - Variable Guarded Fragment with Transitive Guards and Related Variants
We are concerned with extensions of the two - variable guarded fragment , GF2 , where distinguished binary predicates that occur only in guards are required to be interpreted in a special way ( as transitive relations , equivalence relations , pre- or partial orders ) . We prove that the only fragment that retains the finite ( exponential ) model property is GF2 with equivalence guards when equality is not available in the signature . For remaining fragments we show that the size of a minimal finite model is at most doubly exponential . To obtain the result we invent a strategy of building finite models that are formed from a number of multidimensional grids placed over a cylindrical surface . The construction yields a 2NExpTime - upper bound on the complexity of the finite satisfiability problem for these fragments . We improve the bounds and obtain optimal ones for all the fragments considered , in particular NExpTime for GF2 with equivalence guards , and 2ExpTime for GF2 with transitive guards . To obtain our results we essentially use some results from integer programming .
Compatibility Properties of Synchronously and Asynchronously Communicating Components
We study interacting components and their compatibility with respect to synchronous and asynchronous composition . The behavior of components is formalized by I / O - transition systems . Synchronous composition is based on simultaneous execution of shared output and input actions of two components while asynchronous composition uses unbounded FIFO - buffers for message transfer . In both contexts we study compatibility notions based on the idea that any output issued by one component should be accepted as an input by the other . We distinguish between strong and weak versions of compatibility , the latter allowing the execution of internal actions before a message is accepted . We consider open systems and study conditions under which ( strong / weak ) synchronous compatibility is sufficient and necessary to get ( strong / weak ) asynchronous compatibility . We show that these conditions characterize half - duplex systems . Then we focus on the verification of weak asynchronous compatibility for possibly non half - duplex systems and provide a decidable criterion that ensures weak asynchronous compatibility . We investigate conditions under which this criterion is complete , i.e. if it is not satisfied then the asynchronous system is not weakly asynchronously compatible . Finally , we discuss deadlock - freeness and investigate relationships between deadlock - freeness in the synchronous and in the asynchronous case .
On Proving Confluence Modulo Equivalence for Constraint Handling Rules
Previous results on proving confluence for Constraint Handling Rules are extended in two ways in order to allow a larger and more realistic class of CHR programs to be considered confluent . Firstly , we introduce the relaxed notion of confluence modulo equivalence into the context of CHR : while confluence for a terminating program means that all alternative derivations for a query lead to the exact same final state , confluence modulo equivalence only requires the final states to be equivalent with respect to an equivalence relation tailored for the given program . Secondly , we allow non - logical built - in predicates such as var/1 and incomplete ones such as is/2 , that are ignored in previous work on confluence . To this end , a new operational semantics for CHR is developed which includes such predicates . In addition , this semantics differs from earlier approaches by its simplicity without loss of generality , and it may also be recommended for future studies of CHR . For the purely logical subset of CHR , proofs can be expressed in first - order logic , that we show is not sufficient in the present case . We have introduced a formal meta - language that allows reasoning about abstract states and derivations with meta - level restrictions that reflect the non - logical and incomplete predicates . This language represents subproofs as diagrams , which facilitates a systematic enumeration of proof cases , pointing forward to a mechanical support for such proofs .
HoTT formalisation in Coq : Dependency Graphs \ & ML4PG
This note is a response to Bas Spitter 's email of 28 February 2014 about ML4PG : " We ( Jason actually ) are adding dependency graphs to our HoTT library : https://github.com/HoTT/HoTT/wiki I seem to recall that finding the dependency graph was a main obstacle preventing machine learning to be used in Coq . However , you seem to have made progress on this . What tool are you using ? https://anne.pacalet.fr/dev/dpdgraph/ ? Or another tool ? Would it be easy to use your ML4PG on the HoTT library ? " This note gives explanation of how ML4PG can be used in the HoTT library and how ML4PG relates to the two kinds of Dependency graphs available in Coq .
Semantic information and artificial intelligence
For a computational system to be intelligent , it should be able to perform , at least , basic deductions . Nonetheless , since deductions are , in some sense , equivalent to tautologies , it seems that they do not provide new information . The present article proposes a measure the degree of semantic informativity of valid deductions in a dynamic setting . Concepts of coherency and relevancy , displayed in terms of insertions and deletions on databases , are used to define semantic informativity . In this way , the article shows that a solution to the problem about the informativity of deductions provides a heuristic principle to improve the deductive power of computational systems .
Reducing Higher Order Pi - Calculus to Spatial Logics
In this paper , we show that theory of processes can be reduced to the theory of spatial logic . Firstly , we propose a spatial logic SL for higher order pi - calculus , and give an inference system of SL . The soundness and incompleteness of SL are proved . Furthermore , we show that the structure congruence relation and one - step transition relation can be described as the logical relation of SL formulae . We also extend bisimulations for processes to that for SL formulae . Then we extend all definitions and results of SL to a weak semantics version of SL , called WL . At last , we add mu - operator to SL . This new logic is named muSL . We show that WL is a sublogic of muSL and replication operator can be expressed in muSL .
Linearity in the non - deterministic call - by - value setting
We consider the non - deterministic extension of the call - by - value lambda calculus , which corresponds to the additive fragment of the linear - algebraic lambda - calculus . We define a fine - grained type system , capturing the right linearity present in such formalisms . After proving the subject reduction and the strong normalisation properties , we propose a translation of this calculus into the System F with pairs , which corresponds to a non linear fragment of linear logic . The translation provides a deeper understanding of the linearity in our setting .
Effectively Nonblocking Consensus Procedures Can Execute Forever - a Constructive Version of FLP
The Fischer - Lynch - Paterson theorem ( FLP ) says that it is impossible for processes in an asynchronous distributed system to achieve consensus on a binary value when a single process can fail ; it is a widely cited theoretical result about network computing . All proofs that I know depend essentially on classical ( nonconstructive ) logic , although they use the hypothetical construction of a nonterminating execution as a main lemma . FLP is also a guide for protocol designers , and in that role there is a connection to an important property of consensus procedures , namely that they should not block , i.e. reach a global state in which no process can decide . A deterministic fault - tolerant consensus protocol is effectively nonblocking if from any reachable global state we can find an execution path that decides . In this article we effectively construct a nonterminating execution of any such protocol . That is , given any effectively nonblocking protocol P and a natural number n , we show how to compute the n - th step of an infinitely indecisive computation of P. From this fully constructive result , the classical FLP follows as a corollary as well as a stronger classical result , called here Strong FLP . Moreover , the construction focuses attention on the important role of nonblocking in protocol design . An interesting consequence of the constructive proof is that we can , in principle , build an undefeatable attacker for a consensus protocol that is provably correct , indeed because it is provably correct . We can do this in practice on certain kinds of networks .
Towards a Coalgebraic Interpretation of Propositional Dynamic Logic
The interpretation of propositional dynamic logic ( PDL ) through Kripke models requires the relations constituting the interpreting Kripke model to closely observe the syntax of the modal operators . This poses a significant challenge for an interpretation of PDL through stochastic Kripke models , because the programs ' operations do not always have a natural counterpart in the set of stochastic relations . We use rewrite rules for building up an interpretation of PDL . It is shown that each program corresponds to an essentially unique irreducible tree , which in turn is assigned a predicate lifting , serving as the program 's interpretation . The paper establishes and studies this interpretation . It discusses the expressivity of probabilistic models for PDL and relates properties like logical and behavioral equivalence or bisimilarity to the corresponding properties of a Kripke model for a closely related non - dynamic logic of the Hennessy - Milner type .
The Refined Calculus of Inductive Construction : Parametricity and Abstraction
We present a refinement of the Calculus of Inductive Constructions in which one can easily define a notion of relational parametricity . It provides a new way to automate proofs in an interactive theorem prover like Coq .
Average Case Analysis of the Classical Algorithm for Markov Decision Processes with Buchi Objectives
We consider Markov decision processes ( MDPs ) with $ \omega$-regular specifications given as parity objectives . We consider the problem of computing the set of almost - sure winning vertices from where the objective can be ensured with probability 1 . The algorithms for the computation of the almost - sure winning set for parity objectives iteratively use the solutions for the almost - sure winning set for B\"uchi objectives ( a special case of parity objectives ) . We study for the first time the average case complexity of the classical algorithm for computing almost - sure winning vertices for MDPs with B\"uchi objectives . Our contributions are as follows : First , we show that for MDPs with constant out - degree the expected number of iterations is at most logarithmic and the average case running time is linear ( as compared to the worst case linear number of iterations and quadratic time complexity ) . Second , we show that for general MDPs the expected number of iterations is constant and the average case running time is linear ( again as compared to the worst case linear number of iterations and quadratic time complexity ) . Finally we also show that given all graphs are equally likely , the probability that the classical algorithm requires more than constant number of iterations is exponentially small .
Exponential Lower Bounds and Separation for Query Rewriting
We establish connections between the size of circuits and formulas computing monotone Boolean functions and the size of first - order and nonrecursive Datalog rewritings for conjunctive queries over OWL 2 QL ontologies . We use known lower bounds and separation results from circuit complexity to prove similar results for the size of rewritings that do not use non - signature constants . For example , we show that , in the worst case , positive existential and nonrecursive Datalog rewritings are exponentially longer than the original queries ; nonrecursive Datalog rewritings are in general exponentially more succinct than positive existential rewritings ; while first - order rewritings can be superpolynomially more succinct than positive existential rewritings .
A Categorical Model for the Lambda Calculus with Constructors
The lambda calculus with constructors is an extension of the lambda calculus with variadic constructors . It decomposes the pattern - matching a la ML into a case analysis on constants and a commutation rule between case and application constructs . Although this commutation rule does not match with the usual computing intuitions , it makes the calculus expressive and confluent , with a rather simple syntax . In this paper we define a sound notion of categorical model for the lambda calculus with constructors . We then prove that this definition is complete for the fragment of the calculus with no match - failure , using the model of partial equivalence relations .
A General Form of Attribute Exploration
We present a general form of attribute exploration , a knowledge completion algorithm from Formal Concept Analysis . The aim of our presentation is not only to extend the applicability of attribute exploration by a general description . It may also allow to view different existing variants of attribute exploration as instances of a general form , which may simplify theoretical considerations .
Termination of Linear Programs with Nonlinear Constraints
Tiwari proved that termination of linear programs ( loops with linear loop conditions and updates ) over the reals is decidable through Jordan forms and eigenvectors computation . Braverman proved that it is also decidable over the integers . In this paper , we consider the termination of loops with polynomial loop conditions and linear updates over the reals and integers . First , we prove that the termination of such loops over the integers is undecidable . Second , with an assumption , we provide an complete algorithm to decide the termination of a class of such programs over the reals . Our method is similar to that of Tiwari in spirit but uses different techniques . Finally , we conjecture that the termination of linear programs with polynomial loop conditions over the reals is undecidable in general by % constructing a loop and reducing the problem to another decision problem related to number theory and ergodic theory , which we guess undecidable .
A Machine Checked Model of Idempotent MGU Axioms For Lists of Equational Constraints
We present formalized proofs verifying that the first - order unification algorithm defined over lists of satisfiable constraints generates a most general unifier ( MGU ) , which also happens to be idempotent . All of our proofs have been formalized in the Coq theorem prover . Our proofs show that finite maps produced by the unification algorithm provide a model of the axioms characterizing idempotent MGUs of lists of constraints . The axioms that serve as the basis for our verification are derived from a standard set by extending them to lists of constraints . For us , constraints are equalities between terms in the language of simple types . Substitutions are formally modeled as finite maps using the Coq library Coq . FSets . FMapInterface . Coq 's method of functional induction is the main proof technique used in proving many of the axioms .
Recursive Definitions of Monadic Functions
Using standard domain - theoretic fixed - points , we present an approach for defining recursive functions that are formulated in monadic style . The method works both in the simple option monad and the state - exception monad of Isabelle / HOL 's imperative programming extension , which results in a convenient definition principle for imperative programs , which were previously hard to define . For such monadic functions , the recursion equation can always be derived without preconditions , even if the function is partial . The construction is easy to automate , and convenient induction principles can be derived automatically .
Rewriting and Well - Definedness within a Proof System
Term rewriting has a significant presence in various areas , not least in automated theorem proving where it is used as a proof technique . Many theorem provers employ specialised proof tactics for rewriting . This results in an interleaving between deduction and computation ( i.e. , rewriting ) steps . If the logic of reasoning supports partial functions , it is necessary that rewriting copes with potentially ill - defined terms . In this paper , we provide a basis for integrating rewriting with a deductive proof system that deals with well - definedness . The definitions and theorems presented in this paper are the theoretical foundations for an extensible rewriting - based prover that has been implemented for the set theoretical formalism Event - B.
General Recursion and Formal Topology
It is well known that general recursion can not be expressed within Martin - Loef 's type theory and various approaches have been proposed to overcome this problem still maintaining the termination of the computation of the typable terms . In this work we propose a new approach to this problem based on the use of inductively generated formal topologies .
Extending Buchi Automata with Constraints on Data Values
Recently data trees and data words have received considerable amount of attention in connection with XML reasoning and system verification . These are trees or words that , in addition to labels from a finite alphabet , carry data values from an infinite alphabet ( data ) . In general it is rather hard to obtain logics for data words and trees that are sufficiently expressive , but still have reasonable complexity for the satisfiability problem . In this paper we extend and study the notion of B\"uchi automata for omega - words with data . We prove that the emptiness problem for such extension is decidable in elementary complexity . We then apply our result to show the decidability of two kinds of logics for omega - words with data : the two - variable fragment of first - order logic and some extensions of classical linear temporal logic for omega - words with data .
Improving legibility of natural deduction proofs is not trivial
In formal proof checking environments such as Mizar it is not merely the validity of mathematical formulas that is evaluated in the process of adoption to the body of accepted formalizations , but also the readability of the proofs that witness validity . As in case of computer programs , such proof scripts may sometimes be more and sometimes be less readable . To better understand the notion of readability of formal proofs , and to assess and improve their readability , we propose in this paper a method of improving proof readability based on Behaghel 's First Law of sentence structure . Our method maximizes the number of local references to the directly preceding statement in a proof linearisation . It is shown that our optimization method is NP - complete .
Synthesis from Probabilistic Components
Synthesis is the automatic construction of a system from its specification . In classical synthesis algorithms , it is always assumed that the system is " constructed from scratch " rather than composed from reusable components . This , of course , rarely happens in real life , where almost every non - trivial commercial software system relies heavily on using libraries of reusable components . Furthermore , other contexts , such as web - service orchestration , can be modeled as synthesis of a system from a library of components . Recently , Lustig and Vardi introduced dataflow and control - flow synthesis from libraries of reusable components . They proved that dataflow synthesis is undecidable , while control - flow synthesis is decidable . In this work , we consider the problem of control - flow synthesis from libraries of probabilistic components . We show that this more general problem is also decidable .
Checking Termination of Bottom - Up Evaluation of Logic Programs with Function Symbols
Recently , there has been an increasing interest in the bottom - up evaluation of the semantics of logic programs with complex terms . The presence of function symbols in the program may render the ground instantiation infinite , and finiteness of models and termination of the evaluation procedure , in the general case , are not guaranteed anymore . Since the program termination problem is undecidable in the general case , several decidable criteria ( called program termination criteria ) have been recently proposed . However , current conditions are not able to identify even simple programs , whose bottom - up execution always terminates . The paper introduces new decidable criteria for checking termination of logic programs with function symbols under bottom - up evaluation , by deeply analyzing the program structure . First , we analyze the propagation of complex terms among arguments by means of the extended version of the argument graph called propagation graph . The resulting criterion , called Gamma - acyclicity , generalizes most of the decidable criteria proposed so far . Next , we study how rules may activate each other and define a more powerful criterion , called safety . This criterion uses the so - called safety function able to analyze how rules may activate each other and how the presence of some arguments in a rule limits its activation . We also study the application of the proposed criteria to bound queries and show that the safety criterion is well - suited to identify relevant classes of programs and bound queries . Finally , we propose a hierarchy of classes of terminating programs , called k - safety , where the k - safe class strictly includes the ( k-1)-safe class . Note : To appear in Theory and Practice of Logic Programming ( TPLP ) .
Reformulation of Global Constraints in Answer Set Programming
We show that global constraints on finite domains like all - different can be reformulated into answer set programs on which we achieve arc , bound or range consistency . These reformulations offer a number of other advantages beyond providing the power of global propagators to answer set programming . For example , they provide other constraints with access to the state of the propagator by sharing variables . Such sharing can be used to improve propagation between constraints . Experiments with these encodings demonstrate their promise .
Propositional Logics Complexity and the Sub - Formula Property
In 1979 Richard Statman proved , using proof - theory , that the purely implicational fragment of Intuitionistic Logic ( M - imply ) is PSPACE - complete . He showed a polynomially bounded translation from full Intuitionistic Propositional Logic into its implicational fragment . By the PSPACE - completeness of S4 , proved by Ladner , and the Goedel translation from S4 into Intuitionistic Logic , the PSPACE- completeness of M - imply is drawn . The sub - formula principle for a deductive system for a logic L states that whenever F1, ... ,Fk proves A , there is a proof in which each formula occurrence is either a sub - formula of A or of some of Fi . In this work we extend Statman result and show that any propositional ( possibly modal ) structural logic satisfying a particular formulation of the sub - formula principle is in PSPACE . If the logic includes the minimal purely implicational logic then it is PSPACE - complete . As a consequence , EXPTIME - complete propositional logics , such as PDL and the common - knowledge epistemic logic with at least 2 agents satisfy this particular sub - formula principle , if and only if , PSPACE = EXPTIME . We also show how our technique can be used to prove that any finitely many - valued logic has the set of its tautologies in PSPACE .
An Equivalent Presentation of the Bezem - Coquand - Huber Category of Cubical Sets
Staton has shown that there is an equivalence between the category of presheaves on ( the opposite of ) finite sets and partial bijections and the category of nominal restriction sets : see [ 2 , Exercise 9.7 ] . The aim here is to see that this extends to an equivalence between the category of cubical sets introduced in [ 1 ] and a category of nominal sets equipped with a " 01-substitution " operation . It seems to me that presenting the topos in question equivalently as 01-substitution sets rather than cubical sets will make it easier ( and more elegant ) to carry out the constructions and calculations needed to build the intended univalent model of intentional constructive type theory .
A Hybrid Linear Logic for Constrained Transition Systems
Linear implication can represent state transitions , but real transition systems operate under temporal , stochastic or probabilistic constraints that are not directly representable in ordinary linear logic . We propose a general modal extension of intuitionistic linear logic where logical truth is indexed by constraints and hybrid connectives combine constraint reasoning with logical reasoning . The logic has a focused cut - free sequent calculus that can be used to internalize the rules of particular constrained transition systems ; we illustrate this with an adequate encoding of the synchronous stochastic pi - calculus .
Reasoning about Recursive Probabilistic Programs
This paper presents a wp - style calculus for obtaining expectations on the outcomes of ( mutually ) recursive probabilistic programs . We provide several proof rules to derive one-- and two -- sided bounds for such expectations , and show the soundness of our wp - calculus with respect to a probabilistic pushdown automaton semantics . We also give a wp - style calculus for obtaining bounds on the expected runtime of recursive programs that can be used to determine the ( possibly infinite ) time until termination of such programs .
The Vectorial $ l$-Calculus
We describe a type system for the linear - algebraic $ \lambda$-calculus . The type system accounts for the linear - algebraic aspects of this extension of $ \lambda$-calculus : it is able to statically describe the linear combinations of terms that will be obtained when reducing the programs . This gives rise to an original type theory where types , in the same way as terms , can be superposed into linear combinations . We prove that the resulting typed $ \lambda$-calculus is strongly normalising and features weak subject reduction . Finally , we show how to naturally encode matrices and vectors in this typed calculus .
Coalgebraic Characterizations of Context - Free Languages
In this article , we provide three coalgebraic characterizations of the class of context - free languages , each based on the idea of adding coalgebraic structure to an existing algebraic structure by specifying output - derivative pairs . Final coalgebra semantics then gives an interpretation function into the final coalgebra of all languages with the usual output and derivative operations . The first characterization is based on systems , where each derivative is given as a finite language over the set of nonterminals ; the second characterization on systems where derivatives are given as elements of a term - algebra ; and the third characterization is based on adding coalgebraic structure to a class of closed ( unique ) fixed point expressions . We prove equivalences between these characterizations , discuss the generalization from languages to formal power series , as well as the relationship to the generalized powerset construction .
Proof - Pattern Recognition and Lemma Discovery in ACL2
We present a novel technique for combining statistical machine learning for proof - pattern recognition with symbolic methods for lemma discovery . The resulting tool , ACL2(ml ) , gathers proof statistics and uses statistical pattern - recognition to pre - processes data from libraries , and then suggests auxiliary lemmas in new proofs by analogy with already seen examples . This paper presents the implementation of ACL2(ml ) alongside theoretical descriptions of the proof - pattern recognition and lemma discovery methods involved in it .
A Nondeterministic and Abstract Algorithm for Translating Hierarchical Block Diagrams
In this paper we introduce a nondeterministic algorithm for translating hierarchical block diagrams ( HBDs ) into an abstract algebra of components with three basic composition operations ( serial , parallel , and feedback ) and with three constants ( split , switch , and sink ) . We prove that despite its internal nondeterminism , the result of the algorithm is deterministic , meaning that all possible algebra expressions that can be generated from a given HBD are equivalent . Then , different determinizations of the algorithm result in different translation strategies which are all semantically equivalent , although each having its pros and cons with respect to various criteria ( compositionality , readability , simplifiability , etc . ) . As an application of our framework , we show how two translation strategies for Simulink introduced in previous work can be formalized as determinizations of the abstract algorithm . We also prove these strategies equivalent , thus answering an open question raised in the earlier work . All results are formalized and proved in Isabelle .
Extending Two - Variable Logic on Trees
The finite satisfiability problem for the two - variable fragment of first - order logic interpreted over trees was recently shown to be ExpSpace - complete . We consider two extensions of this logic . We show that adding either additional binary symbols or counting quantifiers to the logic does not affect the complexity of the finite satisfiability problem . However , combining the two extensions and adding both binary symbols and counting quantifiers leads to an explosion of this complexity . We also compare the expressive power of the two - variable fragment over trees with its extension with counting quantifiers . It turns out that the two logics are equally expressive , although counting quantifiers do add expressive power in the restricted case of unordered trees .
A hierarchy of behavioral equivalences in the $ p$-calculus with noisy channels
The $ \pi$-calculus is a process algebra where agents interact by sending communication links to each other via noiseless communication channels . Taking into account the reality of noisy channels , an extension of the $ \pi$-calculus , called the $ \pi_N$-calculus , has been introduced recently . In this paper , we present an early transitional semantics of the $ \pi_N$-calculus , which is not a directly translated version of the late semantics of $ \pi_N$ , and then extend six kinds of behavioral equivalences consisting of reduction bisimilarity , barbed bisimilarity , barbed equivalence , barbed congruence , bisimilarity , and full bisimilarity into the $ \pi_N$-calculus . Such behavioral equivalences are cast in a hierarchy , which is helpful to verify behavioral equivalence of two agents . In particular , we show that due to the noisy nature of channels , the coincidence of bisimilarity and barbed equivalence , as well as the coincidence of full bisimilarity and barbed congruence , in the $ \pi$-calculus does not hold in $ \pi_N$.
On Characterising Distributability
We formalise a general concept of distributed systems as sequential components interacting asynchronously . We define a corresponding class of Petri nets , called LSGA nets , and precisely characterise those system specifications which can be implemented as LSGA nets up to branching ST - bisimilarity with explicit divergence .
Specifying Robustness
This paper proposes a new logic RoCTL * to model robustness in concurrent systems . RoCTL * extends CTL * with the addition of Obligatory and Robustly operators , which quantify over failure - free paths and paths with one more failure respectively . We present a number of examples of problems to which RoCTL * can be applied . The core result of this paper is to show that RoCTL * is expressively equivalent to CTL * but is non - elementarily more succinct . We present a translation from RoCTL * into CTL * that preserves truth but may result in non - elementary growth in the length of the translated formula as each nested Robustly operator may result in an extra exponential blowup . However , we show that this translation is optimal in the sense that any equivalence preserving translation will require an extra exponential growth per nested Robustly . We also compare RoCTL * to Quantified CTL * ( QCTL * ) and hybrid logics .
On abstract normalisation beyond neededness
We study normalisation of multistep strategies , strategies that reduce a set of redexes at a time , focussing on the notion of necessary sets , those which contain at least one redex that can not be avoided in order to reach a normal form . This is particularly appealing in the setting of non - sequential rewrite systems , in which terms that are not in normal form may not have any needed redex . We first prove a normalisation theorem for abstract rewrite systems ( ARS ) , a general rewriting framework encompassing many rewriting systems developed by P - A.Melli\`es in his PhD thesis . The theorem states that multistep strategies reducing so called necessary and never - gripping sets of redexes at a time are normalising in any ARS . Gripping refers to an abstract property reflecting the behavior of higher - order substitution . We then apply this result to the particular case of PPC , a calculus of patterns and to the lambda - calculus with parallel - or .
An Intuitionistic Set - theoretical Model of the Extended Calculus of Constructions
Werner 's set - theoretical model is one of the most intuitive models of ECC . It combines a functional view of predicative universes with a collapsed view of the impredicative sort Prop . However this model of Prop is so coarse that the principle of excluded middle holds . In this paper , we interpret Prop into a topological space ( a special case of Heyting algebra ) to make it more intuitionistic without sacrificing simplicity . We prove soundness and show some applications of our model .
A Second - Order Formulation of Non - Termination
We consider the termination / non - termination property of a class of loops . Such loops are commonly used abstractions of real program pieces . Second - order logic is a convenient language to express non - termination . Of course , such property is generally undecidable . However , by restricting the language to known decidable cases , we exhibit new classes of loops , the non - termination of which is decidable . We present a bunch of examples .
A Logical Study of Some Common Principles of Inductive Definition and its Implications for Knowledge Representation
The definition is a common form of human expert knowledge , a building block of formal science and mathematics , a foundation for database theory and is supported in various forms in many knowledge representation and formal specification languages and systems . This paper is a formal study of some of the most common forms of inductive definitions found in scientific text : monotone inductive definition , definition by induction over a well - founded order and iterated inductive definitions . We define a logic of definitions offering a uniform formal syntax to express definitions of the different sorts , and we define its semantics by a faithful formalization of the induction process . Several fundamental properties of definition by induction emerge : the non - determinism of the induction process , the confluence of induction processes , the role of the induction order and its relation to the inductive rules , how the induction order constrains the induction process and , ultimately , that the induction order is irrelevant : the defined set does not depend on the induction order . We propose an inductive construction capable of constructing the defined set without using the induction order . We investigate borderline definitions of the sort that appears in definitional paradoxes .
Relational Convolution , Generalised Modalities and Incidence Algebras
Convolution is a ubiquitous operation in mathematics and computing . The Kripke semantics for substructural and interval logics motivates its study for quantale - valued functions relative to ternary relations . The resulting notion of relational convolution leads to generalised binary and unary modal operators for qualitative and quantitative models , and to more conventional variants , when ternary relations arise from identies over partial semigroups . Convolution - based semantics for fragments of categorial , linear and incidence ( segment or interval ) logics are provided as qualitative applications . Quantitative examples include algebras of durations and mean values in the duration calculus .
Towards M - Adhesive Categories of Corecursive Graphs
In this contribution we investigate several extensions of the powerset that comprise arbitrarily nested subsets , and call them superpower set . This allows the definition of graphs with possibly infinitely nested nodes . additionally we define edges that are incident to edges . Since we use coalgebraic constructions we refer to these graphs as corecursive graphs . The superpower set functors are examined and then used for the definition of $ \mathcal{M}$-adhesive categories which are the basic categories for $ \mathcal{M}$-adhesive transformation systems . So , we additionally show that coalgebras $ \mathbf{Sets}_F$ are $ \mathcal{M}$-adhesive categories provided the functor $ F:\mathbf{Sets}_F \to \mathbf{Sets}_F$ preserves pullbacks along monomorphisms .
Is your software on dope ? Formal analysis of surreptitiously " enhanced " programs
Usually , it is the software manufacturer who employs verification or testing to ensure that the software embedded in a device meets its main objectives . However , these days we are confronted with the situation that economical or technological reasons might make a manufacturer become interested in the software slightly deviating from its main objective for dubious reasons . Examples include lock - in strategies and the $ \mathrm{NO}_x$ emission scandals in automotive industry . This phenomenon is what we call software doping . It is turning more widespread as software is embedded in ever more devices of daily use . The primary contribution of this article is to provide a hierarchy of simple but solid formal definitions that enable to distinguish whether a program is clean or doped . Moreover , we show that these characterisations provide an immediate framework for analysis by using already existing verification techniques . We exemplify this by applying self - composition on sequential programs and model checking of HyperLTL formulas on reactive models .
Game - theoretic Model of Computation
The present paper introduces an intrinsic notion of " ( effective ) computability " in game semantics motivated by the fact that strategies in game semantics have been defined recursive if they are " computable in an extrinsic sense " , i.e. , they are representable by partial recursive functions , and so it has been difficult to regard game semantics as an autonomous foundation of computation . As a consequence , we have formulated a general notion of " algorithms " under the name of effective strategies , giving rise to a mathematical model of computation in the same sense as Turing machines but beyond computation on natural numbers , e.g. , higher - order one , solely in terms of games and strategies . It subsumes computation of the programming language PCF , and so it is in particular Turing complete . Notably , effective strategies have a natural notion of types ( i.e. , games ) unlike Turing machines , while they are non - inductively defined as opposed to partial recursive functions as well as semantic in contrast with lambda - calculi and combinatory logic . Thus , in a sense , we have captured a mathematical ( or semantic ) notion of computation ( and computability ) that is more general than the " classical ones " in a fundamental level . Exploiting the flexibility of game semantics , our game - theoretic model of computation is intended to give a mathematical foundation of various ( constructive ) logics and programming languages .
Local Redundancy in SAT : Generalizations of Blocked Clauses
Clause - elimination procedures that simplify formulas in conjunctive normal form play an important role in modern SAT solving . Before or during the actual solving process , such procedures identify and remove clauses that are irrelevant to the solving result . These simplifications usually rely on so - called redundancy properties that characterize cases in which the removal of a clause does not affect the satisfiability status of a formula . A particularly successful redundancy property is that of blocked clauses , because it generalizes several other redundancy properties . To find out whether a clause is blocked --- and therefore redundant --- one only needs to consider its resolution environment , i.e. , the clauses with which it can be resolved . For this reason , the redundancy property of blocked clauses is said to be local . In this paper , we show that there exist local redundancy properties that are even more general than blocked clauses . To this end , we present a semantic notion of blocking and prove that it constitutes the most general local redundancy property . We furthermore introduce the syntax - based notions of set - blocking and super - blocking , the latter of which coincides with our semantic blocking notion . In addition , we show how semantic blocking can be alternatively characterized via Davis and Putnam 's " rule for eliminating atomic formulas " . Finally , we perform a detailed complexity analysis and relate our novel redundancy properties to prominent redundancy properties from the literature .
Automata for two - variable logic over trees with ordered data values
Data trees are trees in which each node , besides carrying a label from a finite alphabet , also carries a data value from an infinite domain . They have been used as an abstraction model for reasoning tasks on { XML } and verification . However , most existing approaches consider the case where only equality test can be performed on the data values . In this paper we study data trees in which the data values come from a linearly ordered domain , and in addition to equality test , we can test whether the data value in a node is greater than the one in another node . We introduce an automata model for them which we call ordered - data tree automata ( ODTA ) , provide its logical characterisation , and prove that its non - emptiness problem is decidable in 3-NEXPTIME . We also show that the two - variable logic on unranked trees , studied by Bojanczyk , Muscholl , Schwentick and Segoufin in 2009 , corresponds precisely to a special subclass of this automata model . Then we define a slightly weaker version of ODTA , which we call weak ODTA , and provide its logical characterisation . The complexity of the non - emptiness problem drops to NP . However , a number of existing formalisms and models studied in the literature can be captured already by weak ODTA . We also show that the definition of ODTA can be easily modified , to the case where the data values come from a tree - like partially ordered domain , such as strings .
Extracting Unsatisfiable Cores for LTL via Temporal Resolution
Unsatisfiable cores ( UCs ) are a well established means for debugging in a declarative setting . Still , there are few tools that perform automated extraction of UCs for LTL . Existing tools compute a UC as an unsatisfiable subset of the set of top - level conjuncts of an LTL formula . Using resolution graphs to extract UCs is common in other domains such as SAT . In this article we construct and optimize resolution graphs for temporal resolution as implemented in the temporal resolution - based solver TRP++ , and we use them to extract UCs for propositional LTL . The resulting UCs are more fine - grained than the UCs obtained from existing tools because UC extraction also simplifies top - level conjuncts instead of treating them as atomic entities . For example , given an unsatisfiable LTL formula of the form $ \phi \equiv ( { \bf G } \psi ) \wedge { \bf F } \psi'$ existing tools return $ \phi$ as a UC irrespective of the complexity of $ \psi$ and $ \psi'$ , whereas the approach presented in this article continues to remove parts not required for unsatisfiability inside $ \psi$ and $ \psi'$. Our approach also identifies groups of occurrences of a proposition that do not interact in a proof of unsatisfiability . We implement our approach in TRP++ . Our experimental evaluation demonstrates that our approach ( i ) extracts UCs that are often significantly smaller than the input formula with an acceptable overhead and ( ii ) produces more fine - grained UCs than competing tools while remaining at least competitive in terms of run time and memory usage . The source code of our tool is publicly available .
Towards Approximate Model Checking DC and PDC Specifications
DC has proved to be a promising tool for the specification and verification of functional requirements on the design of hard real - time systems . Many works were devoted to develop effective techniques for checking the models of hard real - time systems against DC specifications . DC model checking theory is still evolving and yet there is no available tools supporting practical verifications due to the high undecidability of calculus and the great complexity of model checking . Present situation of PDC model checking is much worse than the one of DC model checking . In view of the results so far achieved , it is desirable to develop approximate model checking techniques for DC and PDC specifications . This work was motivated to develop approximate techniques checking automata models of hard real - time systems for DC and PDC specifications . Unlike previous works which only deal with decidable formulas , we want to develop approximate techniques covering whole DC and PDC formulas . The first results of our work , namely , approximate techniques checking real - time automata models of systems for LDI and PLDI specifications , are described in this paper .
Interactive verification of Markov chains : Two distributed protocol case studies
Probabilistic model checkers like PRISM only check probabilistic systems of a fixed size . To guarantee the desired properties for an arbitrary size , mathematical analysis is necessary . We show for two case studies how this can be done in the interactive proof assistant Isabelle / HOL . The first case study is a detailed description of how we verified properties of the ZeroConf protocol , a decentral address allocation protocol . The second case study shows the more involved verification of anonymity properties of the Crowds protocol , an anonymizing protocol .
Parameterized Metatheory for Continuous Markovian Logic
This paper shows that a classic metalogical framework , including all Boolean operators , can be used to support the development of a metric behavioural theory for Markov processes . Previously , only intuitionistic frameworks or frameworks without negation and logical implication have been developed to fulfill this task . The focus of this paper is on continuous Markovian logic ( CML ) , a logic that characterizes stochastic bisimulation of Markov processes with an arbitrary measurable state space and continuous - time transitions . For a parameter epsilon>0 interpreted as observational error , we introduce an epsilon - parameterized metatheory for CML : we define the concepts of epsilon - satisfiability and epsilon - provability related by a sound and complete axiomatization and prove a series of " parameterized " metatheorems including decidability , weak completeness and finite model property . We also prove results regarding the relations between metalogical concepts defined for different parameters . Using this framework , we can characterize both the stochastic bisimulation relation and various observational preorders based on behavioural pseudometrics . The main contribution of this paper is proving that all these analyses can actually be done using a unified complete Boolean framework . This extends the state of the art in this field , since the related works only propose intuitionistic contexts that limit , for instance , the use of the Boolean logical implication .
Combining generic judgments with recursive definitions
Many semantical aspects of programming languages , such as their operational semantics and their type assignment calculi , are specified by describing appropriate proof systems . Recent research has identified two proof - theoretic features that allow direct , logic - based reasoning about such descriptions : the treatment of atomic judgments as fixed points ( recursive definitions ) and an encoding of binding constructs via generic judgments . However , the logics encompassing these two features have thus far treated them orthogonally : that is , they do not provide the ability to define object - logic properties that themselves depend on an intrinsic treatment of binding . We propose a new and simple integration of these features within an intuitionistic logic enhanced with induction over natural numbers and we show that the resulting logic is consistent . The pivotal benefit of the integration is that it allows recursive definitions to not just encode simple , traditional forms of atomic judgments but also to capture generic properties pertaining to such judgments . The usefulness of this logic is illustrated by showing how it can provide elegant treatments of object - logic contexts that appear in proofs involving typing calculi and of arbitrarily cascading substitutions that play a role in reducibility arguments .
Order effects in dynamic semantics
In their target article , \citet{WangBusemeyer13 } [ A quantum question order model supported by empirical tests of an a priori and precise prediction . \emph{Topics in Cognitive Science } ] discuss question order effects in terms of incompatible projectors on a Hilbert space . In a similar vein , Blutner recently presented an orthoalgebraic query language essentially relying on dynamic update semantics . Here , I shall comment on some interesting analogies between the different variants of dynamic semantics and generalized quantum theory to illustrate other kinds of order effects in human cognition , such as belief revision , the resolution of anaphors , and default reasoning that result from the crucial non - commutativity of mental operations upon the belief state of a cognitive agent .
Taming Past LTL and Flat Counter Systems
Reachability and LTL model - checking problems for flat counter systems are known to be decidable but whereas the reachability problem can be shown in NP , the best known complexity upper bound for the latter problem is made of a tower of several exponentials . Herein , we show that the problem is only NP - complete even if LTL admits past - time operators and arithmetical constraints on counters . Actually , the NP upper bound is shown by adequately combining a new stuttering theorem for Past LTL and the property of small integer solutions for quantifier - free Presburger formulae . Other complexity results are proved , for instance for restricted classes of flat counter systems .
Disjunctive form and the modal $ m$ alternation hierarchy
This paper studies the relationship between disjunctive form , a syntactic normal form for the modal mu calculus , and the alternation hierarchy . First it shows that all disjunctive formulas which have equivalent tableau have the same syntactic alternation depth . However , tableau equivalence only preserves alternation depth for the disjunctive fragment : there are disjunctive formulas with arbitrarily high alternation depth that are tableau equivalent to alternation - free non - disjunctive formulas . Conversely , there are non - disjunctive formulas of arbitrarily high alternation depth that are tableau equivalent to disjunctive formulas without alternations . This answers negatively the so far open question of whether disjunctive form preserves alternation depth . The classes of formulas studied here illustrate a previously undocumented type of avoidable syntactic complexity which may contribute to our understanding of why deciding the alternation hierarchy is still an open problem .
The Arity Hierarchy in the Polyadic $ m$-Calculus
The polyadic mu - calculus is a modal fixpoint logic whose formulas define relations of nodes rather than just sets in labelled transition systems . It can express exactly the polynomial - time computable and bisimulation - invariant queries on finite graphs . In this paper we show a hierarchy result with respect to expressive power inside the polyadic mu - calculus : for every level of fixpoint alternation , greater arity of relations gives rise to higher expressive power . The proof uses a diagonalisation argument .
Weak Completeness of Coalgebraic Dynamic Logics
We present a coalgebraic generalisation of Fischer and Ladner 's Propositional Dynamic Logic ( PDL ) and Parikh 's Game Logic ( GL ) . In earlier work , we proved a generic strong completeness result for coalgebraic dynamic logics without iteration . The coalgebraic semantics of such programs is given by a monad T , and modalities are interpreted via a predicate lifting \^I whose transpose is a monad morphism from T to the neighbourhood monad . In this paper , we show that if the monad T carries a complete semilattice structure , then we can define an iteration construct , and suitable notions of diamond - likeness and box - likeness of predicate - liftings which allows for the definition of an axiomatisation parametric in T , \^I and a chosen set of pointwise program operations . As our main result , we show that if the pointwise operations are " negation - free " and Kleisli composition left - distributes over the induced join on Kleisli arrows , then this axiomatisation is weakly complete with respect to the class of standard models . As special instances , we recover the weak completeness of PDL and of dual - free Game Logic . As a modest new result we obtain completeness for dual - free GL extended with intersection ( demonic choice ) of games .
Partial Model Checking using Networks of Labelled Transition Systems and Boole an Equation Systems
Partial model checking was proposed by Andersen in 1995 to verify a temporal logic formula compositionally on a composition of processes . It consists in incrementally incorporating into the formula the behavioural information taken from one process - an operation called quotienting - to obtain a new formula that can be verified on a smaller composition from which the incorporated process has been removed . Simplifications of the formula must be applied at each step , so as to maintain the formula at a tractable size . In this paper , we revisit partial model checking . First , we extend quotienting to the network of labelled transition systems model , which subsumes most parallel composition operators , including m - among - n synchronisation and parallel composition using synchronisation interfaces , available in the ELOTOS standard . Second , we reformulate quotienting in terms of a simple synchronous product between a graph representation of the formula ( called formula graph ) and a process , thus enabling quotienting to be implemented efficiently and easily , by reusing existing tools dedicated to graph compositions . Third , we propose simplifications of the formula as a combination of bisimulations and reductions using Boolean equation systems applied directly to the formula graph , thus enabling formula simplifications also to be implemented efficiently . Finally , we describe an implementation in the CADP ( Construction and Analysis of Distributed Processes ) toolbox and present some experimental results in which partial model checking uses hundreds of times less memory than on - the - fly model checking .
On Modal Logics of Partial Recursive Functions
The classical propositional logic is known to be sound and complete with respect to the set semantics that interprets connectives as set operations . The paper extends propositional language by a new binary modality that corresponds to partial recursive function type constructor under the above interpretation . The cases of deterministic and non - deterministic functions are considered and for both of them semantically complete modal logics are described and decidability of these logics is established .
Analysis of Clause set Schema Aided by Automated Theorem Proving : A Case Study [ Extended Paper ]
The schematic CERES method [ 8 ] is a recently developed method of cut elimination for proof schemata , that is a sequence of proofs with a recursive construction . Proof schemata can be thought of as a way to circumvent adding an induction rule to the LK - calculus . In this work , we formalize a schematic version of the infinitary pigeonhole principle , which we call the Non - injectivity Assertion schema ( NiA - schema ) , in the LKS - calculus [ 8 ] , and analyse the clause set schema extracted from the NiA - schema using some of the structure provided by the schematic CERES method . To the best of our knowledge , this is the first appli- cation of the constructs built for proof analysis of proof schemata to a mathematical argument since its publication . We discuss the role of Automated Theorem Proving ( ATP ) in schematic proof analysis , as well as the shortcomings of the schematic CERES method concerning the formalization of the NiA - schema , namely , the expressive power of the schematic resolution calculus . We conclude with a discussion concerning the usage of ATP in schematic proof analysis .
Towards Efficient Axiom Pinpointing of EL+ Ontologies
The EL family of Description Logics ( DLs ) has been the subject of interest in recent years . On the one hand , these DLs are tractable , but fairly inexpressive . On the other hand , these DLs can be used for designing different classes of ontologies , most notably ontologies from the medical domain . Unfortunately , building ontologies is error - prone . As a result , inferable subsumption relations among concepts may be unintended . In recent years , the problem of axiom pinpointing has been studied with the purpose of providing minimal sets of axioms that explain unintended subsumption relations . For the concrete case of EL and EL+ , the most efficient approaches consist of encoding the problem into propositional logic , specifically as a Horn formula , which is then analyzed with a dedicated algorithm . This paper builds on this earlier work , but exploits the important relationship between minimal axioms sets and minimal unsatisfiable subformulas in the propositional domain . In turn , this relationship allows applying a vast body of recent work in the propositional domain to the concrete case of axiom pinpointing for EL and its variants . From a practical perspective , the algorithms described in this paper are often several orders of magnitude more efficient that the current state of the art in axiom pinpointing for the EL family of DLs .
On partial order semantics for SAT / SMT - based symbolic encodings of weak memory concurrency
Concurrent systems are notoriously difficult to analyze , and technological advances such as weak memory architectures greatly compound this problem . This has renewed interest in partial order semantics as a theoretical foundation for formal verification techniques . Among these , symbolic techniques have been shown to be particularly effective at finding concurrency - related bugs because they can leverage highly optimized decision procedures such as SAT / SMT solvers . This paper gives new fundamental results on partial order semantics for SAT / SMT - based symbolic encodings of weak memory concurrency . In particular , we give the theoretical basis for a decision procedure that can handle a fragment of concurrent programs endowed with least fixed point operators . In addition , we show that a certain partial order semantics of relaxed sequential consistency is equivalent to the conjunction of three extensively studied weak memory axioms by Alglave et al . An important consequence of this equivalence is an asymptotically smaller symbolic encoding for bounded model checking which has only a quadratic number of partial order constraints compared to the state - of - the - art cubic - size encoding .
Quantitative Approximation of the Probability Distribution of a Markov Process by Formal Abstractions
The goal of this work is to formally abstract a Markov process evolving in discrete time over a general state space as a finite - state Markov chain , with the objective of precisely approximating its state probability distribution in time , which allows for its approximate , faster computation by that of the Markov chain . The approach is based on formal abstractions and employs an arbitrary finite partition of the state space of the Markov process , and the computation of average transition probabilities between partition sets . The abstraction technique is formal , in that it comes with guarantees on the introduced approximation that depend on the diameters of the partitions : as such , they can be tuned at will . Further in the case of Markov processes with unbounded state spaces , a procedure for precisely truncating the state space within a compact set is provided , together with an error bound that depends on the asymptotic properties of the transition kernel of the original process . The overall abstraction algorithm , which practically hinges on piecewise constant approximations of the density functions of the Markov process , is extended to higher - order function approximations : these can lead to improved error bounds and associated lower computational requirements . The approach is practically tested to compute probabilistic invariance of the Markov process under study , and is compared to a known alternative approach from the literature .
Dynamic Causality in Event Structures ( Technical Report )
In [ 1 ] we present an extension of Prime Event Structures by a mechanism to express dynamicity in the causal relation . More precisely we add the possibility that the occurrence of an event can add or remove causal dependencies between events and analyse the expressive power of the resulting Event Structures w.r.t . to some well - known Event Structures from the literature . This technical report contains some additional information and the missing proofs of [ 1 ] .
Temporal Logics for Hyperproperties
Two new logics for verification of hyperproperties are proposed . Hyperproperties characterize security policies , such as noninterference , as a property of sets of computation paths . Standard temporal logics such as LTL , CTL , and CTL * can refer only to a single path at a time , hence can not express many hyperproperties of interest . The logics proposed here , HyperLTL and HyperCTL * , add explicit and simultaneous quantification over multiple paths to LTL and to CTL*. This kind of quantification enables expression of hyperproperties . A model checking algorithm for the proposed logics is given . For a fragment of HyperLTL , a prototype model checker has been implemented .
Axioms for Definability and Full Completeness
Axioms are presented which encapsulate the properties satisfied by categories of games which form the basis of results on full abstraction for PCF and other programming languages , and on full completeness for various logics and type theories . Axioms are presented on models of PCF from which full abstraction can be proved . These axioms have been distilled from recent results on definability and full abstraction of game semantics for a number of programming languages . Full completeness for pure simply - typed $ \lambda$-calculus is also axiomatized .
Retracing some paths in Process Algebra
We use traced monoidal categories to give a precise general version of " geometry of interaction " . We give a number of examples of both " particle - style " and " wave - style " instances of this construction . We relate these ideas to semantics of computation .
Ranking Templates for Linear Loops
We present a new method for the constraint - based synthesis of termination arguments for linear loop programs based on linear ranking templates . Linear ranking templates are parametrized , well - founded relations such that an assignment to the parameters gives rise to a ranking function . This approach generalizes existing methods and enables us to use templates for many different ranking functions with affine - linear components . We discuss templates for multiphase , piecewise , and lexicographic ranking functions . Because these ranking templates require both strict and non - strict inequalities , we use Motzkin 's Transposition Theorem instead of Farkas Lemma to transform the generated $ \exists\forall$-constraint into an $ \exists$-constraint .
Linear Ranking for Linear Lasso Programs
The general setting of this work is the constraint - based synthesis of termination arguments . We consider a restricted class of programs called lasso programs . The termination argument for a lasso program is a pair of a ranking function and an invariant . We present the --- to the best of our knowledge --- first method to synthesize termination arguments for lasso programs that uses linear arithmetic . We prove a completeness theorem . The completeness theorem establishes that , even though we use only linear ( as opposed to non - linear ) constraint solving , we are able to compute termination arguments in several interesting cases . The key to our method lies in a constraint transformation that replaces a disjunction by a sum .
Ranking Function Synthesis for Linear Lasso Programs
The scope of this work is the constraint - based synthesis of termination arguments for the restricted class of programs called linear lasso programs . A termination argument consists of a ranking function as well as a set of supporting invariants . We extend existing methods in several ways . First , we use Motzkin 's Transposition Theorem instead of Farkas ' Lemma . This allows us to consider linear lasso programs that can additionally contain strict inequalities . Existing methods are restricted to non - strict inequalities and equalities . Second , we consider several kinds of ranking functions : affine - linear , piecewise and lexicographic ranking functions . Moreover , we present a novel kind of ranking function called multiphase ranking function which proceeds through a fixed number of phases such that for each phase , there is an affine - linear ranking function . As an abstraction to the synthesis of specific ranking functions , we introduce the notion ranking function template . This enables us to handle all ranking functions in a unified way . Our method relies on non - linear algebraic constraint solving as a subroutine which is known to scale poorly to large problems . As a mitigation we formalize an assessment of the difficulty of our constraints and present an argument why they are of an easier kind than general non - linear constraints . We prove our method to be complete : if there is a termination argument of the form specified by the given ranking function template with a fixed number of affine - linear supporting invariants , then our method will find a termination argument . To our knowledge , the approach we propose is the most powerful technique of synthesis - based discovery of termination arguments for linear lasso programs and encompasses and enhances several methods having been proposed thus far .
Game Semantics for Access Control
We introduce a semantic approach to the study of logics for access control and dependency analysis , based on Game Semantics . We use a variant of AJM games with explicit justification ( but without pointers ) . Based on this , we give a simple and intuitive model of the information flow constraints underlying access control . This is used to give strikingly simple proofs of \emph{non - interference theorems } in robust , semantic versions .
Monitoring Temporal Properties using Interval Analysis
Verification of temporal logic properties plays a crucial role in proving the desired behaviors of continuous systems . In this paper , we propose an interval method that verifies the properties described by a bounded signal temporal logic . We relax the problem so that if the verification process can not succeed at the prescribed precision , it outputs an inconclusive result . The problem is solved by an efficient and rigorous monitoring algorithm . This algorithm performs a forward simulation of a continuous - time dynamical system , detects a set of time intervals in which the atomic propositions hold , and validates the property by propagating the time intervals . In each step , the continuous state at a certain time is enclosed by an interval vector that is proven to contain a unique solution . We experimentally demonstrate the utility of the proposed method in formal analysis of nonlinear and complex continuous systems .
Ioco Theory for Probabilistic Automata
Model - based testing ( MBT ) is a well - known technology , which allows for automatic test case generation , execution and evaluation . To test non - functional properties , a number of test MBT frameworks have been developed to test systems with real - time , continuous behaviour , symbolic data and quantitative system aspects . Notably , a lot of these frameworks are based on Tretmans ' classical input / output conformance ( ioco ) framework . However , a model - based test theory handling probabilistic behaviour does not exist yet . Probability plays a role in many different systems : unreliable communication channels , randomized algorithms and communication protocols , service level agreements pinning down up - time percentages , etc . Therefore , a probabilistic test theory is of great practical importance . We present the ingredients for a probabilistic variant of ioco and define the { \pi}oco relation , show that it conservatively extends ioco and define the concepts of test case , execution and evaluation .
Cellular Automata are Generic
Any algorithm ( in the sense of Gurevich 's abstract - state - machine axiomatization of classical algorithms ) operating over any arbitrary unordered domain can be simulated by a dynamic cellular automaton , that is , by a pattern - directed cellular automaton with unconstrained topology and with the power to create new cells . The advantage is that the latter is closer to physical reality . The overhead of our simulation is quadratic .
Towards A Theory Of Quantum Computability
We propose a definition of quantum computable functions as mappings between superpositions of natural numbers to probability distributions of natural numbers . Each function is obtained as a limit of an infinite computation of a quantum Turing machine . The class of quantum computable functions is recursively enumerable , thus opening the door to a quantum computability theory which may follow some of the classical developments .
Linear Intransitive Temporal Logic of Knowledge LTK_r , Decision Algorithms , Inference Rules
Our paper investigates the linear logic of knowledge and time LTK_r with reflexive intransitive time relation . The logic is defined semantically , -- as the set of formulas which are true at special frames with intransitive and reflexive time binary relation . The LTK_r -frames are linear chains of clusters connected by a reflexive intransitive relation $ R_T$. Elements inside a cluster are connected by several equivalence relations imitating the knowledge of different agents . We study the decidability problem for formulas and inference rules . Decidability for formulas follows from decidability w.r.t . admissible inference rules . To study admissibility , we introduce some special constructive Kripke models useful for description of admissibility of inference rules . With a special technique of definable valuations we find an algorithm determining admissible inference rules in LTK_r . That is , we show that the logic LTK_r is decidable and decidable with respect to admissibility of inference rules .
Morphoid Type Theory
Morphoid type theory ( MorTT ) is a typed foundation for mathematics extending classical predicate calculus under Platonic compositional semantics and supporting the concept of isomorphism . MorTT provides a formal account of the substitution of isomorphics , the distinction between general functions and natural maps , and " Voldemort 's theorem " stating that certain objects exist but can not be named . For example , there is no natural point on a geometric circle --- no point on a geometric circle can be named by a well - typed expression . Similarly it is not possible to name any particular basis for a vector space or any particular isomorphism of a finite dimensional vector space with its dual . Homotopy type theory ( HoTT ) also provides a formal account of isomorphism but extends constructive logic rather than classical predicate calculus . MorTT 's classical approach avoids HoTT 's propositions - as - types , path induction , squashing and higher order isomorphisms . Unlike HoTT , MorTT is designed to be compatible with Platonic mathematical thought .
Parameterized Model - Checking for Timed - Systems with Conjunctive Guards ( Extended Version )
In this work we extend the Emerson and Kahlon 's cutoff theorems for process skeletons with conjunctive guards to Parameterized Networks of Timed Automata , i.e. systems obtained by an \emph{apriori } unknown number of Timed Automata instantiated from a finite set $ U_1 , \dots , U_n$ of Timed Automata templates . In this way we aim at giving a tool to universally verify software systems where an unknown number of software components ( i.e. processes ) interact with continuous time temporal constraints . It is often the case , indeed , that distributed algorithms show an heterogeneous nature , combining dynamic aspects with real - time aspects . In the paper we will also show how to model check a protocol that uses special variables storing identifiers of the participating processes ( i.e. PIDs ) in Timed Automata with conjunctive guards . This is non - trivial , since solutions to the parameterized verification problem often relies on the processes to be symmetric , i.e. indistinguishable . On the other side , many popular distributed algorithms make use of PIDs and thus can not directly apply those solutions .
On CSP and the Algebraic Theory of Effects
We consider CSP from the point of view of the algebraic theory of effects , which classifies operations as effect constructors or effect deconstructors ; it also provides a link with functional programming , being a refinement of Moggi 's seminal monadic point of view . There is a natural algebraic theory of the constructors whose free algebra functor is Moggi 's monad ; we illustrate this by characterising free and initial algebras in terms of two versions of the stable failures model of CSP , one more general than the other . Deconstructors are dealt with as homomorphisms to ( possibly non - free ) algebras . One can view CSP 's action and choice operators as constructors and the rest , such as concealment and concurrency , as deconstructors . Carrying this programme out results in taking deterministic external choice as constructor rather than general external choice . However , binary deconstructors , such as the CSP concurrency operator , provide unresolved difficulties . We conclude by presenting a combination of CSP with Moggi 's computational { \lambda}-calculus , in which the operators , including concurrency , are polymorphic . While the paper mainly concerns CSP , it ought to be possible to carry over similar ideas to other process calculi .
The Coarsest Precongruences Respecting Safety and Liveness Properties
This paper characterises the coarsest refinement preorders on labelled transition systems that are precongruences for renaming and partially synchronous interleaving operators , and respect all safety , liveness , and conditional liveness properties , respectively .
Sequential Convex Programming for the Efficient Verification of Parametric MDPs
Multi - objective verification problems of parametric Markov decision processes under optimality criteria can be naturally expressed as nonlinear programs . We observe that many of these computationally demanding problems belong to the subclass of signomial programs . This insight allows for a sequential optimization algorithm to efficiently compute sound but possibly suboptimal solutions . Each stage of this algorithm solves a geometric programming problem . These geometric programs are obtained by convexifying the nonconvex constraints of the original problem . Direct applications of the encodings as nonlinear pro- grams are model repair and parameter synthesis . We demonstrate the scalability and quality of our approach by well - known benchmarks
Blocked Clauses in First - Order Logic
Blocked clauses provide the basis for powerful reasoning techniques used in SAT , QBF , and DQBF solving . Their definition , which relies on a simple syntactic criterion , guarantees that they are both redundant and easy to find . In this paper , we lift the notion of blocked clauses to first - order logic . We introduce two types of blocked clauses , one for first - order logic with equality and the other for first - order logic without equality , and prove their redundancy . In addition , we give a polynomial algorithm for checking whether a clause is blocked . Based on our new notions of blocking , we implemented a novel first - order preprocessing tool . Our experiments showed that many first - order problems in the TPTP library contain a large number of blocked clauses . Moreover , we observed that their elimination can improve the performance of modern theorem provers , especially on satisfiable problem instances .
Completeness for Two Left - Sequential Logics
Left - sequential logics provide a means for reasoning about ( closed ) propositional terms with atomic propositions that may have side effects and that are evaluated sequentially from left to right . Such propositional terms are commonly used in programming languages to direct the flow of a program . In this thesis we explore two such left - sequential logics . First we discuss Fully Evaluated Left - Sequential Logic , which employs a full evaluation strategy , i.e. , to evaluate a term every one of its atomic propositions is evaluated causing its possible side effects to occur . We then turn to Short - Circuit ( Left - Sequential ) Logic as presented in [ BP10b ] , where the evaluation may be ' short - circuited ' , thus preventing some , if not all , of the atomic propositions in a term being evaluated . We propose evaluation trees as a natural semantics for both logics and provide axiomatizations for the least identifying variant of each . From this , we define a logic with connectives that prescribe a full evaluation strategy as well as connectives that prescribe a short - circuit evaluation strategy .
A Logic with Reverse Modalities for History - preserving Bisimulations
We introduce event identifier logic ( EIL ) which extends Hennessy - Milner logic by the addition of ( 1 ) reverse as well as forward modalities , and ( 2 ) identifiers to keep track of events . We show that this logic corresponds to hereditary history - preserving ( HH ) bisimulation equivalence within a particular true - concurrency model , namely stable configuration structures . We furthermore show how natural sublogics of EIL correspond to coarser equivalences . In particular we provide logical characterisations of weak history - preserving ( WH ) and history - preserving ( H ) bisimulation . Logics corresponding to HH and H bisimulation have been given previously , but not to WH bisimulation ( when autoconcurrency is allowed ) , as far as we are aware . We also present characteristic formulas which characterise individual structures with respect to history - preserving equivalences .
Synchrony vs Causality in the Asynchronous Pi - Calculus
We study the relation between process calculi that differ in their either synchronous or asynchronous interaction mechanism . Concretely , we are interested in the conditions under which synchronous interaction can be implemented using just asynchronous interactions in the pi - calculus . We assume a number of minimal conditions referring to the work of Gorla : a " good " encoding must be compositional and preserve and reflect computations , deadlocks , divergence , and success . Under these conditions , we show that it is not possible to encode synchronous interactions without introducing additional causal dependencies in the translation .
Graphical representation of covariant - contravariant modal formulae
Covariant - contravariant simulation is a combination of standard ( covariant ) simulation , its contravariant counterpart and bisimulation . We have previously studied its logical characterization by means of the covariant - contravariant modal logic . Moreover , we have investigated the relationships between this model and that of modal transition systems , where two kinds of transitions ( the so - called may and must transitions ) were combined in order to obtain a simple framework to express a notion of refinement over state - transition models . In a classic paper , Boudol and Larsen established a precise connection between the graphical approach , by means of modal transition systems , and the logical approach , based on Hennessy - Milner logic without negation , to system specification . They obtained a ( graphical ) representation theorem proving that a formula can be represented by a term if , and only if , it is consistent and prime . We show in this paper that the formulae from the covariant - contravariant modal logic that admit a " graphical " representation by means of processes , modulo the covariant - contravariant simulation preorder , are also the consistent and prime ones . In order to obtain the desired graphical representation result , we first restrict ourselves to the case of covariant - contravariant systems without bivariant actions . Bivariant actions can be incorporated later by means of an encoding that splits each bivariant action into its covariant and its contravariant parts .
Each normal logic program has a 2-valued Minimal Hypotheses semantics
In this paper we explore a unifying approach --- that of hypotheses assumption --- as a means to provide a semantics for all Normal Logic Programs ( NLPs ) , the Minimal Hypotheses ( MH ) semantics . This semantics takes a positive hypotheses assumption approach as a means to guarantee the desirable properties of model existence , relevance and cumulativity , and of generalizing the Stable Models in the process . To do so we first introduce the fundamental semantic concept of minimality of assumed positive hypotheses , define the MH semantics , and analyze the semantics ' properties and applicability . Indeed , abductive Logic Programming can be conceptually captured by a strategy centered on the assumption of abducibles ( or hypotheses ) . Likewise , the Argumentation perspective of Logic Programs also lends itself to an arguments ( or hypotheses ) assumption approach . Previous works on Abduction have depicted the atoms of default negated literals in NLPs as abducibles , i.e. , assumable hypotheses . We take a complementary and more general view than these works to NLP semantics by employing positive hypotheses instead .
Transfer of semantics from argumentation frameworks to logic programming A preliminary report
There are various interesting semantics ' ( extensions ) designed for argumentation frameworks . They enable to assign a meaning , e.g. , to odd - length cycles . Our main motivation is to transfer semantics ' proposed by Baroni , Giacomin and Guida for argumetation frameworks with odd - length cycles to logic programs with odd - length cycles through default negation . The developed construction is even stronger . For a given logic program an argumentation framework is defined . The construction enables to transfer each semantics of the resulting argumentation framework to a semantics of the given logic program . Weak points of the construction are discussed and some future continuations of this approach are outlined .
Assembling the Proofs of Ordered Model Transformations
In model - driven development , an ordered model transformation is a nested set of transformations between source and target classes , in which each transformation is governed by its own pre and post- conditions , but structurally dependent on its parent . Following the proofs - as - model - transformations approach , in this paper we consider a formalisation in Constructive Type Theory of the concepts of model and model transformation , and show how the correctness proofs of potentially large ordered model transformations can be systematically assembled from the proofs of the specifications of their parts , making them easier to derive .
A Labelled Sequent Calculus for BBI : Proof Theory and Proof Search
We present a labelled sequent calculus for Boolean BI , a classical variant of O'Hearn and Pym 's logic of Bunched Implication . The calculus is simple , sound , complete , and enjoys cut - elimination . We show that all the structural rules in our proof system , including those rules that manipulate labels , can be localised around applications of certain logical rules , thereby localising the handling of these rules in proof search . Based on this , we demonstrate a free variable calculus that deals with the structural rules lazily in a constraint system . A heuristic method to solve the constraints is proposed in the end , with some experimental results .
A Proof Procedure for Hybrid Logic with Binders , Transitivity and Relation Hierarchies ( extended version )
In previous works , a tableau calculus has been defined , which constitutes a decision procedure for hybrid logic with the converse and global modalities and a restricted use of the binder . This work shows how to extend such a calculus to multi - modal logic enriched with features largely used in description logics : transitivity and relation inclusion assertions . The separate addition of either transitive relations or relation hierarchies to the considered decidable fragment of multi - modal hybrid logic can easily be shown to stay decidable , by resorting to results already proved in the literature . However , such results do not directly allow for concluding whether the logic including both features is still decidable . The existence of a terminating , sound and complete calculus for the considered logic proves that the addition of transitive relations and relation hierarchies to such an expressive decidable fragment of hybrid logic does not endanger decidability . A further result proved in this work is that the logic extending the considered fragment with the addition of graded modalities ( the modal counterpart of number restrictions of description logics ) has an undecidable satisfiability problem , unless further syntactical restrictions are placed on the universal graded modality .
Interpolation Properties and SAT - based Model Checking
Craig interpolation is a widespread method in verification , with important applications such as Predicate Abstraction , CounterExample Guided Abstraction Refinement and Lazy Abstraction With Interpolants . Most state - of - the - art model checking techniques based on interpolation require collections of interpolants to satisfy particular properties , to which we refer as " collectives " ; they do not hold in general for all interpolation systems and have to be established for each particular system and verification environment . Nevertheless , no systematic approach exists that correlates the individual interpolation systems and compares the necessary collectives . This paper proposes a uniform framework , which encompasses ( and generalizes ) the most common collectives exploited in verification . We use it for a systematic study of the collectives and of the constraints they pose on propositional interpolation systems used in SAT - based model checking .
Communication , and concurrency with logic - based restriction inside a calculus of structures
It is well known that we can use structural proof theory to refine , or generalize , existing paradigmatic computational primitives , or to discover new ones . Under such a point of view we keep developing a programme whose goal is establishing a correspondence between proof - search of a logical system and computations in a process algebra . We give a purely logical account of a process algebra operation which strictly includes the behavior of restriction on actions we find in Milner CCS . This is possible inside a logical system in the Calculus of Structures of Deep Inference endowed with a self - dual quantifier . Using proof - search of cut - free proofs of such a logical system we show how to solve reachability problems in a process algebra that subsumes a significant fragment of Milner CCS .
Extending a system in the calculus of structures with a self - dual quantifier
We recall that SBV , a proof system developed under the methodology of deep inference , extends multiplicative linear logic with the self - dual non - commutative logical operator Seq . We introduce SBVQ that extends SBV by adding the self - dual quantifier Sdq . The system SBVQ is consistent because we prove that ( the analogous of ) cut elimination holds for it . Its new logical operator Sdq operationally behaves as a binder , in a way that the interplay between Seq , and Sdq can model { \beta}-reduction of linear { \lambda}-calculus inside the cut - free subsystem BVQ of SBVQ . The long term aim is to keep developing a programme whose goal is to give pure logical accounts of computational primitives under the proof - search - as - computation analogy , by means of minimal , and incremental extensions of SBV .
Refinement and Difference for Probabilistic Automata
This paper studies a difference operator for stochastic systems whose specifications are represented by Abstract Probabilistic Automata ( APAs ) . In the case refinement fails between two specifications , the target of this operator is to produce a specification APA that represents all witness PAs of this failure . Our contribution is an algorithm that allows to approximate the difference of two APAs with arbitrary precision . Our technique relies on new quantitative notions of distances between APAs used to assess convergence of the approximations , as well as on an in - depth inspection of the refinement relation for APAs . The procedure is effective and not more complex to implement than refinement checking .
Parametricity in an Impredicative Sort
Reynold 's abstraction theorem is now a well - established result for a large class of type systems . We propose here a definition of relational parametricity and a proof of the abstraction theorem in the Calculus of Inductive Constructions ( CIC ) , the underlying formal language of Coq , in which parametricity relations ' codomain is the impredicative sort of propositions . To proceed , we need to refine this calculus by splitting the sort hierarchy to separate informative terms from non - informative terms . This refinement is very close to CIC , but with the property that typing judgments can distinguish informative terms . Among many applications , this natural encoding of parametricity inside CIC serves both theoretical purposes ( proving the independence of propositions with respect to the logical system ) as well as practical aspirations ( proving properties of finite algebraic structures ) . We finally discuss how we can simply build , on top of our calculus , a new reflexive Coq tactic that constructs proof terms by parametricity .
GEM : a Distributed Goal Evaluation Algorithm for Trust Management
Trust management is an approach to access control in distributed systems where access decisions are based on policy statements issued by multiple principals and stored in a distributed manner . In trust management , the policy statements of a principal can refer to other principals ' statements ; thus , the process of evaluating an access request ( i.e. , a goal ) consists of finding a " chain " of policy statements that allows the access to the requested resource . Most existing goal evaluation algorithms for trust management either rely on a centralized evaluation strategy , which consists of collecting all the relevant policy statements in a single location ( and therefore they do not guarantee the confidentiality of intensional policies ) , or do not detect the termination of the computation ( i.e. , when all the answers of a goal are computed ) . In this paper we present GEM , a distributed goal evaluation algorithm for trust management systems that relies on function - free logic programming for the specification of policy statements . GEM detects termination in a completely distributed way without disclosing intensional policies , thereby preserving their confidentiality . We demonstrate that the algorithm terminates and is sound and complete with respect to the standard semantics for logic programs .
A TLA+ Proof System
We describe an extension to the TLA+ specification language with constructs for writing proofs and a proof environment , called the Proof Manager ( PM ) , to checks those proofs . The language and the PM support the incremental development and checking of hierarchically structured proofs . The PM translates a proof into a set of independent proof obligations and calls upon a collection of back - end provers to verify them . Different provers can be used to verify different obligations . The currently supported back - ends are the tableau prover Zenon and Isabelle / TLA+ , an axiomatisation of TLA+ in Isabelle / Pure . The proof obligations for a complete TLA+ proof can also be used to certify the theorem in Isabelle / TLA+ .
Bounded Variability of Metric Temporal Logic
Previous work has shown that reasoning with real - time temporal logics is often simpler when restricted to models with bounded variability --- where no more than v events may occur every V time units , for given v , V. When reasoning about formulas with intrinsic bounded variability , one can employ the simpler techniques that rely on bounded variability , without any loss of generality . What is then the complexity of algorithmically deciding which formulas have intrinsic bounded variability ? In this paper , we study the problem with reference to Metric Temporal Logic ( MTL ) . We prove that deciding bounded variability of MTL formulas is undecidable over dense - time models , but with a undecidability degree lower than generic dense - time MTL satisfiability . Over discrete - time models , instead , deciding MTL bounded variability has the same exponential - space complexity as satisfiability . To complement these negative results , we also briefly discuss small fragments of MTL that are more amenable to reasoning about bounded variability .
Confluence of an extension of Combinatory Logic by Boolean Constants
We show confluence of a conditional term rewriting system CL - pc${}^1 $ , which is an extension of Combinatory Logic by Boolean constants . This solves problem 15 from the RTA list of open problems . The proof has been fully formalised in the Coq proof assistant .
The MMT API : A Generic MKM System
The MMT language has been developed as a scalable representation and interchange language for formal mathematical knowledge . It permits natural representations of the syntax and semantics of virtually all declarative languages while making MMT - based MKM services easy to implement . It is foundationally unconstrained and can be instantiated with specific formal languages . The MMT API implements the MMT language along with multiple backends for persistent storage and frontends for machine and user access . Moreover , it implements a wide variety of MMT - based knowledge management services . The API and all services are generic and can be applied to any language represented in MMT . A plugin interface permits injecting syntactic and semantic idiosyncrasies of individual formal languages .
On the quantifier - free dynamic complexity of Reachability
The dynamic complexity of the reachability query is studied in the dynamic complexity framework of Patnaik and Immerman , restricted to quantifier - free update formulas . It is shown that , with this restriction , the reachability query can not be dynamically maintained , neither with binary auxiliary relations nor with unary auxiliary functions , and that ternary auxiliary relations are more powerful with respect to graph queries than binary auxiliary relations . Further inexpressibility results are given for the reachability query in a different setting as well as for a syntactical restriction of quantifier - free update formulas . Moreover inexpressibility results for some other queries are presented .
Propositional Dynamic Logic with Converse and Repeat for Message - Passing Systems
The model checking problem for propositional dynamic logic ( PDL ) over message sequence charts ( MSCs ) and communicating finite state machines ( CFMs ) asks , given a channel bound $ B$ , a PDL formula $ \varphi$ and a CFM $ \mathcal{C}$ , whether every existentially $ B$-bounded MSC $ M$ accepted by $ \mathcal{C}$ satisfies $ \varphi$. Recently , it was shown that this problem is PSPACE - complete . In the present work , we consider CRPDL over MSCs which is PDL equipped with the operators converse and repeat . The former enables one to walk back and forth within an MSC using a single path expression whereas the latter allows to express that a path expression can be repeated infinitely often . To solve the model checking problem for this logic , we define message sequence chart automata ( MSCAs ) which are multi - way alternating parity automata walking on MSCs . By exploiting a new concept called concatenation states , we are able to inductively construct , for every CRPDL formula $ \varphi$ , an MSCA precisely accepting the set of models of $ \varphi$. As a result , we obtain that the model checking problem for CRPDL and CFMs is still in PSPACE .
Hierarchy of persistence with respect to the length of action 's disability
The notion of persistence , based on the rule " no action can disable another one " is one of the classical notions in concurrency theory . It is also one of the issues discussed in the Petri net theory . We recall two ways of generalization of this notion : the first is " no action can kill another one " ( called l / l - persistence ) and the second " no action can kill another enabled one " ( called the delayed persistence , or shortly e / l - persistence ) . Afterwards we introduce a more precise notion , called e / l - k - persistence , in which one action disables another one for no longer than a specified number k of single sequential steps . Then we consider an infinite hie\-rarchy of such e / l - k persistencies . We prove that if an action is disabled , and not killed , by another one , it can not be postponed indefinitely . Afterwards , we investigate the set of markings in which two actions are enabled simultaneously , and also the set of reachable markings with that feature . We show that the minimum of the latter is finite and effectively computable . Finally we deal with decision problems about e / l - k persistencies . We show that all the kinds of e / l - k persistencies are decidable with respect to steps , markings and nets .
Horn Linear Logic and Minsky Machines
Here we give a detailed proof for the crucial point in our Minsky machine simulation - that any linear logic derivation for a specific Horn sequent can be transformed into a Minsky computation leading from an initial configuration to the halting configuration . Among other things , the presentation advantage of the 3-step program is that the non - trivial tricky points are distributed between the independent parts each of which we justify following its own intrinsic methodology ( to say nothing of the induction used in the opposite directions ) : ( 1 ) From LL to HLL - we use purely proof - theoretic arguments . ( 2 ) From HLL to Horn programs - we translate trees ( HLL derivations ) into another trees ( Horn programs)of the same shape , almost . ( 3 ) From Horn programs to Minsky computations - we use purely computational arguments .
Typed realizability for first - order classical analysis
We describe a realizability framework for classical first - order logic in which realizers live in ( a model of ) typed { \lambda}{\mu}-calculus . This allows a direct interpretation of classical proofs , avoiding the usual negative translation to intuitionistic logic . We prove that the usual terms of G\"odel 's system T realize the axioms of Peano arithmetic , and that under some assumptions on the computational model , the bar recursion operator realizes the axiom of dependent choice . We also perform a proper analysis of relativization , which allows for less technical proofs of adequacy . Extraction of algorithms from proofs of { \Pi}02 formulas relies on a novel implementation of Friedman 's trick exploiting the control possibilities of the language . This allows to have extracted programs with simpler types than in the case of negative translation followed by intuitionistic realizability .
A Foundational View on Integration Problems
The integration of reasoning and computation services across system and language boundaries is a challenging problem of computer science . In this paper , we use integration for the scenario where we have two systems that we integrate by moving problems and solutions between them . While this scenario is often approached from an engineering perspective , we take a foundational view . Based on the generic declarative language MMT , we develop a theoretical framework for system integration using theories and partial theory morphisms . Because MMT permits representations of the meta - logical foundations themselves , this includes integration across logics . We discuss safe and unsafe integration schemes and devise a general form of safe integration .
Weak Affine Light Typing : Polytime intensional expressivity , soundness and completeness
Weak affine light typing ( WALT ) assigns light affine linear formulae as types to a subset of lambda - terms in System F. WALT is poly - time sound : if a lambda - term M has type in WALT , M can be evaluated with a polynomial cost in the dimension of the derivation that gives it a type . In particular , the evaluation can proceed under any strategy of a rewriting relation , obtained as a mix of both call - by - name / call - by - value beta - reductions . WALT is poly - time complete since it can represent any poly - time Turing machine . WALT weakens , namely generalizes , the notion of stratification of deductions common to some Light Systems -- we call as such those logical systems , derived from Linear logic , to characterize FP , the set of Polynomial functions -- . A weaker stratification allows to define a compositional embedding of the Quasi - linear fragment QlSRN of Safe recursion on notation ( SRN ) into WALT . QlSRN is SRN , which is a recursive - theoretical system characterizing FP , where only the composition scheme is restricted to linear safe variables . So , the expressivity of WALT is stronger , as compared to the known Light Systems . In particular , using the types , the embedding puts in evidence the stratification of normal and safe arguments hidden in QlSRN : the less an argument is impredicative , the deeper , in a formal , proof - theoretical sense , gets its representation in WALT .
Finite Automata Based on Quantum Logic and Their Determinization
We give the quantum subset construction of orthomodular lattice - valued finite automata , then we show the equivalence between orthomodular lattice - valued finite automata , orthomodular lattice - valued deterministic finite automata and orthomodular lattice - valued finite automata with empty string - moves . Based on these equivalences , we study the algebraic operations on orthomodular lattice - valued regular languages , then we establish Kleene theorem in the frame of quantum logic .
On the strictness of the quantifier structure hierarchy in first - order logic
We study a natural hierarchy in first - order logic , namely the quantifier structure hierarchy , which gives a systematic classification of first - order formulas based on structural quantifier resource . We define a variant of Ehrenfeucht - Fraisse games that characterizes quantifier classes and use it to prove that this hierarchy is strict over finite structures , using strategy compositions . Moreover , we prove that this hierarchy is strict even over ordered finite structures , which is interesting in the context of descriptive complexity .
The Power of Priority Channel Systems
We introduce Priority Channel Systems , a new class of channel systems where messages carry a numeric priority and where higher - priority messages can supersede lower - priority messages preceding them in the fifo communication buffers . The decidability of safety and inevitability properties is shown via the introduction of a priority embedding , a well - quasi - ordering that has not previously been used in well - structured systems . We then show how Priority Channel Systems can compute Fast - Growing functions and prove that the aforementioned verification problems are $ \mathbf{F}_{\varepsilon_{0}}$-complete .
A Type - Theoretic Approach to Structural Resolution
Structural resolution ( or S - resolution ) is a newly proposed alternative to SLD - resolution that allows a systematic separation of derivations into term - matching and unification steps . Productive logic programs are those for which term - matching reduction on any query must terminate . For productive programs with coinductive meaning , finite term - rewriting reductions can be seen as measures of observation in an infinite derivation . Ability of handling corecursion in a productive way is an attractive computational feature of S - resolution . In this paper , we make first steps towards a better conceptual understanding of operational properties of S - resolution as compared to SLD - resolution . To this aim , we propose a type system for the analysis of both SLD - resolution and S - resolution . We formulate S - resolution and SLD - resolution as reduction systems , and show their soundness relative to the type system . One of the central methods of this paper is realizability transformation , which makes logic programs productive and non - overlapping . We show that S - resolution and SLD - resolution are only equivalent for programs with these two properties .
Abstract Model Repair
Given a Kripke structure M and CTL formula $ \varphi$ , where M does not satisfy $ \varphi$ , the problem of Model Repair is to obtain a new model M ' such that M ' satisfies $ \varphi$. Moreover , the changes made to M to derive M ' should be minimum with respect to all such M ' . As in model checking , state explosion can make it virtually impossible to carry out model repair on models with infinite or even large state spaces . In this paper , we present a framework for model repair that uses abstraction refinement to tackle state explosion . Our framework aims to repair Kripke Structure models based on a Kripke Modal Transition System abstraction and a 3-valued semantics for CTL . We introduce an abstract - model - repair algorithm for which we prove soundness and semi - completeness , and we study its complexity class . Moreover , a prototype implementation is presented to illustrate the practical utility of abstract - model - repair on an Automatic Door Opener system model and a model of the Andrew File System 1 protocol .
Applicative Bisimulation and Quantum $ l$-Calculi ( Long Version )
Applicative bisimulation is a coinductive technique to check program equivalence in higher - order functional languages . It is known to be sound , and sometimes complete , with respect to context equivalence . In this paper we show that applicative bisimulation also works when the underlying language of programs takes the form of a linear $ \lambda$-calculus extended with features such as probabilistic binary choice , but also quantum data , the latter being a setting in which linearity plays a role . The main results are proofs of soundness for the obtained notions of bisimilarity .
Partial functions and domination
The current work introduces the notion of pdominant sets and studies their recursion - theoretic properties . Here a set A is called pdominant iff there is a partial A - recursive function { \psi } such that for every partial recursive function { \phi } and almost every x in the domain of { \phi } there is a y in the domain of { \psi } with y<= x and { \psi}(y ) > { \phi}(x ) . While there is a full { \pi}01-class of nonrecursive sets where no set is pdominant , there is no { \pi}01-class containing only pdominant sets . No weakly 2-generic set is pdominant while there are pdominant 1-generic sets below K. The halves of Chaitin 's { \Omega } are pdominant . No set which is low for Martin - L\"of random is pdominant . There is a low r.e . set which is pdominant and a high r.e . set which is not pdominant .
A new graphical calculus of proofs
We offer a simple graphical representation for proofs of intuitionistic logic , which is inspired by proof nets and interaction nets ( two formalisms originating in linear logic ) . This graphical calculus of proofs inherits good features from each , but is not constrained by them . By the Curry - Howard isomorphism , the representation applies equally to the lambda calculus , offering an alternative diagrammatic representation of functional computations .
An Algebraic Approach for Approximity
Comparison to traditionally accurate computing , approximate computing focuses on the rapidity of the satisfactory solution , but not the unnecessary accuracy of the solution . Approximate bisimularity is the approximate one corresponding to traditionally accurate bisimilarity . Based on the work of distances between basic processes , we propose an algebraic approach for distances between processes to support a whole process calculus CCS , which contains prefix , sum , composition , restriction , relabeling and recursion .
Proof Relevant Corecursive Resolution
Resolution lies at the foundation of both logic programming and type class context reduction in functional languages . Terminating derivations by resolution have well - defined inductive meaning , whereas some non - terminating derivations can be understood coinductively . Cycle detection is a popular method to capture a small subset of such derivations . We show that in fact cycle detection is a restricted form of coinductive proof , in which the atomic formula forming the cycle plays the role of coinductive hypothesis . This paper introduces a heuristic method for obtaining richer coinductive hypotheses in the form of Horn formulas . Our approach subsumes cycle detection and gives coinductive meaning to a larger class of derivations . For this purpose we extend resolution with Horn formula resolvents and corecursive evidence generation . We illustrate our method on non - terminating type class resolution problems .
Sampling Techniques for Boolean Satisfiability
Boolean satisfiability ( { \SAT } ) has played a key role in diverse areas spanning testing , formal verification , planning , optimization , inferencing and the like . Apart from the classical problem of checking boolean satisfiability , the problems of generating satisfying uniformly at random , and of counting the total number of satisfying assignments have also attracted significant theoretical and practical interest over the years . Prior work offered heuristic approaches with very weak or no guarantee of performance , and theoretical approaches with proven guarantees , but poor performance in practice . We propose a novel approach based on limited - independence hashing that allows us to design algorithms for both problems , with strong theoretical guarantees and scalability extending to thousands of variables . Based on this approach , we present two practical algorithms , { \UniformWitness } : a near uniform generator and { \approxMC } : the first scalable approximate model counter , along with reference implementations . Our algorithms work by issuing polynomial calls to { \SAT } solver . We demonstrate scalability of our algorithms over a large set of benchmarks arising from different application domains .
A Family of Descriptive Approaches To Preferred Answer Sets
In logic programming under the answer set semantics , preferences on rules are used to choose which of the conflicting rules are applied . Many interesting semantics have been proposed . Brewka and Eiter 's Principle I expresses the basic intuition behind the preferences . All the approaches that satisfy Principle I introduce a rather imperative feature into otherwise declarative language . They understand preferences as the order , in which the rules of a program have to be applied . In this paper we present two purely declarative approaches for preference handling that satisfy Principle I , and work for general conflicts , including direct and indirect conflicts between rules . The first approach is based on the idea that a rule can not be defeated by a less preferred conflicting rule . This approach is able to ignore preferences between non - conflicting rules , and , for instance , is equivalent with the answer set semantics for the subclass of stratified programs . It is suitable for the scenarios , when developers do not have full control over preferences . The second approach relaxes the requirement for ignoring conflicting rules , which ensures that it stays in the NP complexity class . It is based on the idea that a rule can not be defeated by a rule that is less preferred or depends on a less preferred rule . The second approach can be also characterized by a transformation to logic programs without preferences . It turns out that the approaches form a hierarchy , a branch in the hierarchy of the approaches by Delgrande et . al . , Wang et . al . , and Brewka and Eiter . Finally , we show an application for which the existing approaches are not usable , and the approaches of this paper produce expected results .
Partially Punctual Metric Temporal Logic is Decidable
Metric Temporal Logic $ \mathsf{MTL}[\until_I,\since_I]$ is one of the most studied real time logics . It exhibits considerable diversity in expressiveness and decidability properties based on the permitted set of modalities and the nature of time interval constraints $ I$. Henzinger et al . , in their seminal paper showed that the non - punctual fragment of $ \mathsf{MTL}$ called $ \mathsf{MITL}$ is decidable . In this paper , we sharpen this decidability result by showing that the partially punctual fragment of $ \mathsf{MTL}$ ( denoted $ \mathsf{PMTL}$ ) is decidable over strictly monotonic finite point wise time . In this fragment , we allow either punctual future modalities , or punctual past modalities , but never both together . We give two satisfiability preserving reductions from $ \mathsf{PMTL}$ to the decidable logic $ \mathsf{MTL}[\until_I]$. The first reduction uses simple projections , while the second reduction uses a novel technique of temporal projections with oversampling . We study the trade - off between the two reductions : while the second reduction allows the introduction of extra action points in the underlying model , the equisatisfiable $ \mathsf{MTL}[\until_I]$ formula obtained is exponentially succinct than the one obtained via the first reduction , where no oversampling of the underlying model is needed . We also show that $ \mathsf{PMTL}$ is strictly more expressive than the fragments $ \mathsf{MTL}[\until_I,\since]$ and $ \mathsf{MTL}[\until,\since_I]$.
Nagoya Termination Tool
This paper describes the implementation and techniques of the Nagoya Termination Tool , a termination prover for term rewrite systems . The main features of the tool are : the first implementation of the weighted path order which subsumes most of the existing reduction pairs , and the efficiency due to the strong cooperation with external SMT solvers . We present some new ideas that contribute to the efficiency and power of the tool .
Dividing Line between Decidable PDA 's and Undecidable Ones
Senizergues has proved that language equivalence is decidable for disjoint epsilon - deterministic PDA . Stirling has showed that strong bisimilarity is decidable for PDA . On the negative side Srba demonstrated that the weak bisimilarity is undecidable for normed PDA . Later Jancar and Srba established the undecidability of the weak bisimilarity for disjoint epsilon - pushing PDA and disjoint epsilon - popping PDA . These decidability and undecidability results are extended in the present paper . The extension is accomplished by looking at the equivalence checking issue for the branching bisimilarity of several variants of PDA .
First - Order Formative Rules
This paper discusses the method of formative rules for first - order term rewriting , which was previously defined for a higher - order setting . Dual to the well - known usable rules , formative rules allow dropping some of the term constraints that need to be solved during a termination proof . Compared to the higher - order definition , the first - order setting allows for significant improvements of the technique .
Weak MSO+U with Path Quantifiers over Infinite Trees
This paper shows that over infinite trees , satisfiability is decidable for weak monadic second - order logic extended by the unbounding quantifier U and quantification over infinite paths . The proof is by reduction to emptiness for a certain automaton model , while emptiness for the automaton model is decided using profinite trees .
Possible values : exploring a concept for concurrency
An important issue in concurrency is interference . This issue manifests itself in both shared - variable and communication - based concurrency --- this paper focusses on the former case where interference is caused by the environment of a process changing the values of shared variables . Rely / guarantee approaches have been shown to be useful in specifying and reasoning compositionally about concurrent programs . This paper explores the use of a " possible values " notation for reasoning about variables whose values can be changed multiple times by interference . Apart from the value of this concept in providing clear specifications , it offers a principled way of avoiding the need for some auxiliary ( or ghost ) variables whose unwise use can destroy compositionality .
Property Checking By Logic Relaxation
We introduce a new framework for Property Checking ( PC ) of sequential circuits . It is based on a method called Lo - gic Relaxation ( LoR ) . Given a safety property , the LoR method relaxes the transition system at hand , which leads to expanding the set of reachable states . For j - th time frame , the LoR method computes a superset A_j of the set of bad states reachable in j transitions only by the relaxed system . Set A_j is constructed by a technique called partial quantifier elimination . If A_j does not contain a bad state and this state is reachable in j transitions in the relaxed system , it is also reachable in the original system . Hence the property in question does not hold . The appeal of PC by LoR is as follows . An inductive invariant ( or a counterexample ) generated by LoR is a result of computing the states reachable only in the relaxed system . So , the complexity of PC can be drastically reduced by finding a " faulty " relaxation that is close to the original system . This is analogous to equivalence checking whose complexity strongly depends on how similar the designs to be compared are .
Termination of LCTRSs
Logically Constrained Term Rewriting Systems ( LCTRSs ) provide a general framework for term rewriting with constraints . We discuss a simple dependency pair approach to prove termination of LCTRSs . We see that existing techniques transfer to the constrained setting in a natural way .
The structure of finite meadows
A meadow is a commutative ring with a total inverse operator satisfying 0^{-1}=0 . We show that the class of finite meadows is the closure of the class of Galois fields under finite products . As a corollary , we obtain a unique representation of minimal finite meadows in terms of finite prime fields .
Models and theories of lambda calculus
In this paper we briefly summarize the contents of Manzonetto 's PhD thesis which concerns denotational semantics and equational / order theories of the pure untyped lambda - calculus . The main research achievements include : ( i ) a general construction of lambda - models from reflexive objects in ( possibly non - well - pointed ) categories ; ( ii ) a Stone - style representation theorem for combinatory algebras ; ( iii ) a proof that no effective lambda - model can have lambda - beta or lambda - beta - eta as its equational theory ( this can be seen as a partial answer to an open problem introduced by Honsell - Ronchi Della Rocca in 1984 ) .
A decidable weakening of Compass Logic based on cone - shaped cardinal directions
We introduce a modal logic , called Cone Logic , whose formulas describe properties of points in the plane and spatial relationships between them . Points are labelled by proposition letters and spatial relations are induced by the four cone - shaped cardinal directions . Cone Logic can be seen as a weakening of Venema 's Compass Logic . We prove that , unlike Compass Logic and other projection - based spatial logics , its satisfiability problem is decidable ( precisely , PSPACE - complete ) . We also show that it is expressive enough to capture meaningful interval temporal logics - in particular , the interval temporal logic of Allen 's relations " Begins " , " During " , and " Later " , and their transposes .
A Program Logic for Verifying Secure Routing Protocols
The Internet , as it stands today , is highly vulnerable to attacks . However , little has been done to understand and verify the formal security guarantees of proposed secure inter - domain routing protocols , such as Secure BGP ( S - BGP ) . In this paper , we develop a sound program logic for SANDLog - a declarative specification language for secure routing protocols for verifying properties of these protocols . We prove invariant properties of SANDLog programs that run in an adversarial environment . As a step towards automated verification , we implement a verification condition generator ( VCGen ) to automatically extract proof obligations . VCGen is integrated into a compiler for SANDLog that can generate executable protocol implementations ; and thus , both verification and empirical evaluation of secure routing protocols can be carried out in this unified framework . To validate our framework , we encoded several proposed secure routing mechanisms in SANDLog , verified variants of path authenticity properties by manually discharging the generated verification conditions in Coq , and generated executable code based on SANDLog specification and ran the code in simulation .
Algebraic Logic , I Quantifier Theories and Completeness Theorems
Algebraic logic studies algebraic theories related to proposition and first - order logic . A new algebraic approach to first - order logic is sketched in this paper . We introduce the notion of a quantifier theory , which is a functor from the category of a monad of sets to the category of Boolean algebras , together with a uniquely determined system of quantifiers . A striking feature of this approach is that Cayley 's Completeness Theorem and Godel 's Completeness Theorem can be stated and proved in a much simpler fashion for quantifier theories . Both theorems are due to Halmos for polyadic algebras . We also present a simple transparent treatment of ultraproducts of models of a quantifier theory .
On Reachability for Hybrid Automata over Bounded Time
This paper investigates the time - bounded version of the reachability problem for hybrid automata . This problem asks whether a given hybrid automaton can reach a given target location within T time units , where T is a constant rational value . We show that , in contrast to the classical ( unbounded ) reachability problem , the timed - bounded version is decidable for rectangular hybrid automata provided only non - negative rates are allowed . This class of systems is of practical interest and subsumes , among others , the class of stopwatch automata . We also show that the problem becomes undecidable if either diagonal constraints or both negative and positive rates are allowed .
Counterexample - Preserving Reduction for Symbolic Model Checking
The cost of LTL model checking is highly sensitive to the length of the formula under verification . We observe that , under some specific conditions , the input LTL formula can be reduced to an easier - to - handle one before model checking . In our reduction , these two formulae need not to be logically equivalent , but they share the same counterexample set w.r.t the model . In the case that the model is symbolically represented , the condition enabling such reduction can be detected with a lightweight effort ( e.g. , with SAT - solving ) . In this paper , we tentatively name such technique " Counterexample - Preserving Reduction " ( CePRe for short ) , and finally the proposed technquie is experimentally evaluated by adapting NuSMV .
Lazy abstractions for timed automata
We consider the reachability problem for timed automata . A standard solution to this problem involves computing a search tree whose nodes are abstractions of zones . For efficiency reasons , they are parametrized by the maximal lower and upper bounds ( LU - bounds ) occurring in the guards of the automaton . We propose an algorithm that is updating LU - bounds during exploration of the search tree . In order to keep them as small as possible , the bounds are refined only when they enable a transition that is impossible in the unabstracted system . So our algorithm can be seen as a kind of lazy CEGAR algorithm for timed automata . We show that on several standard benchmarks , the algorithm is capable of keeping very small LU - bounds , and in consequence reduce the search space substantially .
A Decidable Theory of Skiplists of Unbounded Size and Arbitrary Height
This paper presents a theory of skiplists of arbitrary height , and shows decidability of the satisfiability problem for quantifier - free formulas . A skiplist is an imperative software data structure that implements sets by maintaining several levels of ordered singly - linked lists in memory , where each level is a sublist of its lower levels . Skiplists are widely used in practice because they offer a performance comparable to balanced binary trees , and can be implemented more efficiently . To achieve this performance , most implementations dynamically increment the height ( the number of levels ) . Skiplists are difficult to reason about because of the dynamic size ( number of nodes ) and the sharing between the different layers . Furthermore , reasoning about dynamic height adds the challenge of dealing with arbitrary many levels . The first contribution of this paper is the theory TSL that allows to express the heap memory layout of a skiplist of arbitrary height . The second contribution is a decision procedure for the satisfiability prob- lem of quantifier - free TSL formulas . The last contribution is to illustrate the formal verification of a practical skiplist implementation using this decision procedure .
Specifying and Verifying Properties of Space - Extended Version
The interplay between process behaviour and spatial aspects of computation has become more and more relevant in Computer Science , especially in the field of collective adaptive systems , but also , more generally , when dealing with systems distributed in physical space . Traditional verification techniques are well suited to analyse the temporal evolution of programs ; properties of space are typically not explicitly taken into account . We propose a methodology to verify properties depending upon physical space . We define an appropriate logic , stemming from the tradition of topological interpretations of modal logics , dating back to earlier logicians such as Tarski , where modalities describe neighbourhood . We lift the topological definitions to a more general setting , also encompassing discrete , graph - based structures . We further extend the framework with a spatial until operator , and define an efficient model checking procedure , implemented in a proof - of - concept tool .
Decidability Results for the Boundedness Problem
We prove decidability of the boundedness problem for monadic least fixed - point recursion based on positive monadic second - order ( MSO ) formulae over trees . Given an MSO - formula phi(X , x ) that is positive in X , it is decidable whether the fixed - point recursion based on phi is spurious over the class of all trees in the sense that there is some uniform finite bound for the number of iterations phi takes to reach its least fixed point , uniformly across all trees . We also identify the exact complexity of this problem . The proof uses automata - theoretic techniques . This key result extends , by means of model - theoretic interpretations , to show decidability of the boundedness problem for MSO and guarded second - order logic ( GSO ) over the classes of structures of fixed finite tree - width . Further model - theoretic transfer arguments allow us to derive major known decidability results for boundedness for fragments of first - order logic as well as new ones .
Non - Blocking Concurrent Imperative Programming with Session Types
Concurrent C0 is an imperative programming language in the C family with session - typed message - passing concurrency . The previously proposed semantics implements asynchronous ( non - blocking ) output ; we extend it here with non - blocking input . A key idea is to postpone message reception as much as possible by interpreting receive commands as a request for a message . We implemented our ideas as a translation from a blocking intermediate language to a non - blocking language . Finally , we evaluated our techniques with several benchmark programs and show the results obtained . While the abstract measure of span always decreases ( or remains unchanged ) , only a few of the examples reap a practical benefit .
Metric Reasoning About $ l$-Terms : The General Case ( Long Version )
In any setting in which observable properties have a quantitative flavour , it is natural to compare computational objects by way of \emph{metrics } rather than equivalences or partial orders . This holds , in particular , for probabilistic higher - order programs . A natural notion of comparison , then , becomes context distance , the metric analogue of Morris ' context equivalence . In this paper , we analyze the main properties of the context distance in fully - fledged probabilistic $ \lambda$-calculi , this way going beyond the state of the art , in which only affine calculi were considered . We first of all study to which extent the context distance trivializes , giving a sufficient condition for trivialization . We then characterize context distance by way of a coinductively defined , tuple - based notion of distance in one of those calculi , called $ \Lambda^\oplus_!$. We finally derive pseudometrics for call - by - name and call - by - value probabilistic $ \lambda$-calculi , and prove them fully - abstract .
Finitary Deduction Systems
Cryptographic protocols are the cornerstone of security in distributed systems . The formal analysis of their properties is accordingly one of the focus points of the security community , and is usually split among two groups . In the first group , one focuses on trace - based security properties such as confidentiality and authentication , and provides decision procedures for the existence of attacks for an on - line attackers . In the second group , one focuses on equivalence properties such as privacy and guessing attacks , and provides decision procedures for the existence of attacks for an offline attacker . In all cases the attacker is modeled by a deduction system in which his possible actions are expressed . We present in this paper a notion of finitary deduction systems that aims at relating both approaches . We prove that for such deduction systems , deciding equivalence properties for on - line attackers can be reduced to deciding reachability properties in the same setting .
Dynamic Backward Slicing of Rewriting Logic Computations
Trace slicing is a widely used technique for execution trace analysis that is effectively used in program debugging , analysis and comprehension . In this paper , we present a backward trace slicing technique that can be used for the analysis of Rewriting Logic theories . Our trace slicing technique allows us to systematically trace back rewrite sequences modulo equational axioms ( such as associativity and commutativity ) by means of an algorithm that dynamically simplifies the traces by detecting control and data dependencies , and dropping useless data that do not influence the final result . Our methodology is particularly suitable for analyzing complex , textually - large system computations such as those delivered as counter - example traces by Maude model - checkers .
An Axiomatization for Quantum Processes to Unifying Quantum and Classical Computing
We establish an axiomatization for quantum processes , which is a quantum generalization of process algebra ACP ( Algebra of Communicating Processes ) . We use the framework of a quantum process configuration $ \langle p , \varrho\rangle$ , but we treat it as two relative independent part : the structural part $ p$ and the quantum part $ \varrho$ , because the establishment of a sound and complete theory is dependent on the structural properties of the structural part $ p$. We let the quantum part $ \varrho$ be the outcomes of execution of $ p$ to examine and observe the function of the basic theory of quantum mechanics . We establish not only a strong bisimularity for quantum processes , but also a weak bisimularity to model the silent step and abstract internal computations in quantum processes . The relationship between quantum bisimularity and classical bisimularity is established , which makes an axiomatization of quantum processes possible . An axiomatization for quantum processes called qACP is designed , which involves not only quantum information , but also classical information and unifies quantum computing and classical computing . qACP can be used easily and widely for verification of most quantum communication protocols .
Weighted Modal Transition Systems
Specification theories as a tool in model - driven development processes of component - based software systems have recently attracted a considerable attention . Current specification theories are however qualitative in nature , and therefore fragile in the sense that the inevitable approximation of systems by models , combined with the fundamental unpredictability of hardware platforms , makes it difficult to transfer conclusions about the behavior , based on models , to the actual system . Hence this approach is arguably unsuited for modern software systems . We propose here the first specification theory which allows to capture quantitative aspects during the refinement and implementation process , thus leveraging the problems of the qualitative setting . Our proposed quantitative specification framework uses weighted modal transition systems as a formal model of specifications . These are labeled transition systems with the additional feature that they can model optional behavior which may or may not be implemented by the system . Satisfaction and refinement is lifted from the well - known qualitative to our quantitative setting , by introducing a notion of distances between weighted modal transition systems . We show that quantitative versions of parallel composition as well as quotient ( the dual to parallel composition ) inherit the properties from the Boolean setting .
More on Descriptive Complexity of Second - Order HORN Logics
This paper concerns Gradel 's question asked in 1992 : whether all problems which are in PTIME and closed under substructures are definable in second - order HORN logic SO - HORN . We introduce revisions of SO - HORN and DATALOG by adding first - order universal quantifiers over the second - order atoms in the bodies of HORN clauses and DATALOG rules . We show that both logics are as expressive as FO(LFP ) , the least fixed point logic . We also prove that FO(LFP ) can not define all of the problems that are in PTIME and closed under substructures . As a corollary , we answer Gradel 's question negatively .
Verification for Timed Automata extended with Unbounded Discrete Data Structures
We study decidability of verification problems for timed automata extended with unbounded discrete data structures . More detailed , we extend timed automata with a pushdown stack . In this way , we obtain a strong model that may for instance be used to model real - time programs with procedure calls . It is long known that the reachability problem for this model is decidable . The goal of this paper is to identify subclasses of timed pushdown automata for which the language inclusion problem and related problems are decidable .
Fully Abstract Game Semantics for Actors
Along the way paved by the recent concurrent game semantics for process algebra CCS and $ \pi$-calculus , based on the basic characteristics of the actor computational model and the very reductive semantics for actors , we establish a fully abstract concurrent game semantics for actors by borrowing the algebraic structure from CCS . This semantics can both be seen as an innocent presheaf semantics , and a concurrent game semantics .
Balancing Scalability and Uniformity in SAT Witness Generator
Constrained - random simulation is the predominant approach used in the industry for functional verification of complex digital designs . The effectiveness of this approach depends on two key factors : the quality of constraints used to generate test vectors , and the randomness of solutions generated from a given set of constraints . In this paper , we focus on the second problem , and present an algorithm that significantly improves the state - of - the - art of ( almost-)uniform generation of solutions of large Boolean constraints . Our algorithm provides strong theoretical guarantees on the uniformity of generated solutions and scales to problems involving hundreds of thousands of variables .
On Equivalence of Infinitary Formulas under the Stable Model Semantics
Propositional formulas that are equivalent in intuitionistic logic , or in its extension known as the logic of here - and - there , have the same stable models . We extend this theorem to propositional formulas with infinitely long conjunctions and disjunctions and show how to apply this generalization to proving properties of aggregates in answer set programming . To appear in Theory and Practice of Logic Programming ( TPLP ) .
Resolution in Linguistic First Order Logic based on Linear Symmetrical Hedge Algebra
This paper focuses on resolution in linguistic first order logic with truth value taken from linear symmetrical hedge algebra . We build the basic components of linguistic first order logic , including syntax and semantics . We present a resolution principle for our logic to resolve on two clauses having contradictory linguistic truth values . Since linguistic information is uncertain , inference in our linguistic logic is approximate . Therefore , we introduce the concept of reliability in order to capture the natural approximation of the resolution inference rule .
Reduction of Event Structures under History Preserving Bisimulation
Event structures represent concurrent processes in terms of events and dependencies between events modelling behavioural relations like causality and conflict . Since the introduction of prime event structures , many variants of event structures have been proposed with different behavioural relations and , hence , with differences in their expressive power . One of the possible benefits of using a more expressive event structure is that of having a more compact representation for the same behaviour when considering the number of events used in a prime event structure . Therefore , this article addresses the problem of reducing the size of an event structure while preserving behaviour under a well - known notion of equivalence , namely history preserving bisimulation . In particular , we investigate this problem on two generalisations of the prime event structures . The first one , known as asymmetric event structure , relies on a asymmetric form of the conflict relation . The second one , known as flow event structure , supports a form of disjunctive causality . More specifically , we describe the conditions under which a set of events in an event structure can be folded into a single event while preserving the original behaviour . The successive application of this folding operation leads to a minimal size event structure . However , the order on which the folding operation is applied may lead to different minimal size event structures . The latter has a negative implication on the potential use of a minimal size event structure as a canonical representation for behaviour .
Groupoid Semantics for Thermal Computing
A groupoid semantics is presented for systems with both logical and thermal degrees of freedom . We apply this to a syntactic model for encryption , and obtain an algebraic characterization of the heat produced by the encryption function , as predicted by Landauer 's principle . Our model has a linear representation theory that reveals an underlying quantum semantics , giving for the first time a functorial classical model for quantum teleportation and other quantum phenomena .
Computing the Reveals Relation in Occurrence Nets
Petri net unfoldings are a useful tool to tackle state - space explosion in verification and related tasks . Moreover , their structure allows to access directly the relations of causal precedence , concurrency , and conflict between events . Here , we explore the data structure further , to determine the following relation : event a is said to reveal event b iff the occurrence of a implies that b inevitably occurs , too , be it before , after , or concurrently with a. Knowledge of reveals facilitates in particular the analysis of partially observable systems , in the context of diagnosis , testing or verification ; it can also be used to generate more concise representations of behaviours via abstractions . The reveals relation was previously introduced in the context of fault diagnosis , where it was shown that the reveals relation was decidable : for a given pair a , b in the unfolding U of a safe Petri net N , a finite prefix P of U is sufficient to decide whether or not a reveals b. In this paper , we first considerably improve the bound on |P| . We then show that there exists an efficient algorithm for computing the relation on a given prefix . We have implemented the algorithm and report on experiments .
Ticket Entailment is decidable
We prove the decidability of Ticket Entailment . Raised by Anderson and Belnap within the framework of relevance logic , this question is equivalent to the question of the decidability of type inhabitation in simply - typed combinatory logic with the partial basis BB'IW . We solve the equivalent problem of type inhabitation for the restriction of simply - typed lambda - calculus to hereditarily right - maximal terms .
Bisimulations Meet PCTL Equivalences for Probabilistic Automata
Probabilistic automata ( PAs ) have been successfully applied in formal verification of concurrent and stochastic systems . Efficient model checking algorithms have been studied , where the most often used logics for expressing properties are based on probabilistic computation tree logic ( PCTL ) and its extension PCTL^*. Various behavioral equivalences are proposed , as a powerful tool for abstraction and compositional minimization for PAs . Unfortunately , the equivalences are well - known to be sound , but not complete with respect to the logical equivalences induced by PCTL or PCTL*. The desire of a both sound and complete behavioral equivalence has been pointed out by Segala in 1995 , but remains open throughout the years . In this paper we introduce novel notions of strong bisimulation relations , which characterize PCTL and PCTL * exactly . We extend weak bisimulations that characterize PCTL and PCTL * without next operator , respectively . Further , we also extend the framework to simulation preorders . Thus , our paper bridges the gap between logical and behavioral equivalences and preorders in this setting .
Soundness and completeness of the cirquent calculus system CL6 for computability logic
Computability logic is a formal theory of computability . The earlier article " Introduction to cirquent calculus and abstract resource semantics " by Japaridze proved soundness and completeness for the basic fragment CL5 of computability logic . The present article extends that result to the more expressive cirquent calculus system CL6 , which is a conservative extension of both CL5 and classical propositional logic .
Cut - Free ExpTime Tableaux for Checking Satisfiability of a Knowledge Base in the Description Logic SHI
We give the first cut - free ExpTime ( optimal ) tableau decision procedure for checking satisfiability of a knowledge base in the description logic SHI , which extends the description logic ALC with transitive roles , inverse roles and role hierarchies .
Verifying Embedded C Software with Timing Constraints using an Untimed Model Checker
Embedded systems are everywhere , from home appliances to critical systems such as medical devices . They usually have associated timing constraints that need to be verified for the implementation . Here , we use an untimed bounded model checker to verify timing properties of embedded C programs . We propose an approach to specify discrete time timing constraints using code annotations . The annotated code is then automatically translated to code that manipulates auxiliary timer variables and is thus suitable as input to conventional , untimed software model checker such as ESBMC . Thus , we can check timing constraints in the same way and at the same time as untimed system requirements , and even allow for interaction between them . We applied the proposed method in a case study , and verified timing constraints of a pulse oximeter , a noninvasive medical device that measures the oxygen saturation of arterial blood .
Value - passing CCS for Trees : A Theory for Concurrent Systems
In this paper , we extend the theory CCS for trees ( CCTS ) to value - passing CCTS ( VCCTS ) , of which symbols have the capacity for receiving and sending data values , and a nonsequential semantics is proposed in an operational approach . In this concurrent model , a weak barbed congruence and a localized early weak bisimilarity are defined , and the latter relation is proved to be sufficient to justify the former . As an illustration of potential applications of VCCTS , a semantics based on VCCTS is given to a toy multi - threaded programming language featuring a core of C / C++ concurrency ; and a formalization based on the operational semantics of VCCTS is proposed for some relaxed memory models , and a DRF - guarantee property with respect to VCCTS is proved .
Second - Order Propositional Satisfiability
Fundamentally , every static program analyser searches for a proof through a combination of heuristics providing candidate solutions and a candidate validation technique . Essentially , the heuristic reduces a second - order problem to a first - order / propositional one , while the validation is often just a call to a SAT / SMT solver . This results in a monolithic design of such analyses that conflates the formulation of the problem with the solving process . Consequently , any change to the latter causes changes to the whole analysis . This design is dictated by the state of the art in solver technology . While SAT / SMT solvers have experienced tremendous progress , there are barely any second - order solvers . This paper takes a step towards addressing this situation by proposing a decidable fragment of second - order logic that is still expressive enough to capture numerous program analysis problems ( e.g. safety proving , bug finding , termination and non - termination proving , superoptimisation ) . We refer to the satisfiability problem for this fragment as Second - Order SAT and show it is NEXPTIME - complete . Finally , we build a decision procedure for Second - Order SAT based on program synthesis and present experimental evidence that our approach is tractable for program analysis problems .
Certification of programs with computational effects
In purely functional programming languages imperative features , more generally computational effects are prohibited . However , non - functional lan- guages do involve effects . The theory of decorated logic provides a rigorous for- malism ( with a refinement in operation signatures ) for proving program properties with respect to computational effects . The aim of this thesis is to first develop Coq libraries and tools for verifying program properties in decorated settings as- sociated with several effects : states , local state , exceptions , non - termination , etc . Then , these tools will be combined to deal with several effects .
Program certification with computational effects
Dynamic evaluation is a paradigm in computer algebra which was introduced for computing with algebraic numbers . In linear algebra , for instance , dynamic evaluation can be used to apply programs which have been written for matrices with coefficients modulo some prime number to matrices with coefficients modulo some composite number . A way to implement dynamic evaluation in modern computing languages is to use the exceptions mechanism provided by the language . In this paper , we pesent a proof system for exceptions which involves both raising and handling , by extending Moggi 's approach based on monads . Moreover , the core part of this proof system is dual to a proof system for the state effect in imperative languages , which relies on the categorical notion of comonad . Both proof systems are implemented in the Coq proof assistant , and they are combined in order to deal with both effects at the same time .
DL - PA and DCL - PC : model checking and satisfiability problem are indeed in PSPACE
We prove that the model checking and the satisfiability problem of both Dynamic Logic of Propositional Assignments DL - PA and Coalition Logic of Propositional Control and Delegation DCL - PC are in PSPACE . We explain why the proof of EXPTIME - hardness of the model checking problem of DL - PA presented in ( Balbiani , Herzig , Troquard , 2013 ) is false . We also explain why the proof of membership in PSPACE of the model checking problem of DCL - PC given in ( van der Hoek , Walther , Wooldridge , 2010 ) is wrong .
Data refinement for true concurrency
The majority of modern systems exhibit sophisticated concurrent behaviour , where several system components modify and observe the system state with fine - grained atomicity . Many systems ( e.g. , multi - core processors , real - time controllers ) also exhibit truly concurrent behaviour , where multiple events can occur simultaneously . This paper presents data refinement defined in terms of an interval - based framework , which includes high - level operators that capture non - deterministic expression evaluation . By modifying the type of an interval , our theory may be specialised to cover data refinement of both discrete and continuous systems . We present an interval - based encoding of forward simulation , then prove that our forward simulation rule is sound with respect to our data refinement definition . A number of rules for decomposing forward simulation proofs over both sequential and parallel composition are developed .
Bisimilarity and refinement for hybrid(ised ) logics
The complexity of modern software systems entails the need for reconfiguration mechanisms gov- erning the dynamic evolution of their execution configurations in response to both external stimulus or internal performance measures . Formally , such systems may be represented by transition systems whose nodes correspond to the different configurations they may assume . Therefore , each node is en- dowed with , for example , an algebra , or a first - order structure , to precisely characterise the semantics of the services provided in the corresponding configuration . Hybrid logics , which add to the modal description of transition structures the ability to refer to specific states , offer a generic framework to approach the specification and design of this sort of systems . Therefore , the quest for suitable notions of equivalence and refinement between models of hybrid logic specifications becomes fundamental to any design discipline adopting this perspective . This paper contributes to this effort from a distinctive point of view : instead of focussing on a specific hybrid logic , the paper introduces notions of bisimilarity and refinement for hybridised logics , i.e. standard specification logics ( e.g. propositional , equational , fuzzy , etc ) to which modal and hybrid features were added in a systematic way .
Full abstraction for fair testing in CCS
In previous work with Pous , we defined a semantics for CCS which may both be viewed as an innocent presheaf semantics and as a concurrent game semantics . It is here proved that a behavioural equivalence induced by this semantics on CCS processes is fully abstract for fair testing equivalence . The proof relies on a new algebraic notion called playground , which represents the ' rule of the game ' . From any playground , two languages , equipped with labelled transition systems , are derived , as well as a strong , functional bisimulation between them .
Capturing Hiproofs in HOL Light
Hierarchical proof trees ( hiproofs for short ) add structure to ordinary proof trees , by allowing portions of trees to be hierarchically nested . The additional structure can be used to abstract away from details , or to label particular portions to explain their purpose . In this paper we present two complementary methods for capturing hiproofs in HOL Light , along with a tool to produce web - based visualisations . The first method uses tactic recording , by modifying tactics to record their arguments and construct a hierarchical tree ; this allows a tactic proof script to be modified . The second method uses proof recording , which extends the HOL Light kernel to record hierachical proof trees alongside theorems . This method is less invasive , but requires care to manage the size of the recorded objects . We have implemented both methods , resulting in two systems : Tactician and HipCam .
On the Well Extension of Partial Well Orderings
In this paper , we study the well extension of strict(irreflective ) partial well orderings . We first prove that any partially well - ordered structure < A , R > can be extended to a well - ordered one . Then we prove that every linear extension of < A , R > is well - ordered if and only if A has no infinite totally unordered subset under R.
Property - based Polynomial Invariant Generation using Sums - of - Squares Optimization
While abstract interpretation is not theoretically restricted to specific kinds of properties , it is , in practice , mainly developed to compute linear over - approximations of reachable sets , aka . the collecting semantics of the program . The verification of user - provided properties is not easily compatible with the usual forward fixpoint computation using numerical abstract domains . We propose here to rely on sums - of - squares programming to characterize a property - driven polynomial invariant . This invariant generation can be guided by either boundedness , or in contrary , a given zone of the state space to avoid . While the target property is not necessarily inductive with respect to the program semantics , our method identifies a stronger inductive polynomial invariant using numerical optimization . Our method applies to a wide set of programs : a main while loop composed of a disjunction ( if - then - else ) of polynomial updates e.g. piecewise polynomial controllers . It has been evaluated on various programs .
Paraconsistency and Topological Semantics
The well - studied notion of deductive explosion describes the situation where any formula can be deduced from an inconsistent set of formulas . Paraconsistent logic , on the other hand , is the umbrella term for logical systems where the logical consequence relation is not explosive . In this work , we investigate the relationship between some different topological spaces and paraconsistency .
Finite countermodels for safety verification of parameterized tree systems
In this paper we deal with verification of safety properties of parameterized systems with a tree topology . The verification problem is translated to a purely logical problem of finding a finite countermodel for a first - order formula , which further resolved by a generic finite model finding procedure . A finite countermodel method is shown is at least as powerful as regular tree model checking and as the methods based on monotonic abstraction and backwards symbolic reachability . The practical efficiency of the method is illustrated on a set of examples taken from the literature .
Stochastic Timed Automata
A stochastic timed automaton is a purely stochastic process defined on a timed automaton , in which both delays and discrete choices are made randomly . We study the almost - sure model - checking problem for this model , that is , given a stochastic timed automaton A and a property $ \Phi$ , we want to decide whether A satisfies $ \Phi$ with probability 1 . In this paper , we identify several classes of automata and of properties for which this can be decided . The proof relies on the construction of a finite abstraction , called the thick graph , that we interpret as a finite Markov chain , and for which we can decide the almost - sure model - checking problem . Correctness of the abstraction holds when automata are almost - surely fair , which we show , is the case for two large classes of systems , single- clock automata and so - called weak - reactive automata . Techniques employed in this article gather tools from real - time verification and probabilistic verification , as well as topological games played on timed automata .
CoLoR : a Coq library on well - founded rewrite relations and its application to the automated verification of termination certificates
Termination is an important property of programs ; notably required for programs formulated in proof assistants . It is a very active subject of research in the Turing - complete formalism of term rewriting systems , where many methods and tools have been developed over the years to address this problem . Ensuring reliability of those tools is therefore an important issue . In this paper we present a library formalizing important results of the theory of well - founded ( rewrite ) relations in the proof assistant Coq . We also present its application to the automated verification of termination certificates , as produced by termination tools .
Expressing Preferences using Preference Set Constraint Atoms
This paper introduces an extension of Answer Set Programming called Preference Set Constraint Programming which is a convenient and general formalism to reason with preferences . PSC programming extends Set Constraint Programming introduced by Marek and Remmel ( Marek and Remmel 2004 ) by introducing two types of preference set constraint atoms , measure preference set constraint atoms and pre - ordered preference set constraint atoms , which are extensions of set constraint atoms . We show that the question of whether a PSC program has a preferred stable model is CoNP - complete . We give examples of the uses of the preference set constraint atoms and show that Answer Set Optimization ( Brewka , Niemel\"a , and Truszczynski 2003 ) and General Preference ( Son and Pontelli 2006 ) can be expressed using preference set constraint atoms .
Mathematics of Domains
Two groups of naturally arising questions in the mathematical theory of domains for denotational semantics are addressed . Domains are equipped with Scott topology and represent data types . Scott continuous functions represent computable functions and form the most popular continuous model of computations . Covariant Logic of Domains : Domains are represented as sets of theories , and Scott continuous functions are represented as input - output inference engines . The questions addressed are : A. What constitutes a subdomain ? Do subdomains of a given domain $ A$ form a domain ? B. Which retractions are finitary ? C. What is the essence of generalizations of information systems based on non - reflexive logics ? Are these generalizations restricted to continuous domains ? Analysis on Domains : D. How to describe Scott topologies via generalized distance functions satisfying the requirement of Scott continuity ( " abstract computability " ) ? The answer is that the axiom $ \rho ( x , x ) = 0 $ is incompatible with Scott continuity of distance functions . The resulting \bf relaxed metrics are studied . E. Is it possible to obtain Scott continuous relaxed metrics via measures of domain subsets representing positive and negative information about domain elements ? The positive answer is obtained via the discovery of the novel class of co - continuous valuations on the systems of Scott open sets . Some of these natural questions were studied earlier . However , in each case a novel approach is presented , and the answers are supplied with much more compelling and clear justifications , than were known before .
Clone Theory and Algebraic Logic
The concept of a clone is central to many branches of mathematics , such as universal algebra , algebraic logic , and lambda calculus . Abstractly a clone is a category with two objects such that one is a countably infinite power of the other . Left and right algebras over a clone are covariant and contravariant functors from the category to that of sets respectively . In this paper we show that first - order logic can be studied effectively using the notions of right and left algebras over a clone . It is easy to translate the classical treatment of logic into our setting and prove all the fundamental theorems of first - order theory algebraically .
Non - definability of languages by generalized first - order formulas over ( N,+ )
We consider first - order logic with monoidal quantifiers over words . We show that all languages with a neutral letter , definable using the addition numerical predicate are also definable with the order predicate as the only numerical predicate . Let S be a subset of monoids . Let LS be the logic closed under quantification over the monoids in S and N be the class of neutral letter languages . Then we show that : LS[<,+ ] cap N = LS [ < ] Our result can be interpreted as the Crane Beach conjecture to hold for the logic LS[<,+ ] . As a corollary of our result we get the result of Roy and Straubing that FO+MOD[<,+ ] collapses to FO+MOD [ < ] . For cyclic groups , we answer an open question of Roy and Straubing , proving that MOD[<,+ ] collapses to MOD [ < ] . Our result also shows that multiplication is necessary for Barrington 's theorem to hold . All these results can be viewed as separation results for very uniform circuit classes . For example we separate FO[<,+]-uniform CC0 from FO[<,+]-uniform ACC0 .
Combining Deduction Modulo and Logics of Fixed - Point Definitions
Inductive and coinductive specifications are widely used in formalizing computational systems . Such specifications have a natural rendition in logics that support fixed - point definitions . Another useful formalization device is that of recursive specifications . These specifications are not directly complemented by fixed - point reasoning techniques and , correspondingly , do not have to satisfy strong monotonicity restrictions . We show how to incorporate a rewriting capability into logics of fixed - point definitions towards additionally supporting recursive specifications . In particular , we describe a natural deduction calculus that adds a form of " closed - world " equality - a key ingredient to supporting fixed - point definitions - to deduction modulo , a framework for extending a logic with a rewriting layer operating on formulas . We show that our calculus enjoys strong normalizability when the rewrite system satisfies general properties and we demonstrate its usefulness in specifying and reasoning about syntax - based descriptions . The integration of closed - world equality into deduction modulo leads us to reconfigure the elimination principle for this form of equality in a way that , for the first time , resolves issues regarding the stability of finite proofs under reduction .
Delta - Decidability over the Reals
Given any collection F of computable functions over the reals , we show that there exists an algorithm that , given any L_F - sentence \varphi containing only bounded quantifiers , and any positive rational number \delta , decides either " \varphi is true " , or " a \delta - strengthening of \varphi is false " . Under mild assumptions , for a C - computable signature F , the \delta - decision problem for bounded \Sigma_k - sentences in L_F resides in ( \Sigma_k^P)^C. The results stand in sharp contrast to the well - known undecidability results , and serve as a theoretical basis for the use of numerical methods in decision procedures for nonlinear first - order theories over the reals .
On the Expressive Power of Sub - Propositional Fragments of Modal Logic
Modal logic is a paradigm for several useful and applicable formal systems in computer science . It generally retains the low complexity of classical propositional logic , but notable exceptions exist in the domains of description , temporal , and spatial logic , where the most expressive formalisms have a very high complexity or are even undecidable . In search of computationally well - behaved fragments , clausal forms and other sub - propositional restrictions of temporal and description logics have been recently studied . This renewed interest on sub - propositional logics , which mainly focus on the complexity of the various fragments , raise natural questions on their the relative expressive power , which we try to answer here for the basic multi - modal logic Kn . We consider the Horn and the Krom restrictions , as well as the combined restriction ( known as the core fragment ) of modal logic , and , orthogonally , the fragments that emerge by disallowing boxes or diamonds from positive literals . We study the problem in a very general setting , to ease transferring our results to other meaningful cases .
A New Rule for LTL Tableaux
Propositional linear time temporal logic ( LTL ) is the standard temporal logic for computing applications and many reasoning techniques and tools have been developed for it . Tableaux for deciding satisfiability have existed since the 1980s . However , the tableaux for this logic do not look like traditional tree - shaped tableau systems and their processing is often quite complicated . In this paper , we introduce a novel style of tableau rule which supports a new simple traditional - style tree - shaped tableau for LTL . We prove that it is sound and complete . As well as being simple to understand , to introduce to students and to use , it is also simple to implement and is competitive against state of the art systems . It is particularly suitable for parallel implementations .
Relation - Changing Logics as Fragments of Hybrid Logics
Relation - changing modal logics are extensions of the basic modal logic that allow changes to the accessibility relation of a model during the evaluation of a formula . In particular , they are equipped with dynamic modalities that are able to delete , add , and swap edges in the model , both locally and globally . We provide translations from these logics to hybrid logic along with an implementation . In general , these logics are undecidable , but we use our translations to identify decidable fragments . We also compare the expressive power of relation - changing modal logics with hybrid logics .
Liveness of Parameterized Timed Networks
We consider the model checking problem of infinite state systems given in the form of parameterized discrete timed networks with multiple clocks . We show that this problem is decidable with respect to specifications given by B- or S - automata . Such specifications are very expressive ( they strictly subsume omega - regular specifications ) , and easily express complex liveness and safety properties . Our results are obtained by modeling the passage of time using symmetric broadcast , and by solving the model checking problem of parameterized systems of un - timed processes communicating using k - wise rendezvous and symmetric broadcast . Our decidability proof makes use of automata theory , rational linear programming , and geometric reasoning for solving certain reachability questions in vector addition systems ; we believe these proof techniques will be useful in solving related problems .
Weighted Linear Dynamic Logic
We introduce a weighted linear dynamic logic ( weighted LDL for short ) and show the expressive equivalence of its formulas to weighted rational expressions . This adds a new characterization for recognizable series to the fundamental Sch\"utzenberger theorem . Surprisingly , the equivalence does not require any restriction to our weighted LDL . Our results hold over arbitrary ( resp . totally complete ) semirings for finite ( resp . infinite ) words . As a consequence , the equivalence problem for weighted LDL formulas over fields is decidable in doubly exponential time . In contrast to classical logics , we show that our weighted LDL is expressively incomparable to weighted LTL for finite words . We determine a fragment of the weighted LTL such that series over finite and infinite words definable by LTL formulas in this fragment are definable also by weighted LDL formulas .
A Canonical Model Construction for Iteration - Free PDL with Intersection
We study the axiomatisability of the iteration - free fragment of Propositional Dynamic Logic with Intersection and Tests . The combination of program composition , intersection and tests makes its proof - theory rather difficult . We develop a normal form for formulae which minimises the interaction between these operators , as well as a refined canonical model construction . From these we derive an axiom system and a proof of its strong completeness .
Partial Solvers for Parity Games : Effective Polynomial - Time Composition
Partial methods play an important role in formal methods and beyond . Recently such methods were developed for parity games , where polynomial - time partial solvers decide the winners of a subset of nodes . We investigate here how effective polynomial - time partial solvers can be by studying interactions of partial solvers based on generic composition patterns that preserve polynomial - time computability . We show that use of such composition patterns discovers new partial solvers - including those that merge node sets that have the same but unknown winner - by studying games that composed partial solvers can neither solve nor simplify . We experimentally validate that this data - driven approach to refinement leads to polynomial - time partial solvers that can solve all standard benchmarks of structured games . For one of these polynomial - time partial solvers not even a sole random game from a few billion random games of varying configuration was found that it wo n't solve completely .
Two simulations about DPLL(T )
In this paper we relate different formulations of the DPLL(T ) procedure . The first formulation is based on a system of rewrite rules , which we denote DPLL(T ) . The second formulation is an inference system of , which we denote LKDPLL(T ) . The third formulation is the application of a standard proof - search mechanism in a sequent calculus LKp(T ) introduced here . We formalise an encoding from DPLL(T ) to LKDPLL(T ) that was , to our knowledge , never explicitly given and , in the case where DPLL(T ) is extended with backjumping and Lemma learning , never even implicitly given . We also formalise an encoding from LKDPLL(T ) to LKp(T ) , building on Ivan Gazeau 's previous work : we extend his work in that we handle the " -modulo - Theory " aspect of SAT - modulo - theory , by extending the sequent calculus to allow calls to a theory solver ( seen as a blackbox ) . We also extend his work in that we handle advanced features of DPLL such as backjumping and Lemma learning , etc . Finally , we re fine the approach by starting to formalise quantitative aspects of the simulations : the complexity is preserved ( number of steps to build complete proofs ) . Other aspects remain to be formalised ( non - determinism of the search / width of search space ) .
SMT - based Induction Methods for Timed Systems
Modeling time related aspects is important in many applications of verification methods . For precise results , it is necessary to interpret time as a dense domain , e.g. using timed automata as a formalism , even though the system 's resulting infinite state space is challenging for verification methods . Furthermore , fully symbolic treatment of both timing related and non - timing related elements of the state space seems to offer an attractive approach to model checking timed systems with a large amount of non - determinism . This paper presents an SMT - based timed system extension to the IC3 algorithm , a SAT - based novel , highly efficient , complete verification method for untimed systems . Handling of the infinite state spaces of timed system in the extended IC3 algorithm is based on suitably adapting the well - known region abstraction for timed systems . Additionally , $ k$-induction , another symbolic verification method for discrete time systems , is extended in a similar fashion to support timed systems . Both new methods are evaluated and experimentally compared to a booleanization - based verification approach that uses the original discrete time IC3 algorithm .
On the Complexity of Branching - Time Logics
We classify the complexity of the satisfiability problem for extensions of CTL and UB . The extensions we consider are Boolean combinations of path formulas , fairness properties , past modalities , and forgettable past . Our main result shows that satisfiability for CTL with all these extensions is still in 2-EXPTIME , which strongly contrasts with the nonelementary complexity of CTL * with forgettable past . We give a complete classification of combinations of these extensions , yielding a dichotomy between extensions with 2-EXPTIME - complete and those with EXPTIME - complete complexity . In particular , we show that satisfiability for the extension of UB with forgettable past is complete for 2-EXPTIME , contradicting a claim for a stronger logic in the literature . The upper bounds are established with the help of a new kind of pebble automata .
On the Hybrid Extension of CTL and CTL+
The paper studies the expressivity , relative succinctness and complexity of satisfiability for hybrid extensions of the branching - time logics CTL and CTL+ by variables . Previous complexity results show that only fragments with one variable do have elementary complexity . It is shown that H1CTL+ and H1CTL , the hybrid extensions with one variable of CTL+ and CTL , respectively , are expressively equivalent but H1CTL+ is exponentially more succinct than H1CTL . On the other hand , HCTL+ , the hybrid extension of CTL with arbitrarily many variables does not capture CTL * , as it even can not express the simple CTL * property EGFp . The satisfiability problem for H1CTL+ is complete for triply exponential time , this remains true for quite weak fragments and quite strong extensions of the logic .
Predicate Transformers , ( co)Monads and Resolutions
This short note contains random thoughts about a factorization theorem for closure / interior operators on a powerset which is reminiscent to the notion of resolution for a monad / comonad . The question originated from formal topology but is interesting in itself . The result holds constructively ( even if it classically has several variations ) ; but usually not predicatively ( in the sense that the interpolant will no be given by a set ) . For those not familiar with predicativity issues , we look at a `` classical '' version where we bound the size of the interpolant .
Reasoning in the Bernays - Schoenfinkel - Ramsey Fragment of Separation Logic
Separation Logic ( SL ) is a well - known assertion language used in Hoare - style modular proof systems for programs with dynamically allocated data structures . In this paper we investigate the fragment of first - order SL restricted to the Bernays - Schoenfinkel - Ramsey quantifier prefix $ \exists^*\forall^*$ , where the quantified variables range over the set of memory locations . When this set is uninterpreted ( has no associated theory ) the fragment is PSPACE - complete , which matches the complexity of the quantifier - free fragment . However , SL becomes undecidable when the quantifier prefix belongs to $ \exists^*\forall^*\exists^*$ instead , or when the memory locations are interpreted as integers with linear arithmetic constraints , thus setting a sharp boundary for decidability within SL . We have implemented a decision procedure for the decidable fragment of $ \exists^*\forall^*$SL as a specialized solver inside a DPLL($T$ ) architecture , within the CVC4 SMT solver . The evaluation of our implementation was carried out using two sets of verification conditions , produced by ( i ) unfolding inductive predicates , and ( ii ) a weakest precondition - based verification condition generator . Experimental data shows that automated quantifier instantiation has little overhead , compared to manual model - based instantiation .
Coherence for Frobenius pseudomonoids and the geometry of linear proofs
We prove coherence theorems for Frobenius pseudomonoids and snakeorators in monoidal bicategories . As a consequence we obtain a 3d notation for proofs in nonsymmetric multiplicative linear logic , with a geometrical notion of equivalence , and without the need for a global correctness criterion or thinning links . We argue that traditional proof nets are the 2d projections of these 3d diagrams .
The Cost of Parameterized Reachability in Mobile Ad Hoc Networks
We investigate the impact of spontaneous movement in the complexity of verification problems for an automata - based protocol model of networks with selective broadcast communication . We first consider reachability of an error state and show that parameterized verification is decidable with polynomial complexity . We then move to richer queries and show how the complexity changes when considering properties with negation or cardinality constraints .
Instance Based Methods --- A Brief Overview
Instance - based methods are a specific class of methods for automated proof search in first - order logic . This article provides an overview of the major methods in the area and discusses their properties and relations to the more established resolution methods . It also discusses some recent trends on refinements and applications . This overview is rather brief and informal , but we provide a comprehensive literature list to follow - up on the details .
The Fibers and Range of Reduction Graphs in Ciliates
The biological process of gene assembly has been modeled based on three types of string rewriting rules , called string pointer rules , defined on so - called legal strings . It has been shown that reduction graphs , graphs that are based on the notion of breakpoint graph in the theory of sorting by reversal , for legal strings provide valuable insights into the gene assembly process . We characterize which legal strings obtain the same reduction graph ( up to isomorphism ) , and moreover we characterize which graphs are ( isomorphic to ) reduction graphs .
Feasible reactivity in a synchronous pi - calculus
Reactivity is an essential property of a synchronous program . Informally , it guarantees that at each instant the program fed with an input will ` react ' producing an output . In the present work , we consider a refined property that we call ` feasible reactivity ' . Beyond reactivity , this property guarantees that at each instant both the size of the program and its reaction time are bounded by a polynomial in the size of the parameters at the beginning of the computation and the size of the largest input . We propose a method to annotate programs and we develop related static analysis techniques that guarantee feasible reactivity for programs expressed in the S - pi - calculus . The latter is a synchronous version of the pi - calculus based on the SL synchronous programming model .
The Bedwyr system for model checking over syntactic expressions
Bedwyr is a generalization of logic programming that allows model checking directly on syntactic expressions possibly containing bindings . This system , written in OCaml , is a direct implementation of two recent advances in the theory of proof search . The first is centered on the fact that both finite success and finite failure can be captured in the sequent calculus by incorporating inference rules for definitions that allow fixed points to be explored . As a result , proof search in such a sequent calculus can capture simple model checking problems as well as may and must behavior in operational semantics . The second is that higher - order abstract syntax is directly supported using term - level $ \lambda$-binders and the $ \nabla$ quantifier . These features allow reasoning directly on expressions containing bound variables .
A Simplified Suspension Calculus and its Relationship to Other Explicit Substitution Calculi
This paper concerns the explicit treatment of substitutions in the lambda calculus . One of its contributions is the simplification and rationalization of the suspension calculus that embodies such a treatment . The earlier version of this calculus provides a cumbersome encoding of substitution composition , an operation that is important to the efficient realization of reduction . This encoding is simplified here , resulting in a treatment that is easy to use directly in applications . The rationalization consists of the elimination of a practically inconsequential flexibility in the unravelling of substitutions that has the inadvertent side effect of losing contextual information in terms ; the modified calculus now has a structure that naturally supports logical analyses , such as ones related to the assignment of types , over lambda terms . The overall calculus is shown to have pleasing theoretical properties such as a strongly terminating sub - calculus for substitution and confluence even in the presence of term meta variables that are accorded a grafting interpretation . Another contribution of the paper is the identification of a broad set of properties that are desirable for explicit substitution calculi to support and a classification of a variety of proposed systems based on these . The suspension calculus is used as a tool in this study . In particular , mappings are described between it and the other calculi towards understanding the characteristics of the latter .
How Overlap Determines the Macronuclear Genes in Ciliates
Formal models for gene assembly in ciliates have been developed , in particular the string pointer reduction system ( SPRS ) and the graph pointer reduction system ( GPRS ) . The reduction graph is a valuable tool within the SPRS , revealing much information about how gene assembly is performed for a given gene . The GPRS is more abstract than the SPRS and not all information present in the SPRS is retained in the GPRS . As a consequence the reduction graph can not be defined for the GPRS in general , but we show that it can be defined ( in an equivalent manner as defined for the SPRS ) if we restrict ourselves to so - called realistic overlap graphs . Fortunately , only these graphs correspond to genes occurring in nature . Defining the reduction graph within the GPRS allows one to carry over several results within the SPRS that rely on the reduction graph .
Static Dependency Pair Method based on Strong Computability for Higher - Order Rewrite Systems
Higher - order rewrite systems ( HRSs ) and simply - typed term rewriting systems ( STRSs ) are computational models of functional programs . We recently proposed an extremely powerful method , the static dependency pair method , which is based on the notion of strong computability , in order to prove termination in STRSs . In this paper , we extend the method to HRSs . Since HRSs include \lambda - abstraction but STRSs do not , we restructure the static dependency pair method to allow \lambda - abstraction , and show that the static dependency pair method also works well on HRSs without new restrictions .
Detecting Spurious Counterexamples Efficiently in Abstract Model Checking
Abstraction is one of the most important strategies for dealing with the state space explosion problem in model checking . In the abstract model , the state space is largely reduced , however , a counterexample found in such a model may not be a real counterexample in the concrete model . Accordingly , the abstract model needs to be further refined . How to check whether or not a reported counterexample is spurious is a key problem in the abstraction - refinement loop . In this paper , a formal definition for spurious path is given . Based on it , efficient algorithms for detecting spurious counterexamples are proposed .
Revisiting Trace and Testing Equivalences for Nondeterministic and Probabilistic Processes
Two of the most studied extensions of trace and testing equivalences to nondeterministic and probabilistic processes induce distinctions that have been questioned and lack properties that are desirable . Probabilistic trace - distribution equivalence differentiates systems that can perform the same set of traces with the same probabilities , and is not a congruence for parallel composition . Probabilistic testing equivalence , which relies only on extremal success probabilities , is backward compatible with testing equivalences for restricted classes of processes , such as fully nondeterministic processes or generative / reactive probabilistic processes , only if specific sets of tests are admitted . In this paper , new versions of probabilistic trace and testing equivalences are presented for the general class of nondeterministic and probabilistic processes . The new trace equivalence is coarser because it compares execution probabilities of single traces instead of entire trace distributions , and turns out to be compositional . The new testing equivalence requires matching all resolutions of nondeterminism on the basis of their success probabilities , rather than comparing only extremal success probabilities , and considers success probabilities in a trace - by - trace fashion , rather than cumulatively on entire resolutions . It is fully backward compatible with testing equivalences for restricted classes of processes ; as a consequence , the trace - by - trace approach uniformly captures the standard probabilistic testing equivalences for generative and reactive probabilistic processes . The paper discusses in full details the new equivalences and provides a simple spectrum that relates them with existing ones in the setting of nondeterministic and probabilistic processes .
Lazy Model Expansion : Interleaving Grounding with Search
Finding satisfying assignments for the variables involved in a set of constraints can be cast as a ( bounded ) model generation problem : search for ( bounded ) models of a theory in some logic . The state - of - the - art approach for bounded model generation for rich knowledge representation languages , like ASP , FO ( . ) and Zinc , is ground - and - solve : reduce the theory to a ground or propositional one and apply a search algorithm to the resulting theory . An important bottleneck is the blowup of the size of the theory caused by the reduction phase . Lazily grounding the theory during search is a way to overcome this bottleneck . We present a theoretical framework and an implementation in the context of the FO ( . ) knowledge representation language . Instead of grounding all parts of a theory , justifications are derived for some parts of it . Given a partial assignment for the grounded part of the theory and valid justifications for the formulas of the non - grounded part , the justifications provide a recipe to construct a complete assignment that satisfies the non - grounded part . When a justification for a particular formula becomes invalid during search , a new one is derived ; if that fails , the formula is split in a part to be grounded and a part that can be justified . The theoretical framework captures existing approaches for tackling the grounding bottleneck such as lazy clause generation and grounding - on - the - fly , and presents a generalization of the 2-watched literal scheme . We present an algorithm for lazy model expansion and integrate it in a model generator for FO(ID ) , a language extending first - order logic with inductive definitions . The algorithm is implemented as part of the state - of - the - art FO(ID ) Knowledge - Base System IDP . Experimental results illustrate the power and generality of the approach .
A proof - theoretic view on scheduling in concurrency
This paper elaborates on a new approach of the question of the proof - theoretic study of concurrent interaction called " proofs as schedules " . Observing that proof theory is well suited to the description of confluent systems while concurrency has non - determinism as a fundamental feature , we develop a correspondence where proofs provide what is needed to make concurrent systems confluent , namely scheduling . In our logical system , processes and schedulers appear explicitly as proofs in different fragments of the proof language and cut elimination between them does correspond to execution of a concurrent system . This separation of roles suggests new insights for the denotational semantics of processes and new methods for the translation of pi - calculi into prefix - less formalisms ( like solos ) as the operational counterpart of translations between proof systems .
Extending ALCQIO with reachability
We introduce a description logic ALCQIO_{b , Re } which adds reachability assertions to ALCQIO , a sub - logic of the two - variable fragment of first order logic with counting quantifiers . ALCQIO_{b , Re } is well - suited for applications in software verification and shape analysis . Shape analysis requires expressive logics which can express reachability and have good computational properties . We show that ALCQIO_{b , Re } can describe complex data structures with a high degree of sharing and allows compositions such as list of trees . We show that the finite satisfiability and implication problems of ALCQIO_{b , Re}-formulae are polynomial - time reducible to finite satisfiability of ALCQIO - formulae . As a consequence , we get that finite satisfiability and finite implication in ALCQIO_{b , Re } are NEXPTIME - complete . Description logics with transitive closure constructors have been studied before , but ALCQIO_{b , Re } is the first description logic that remains decidable on finite structures while allowing at the same time nominals , inverse roles , counting quantifiers and reachability assertions ,
On coalgebras with internal moves
In the first part of the paper we recall the coalgebraic approach to handling the so - called invisible transitions that appear in different state - based systems semantics . We claim that these transitions are always part of the unit of a certain monad . Hence , coalgebras with internal moves are exactly coalgebras over a monadic type . The rest of the paper is devoted to supporting our claim by studying two important behavioural equivalences for state - based systems with internal moves , namely : weak bisimulation and trace semantics . We continue our research on weak bisimulations for coalgebras over order enriched monads . The key notions used in this paper and proposed by us in our previous work are the notions of an order saturation monad and a saturator . A saturator operator can be intuitively understood as a reflexive , transitive closure operator . There are two approaches towards defining saturators for coalgebras with internal moves . Here , we give necessary conditions for them to yield the same notion of weak bisimulation . Finally , we propose a definition of trace semantics for coalgebras with silent moves via a uniform fixed point operator . We compare strong and weak bisimilation together with trace semantics for coalgebras with internal steps .
Superposition as a logical glue
The typical mathematical language systematically exploits notational and logical abuses whose resolution requires not just the knowledge of domain specific notation and conventions , but not trivial skills in the given mathematical discipline . A large part of this background knowledge is expressed in form of equalities and isomorphisms , allowing mathematicians to freely move between different incarnations of the same entity without even mentioning the transformation . Providing ITP - systems with similar capabilities seems to be a major way to improve their intelligence , and to ease the communication between the user and the machine . The present paper discusses our experience of integration of a superposition calculus within the Matita interactive prover , providing in particular a very flexible , " smart " application tactic , and a simple , innovative approach to automation .
Stateless HOL
We present a version of the HOL Light system that supports undoing definitions in such a way that this does not compromise the soundness of the logic . In our system the code that keeps track of the constants that have been defined thus far has been moved out of the kernel . This means that the kernel now is purely functional . The changes to the system are small . All existing HOL Light developments can be run by the stateless system with only minor changes . The basic principle behind the system is not to name constants by strings , but by pairs consisting of a string and a definition . This means that the data structures for the terms are all merged into one big graph . OCaml - the implementation language of the system - can use pointer equality to establish equality of data structures fast . This allows the system to run at acceptable speeds . Our system runs at about 85% of the speed of the stateful version of HOL Light .
Nonuniform Coercions via Unification Hints
We introduce the notion of nonuniform coercion , which is the promotion of a value of one type to an enriched value of a different type via a nonuniform procedure . Nonuniform coercions are a generalization of the ( uniform ) coercions known in the literature and they arise naturally when formalizing mathematics in an higher order interactive theorem prover using convenient devices like canonical structures , type classes or unification hints . We also show how nonuniform coercions can be naturally implemented at the user level in an interactive theorem prover that allows unification hints .
Generic Trace Logics
We combine previous work on coalgebraic logic with the coalgebraic traces semantics of Hasuo , Jacobs , and Sokolova .
Typed Operational Semantics for Dependent Record Types
Typed operational semantics is a method developed by H. Goguen to prove meta - theoretic properties of type systems . This paper studies the metatheory of a type system with dependent record types , using the approach of typed operational semantics . In particular , the metatheoretical properties we have proved include strong normalisation , Church - Rosser and subject reduction .
Matching Multiplications in Bit - Vector Formulas
Bit - vector formulas arising from hardware verification problems often contain word - level arithmetic operations . Empirical evidence shows that state - of - the - art SMT solvers are not very efficient at reasoning about bit - vector formulas with multiplication . This is particularly true when multiplication operators are decomposed and represented in alternative ways in the formula . We present a pre - processing heuristic that identifies certain types of decomposed multipliers , and adds special assertions to the input formula encoding the equivalence of sub - terms to word - level multiplication . The pre - processed formulas are then solved using an SMT solver . Our experiments with three SMT solvers show that our heuristic allows several formulas to be solved quickly , while the same formulas time out without the pre - processing step .
Information Flow in Logical Environments
This paper describes information flow within logical environments . The theory of information flow , the logic of distributed systems , was first defined by Barwise and Seligman ( Information Flow : The Logic of Distributed Systems . 1997 ) . Logical environments are a semantic - oriented version of institutions . The theory of institutions , which was initiated by Goguen and Burstall ( Institutions : Abstract Model Theory for Specification and Programming . 1992 ) , is abstract model theory . Information flow is the flow of information in channels over distributed systems . The semantic integration of distributed systems , be they ontologies , databases or other information resources , can be defined in terms of the channel theory of information flow . As originally defined , the theory of information flow uses only a specific logical environment in order to discuss information flow . This paper shows how information flow can be defined in an arbitrary logical environment .
Order - Invariant Types and Their Applications
Our goal is to show that the standard model - theoretic concept of types can be applied in the study of order - invariant properties , i.e. , properties definable in a logic in the presence of an auxiliary order relation , but not actually dependent on that order relation . This is somewhat surprising since order - invariant properties are more of a combinatorial rather than a logical object . We provide two applications of this notion . One is a proof , from the basic principles , of a theorem by Courcelle stating that over trees , order - invariant MSO properties are expressible in MSO with counting quantifiers . The other is an analog of the Feferman - Vaught theorem for order - invariant properties .
Controllable - choice Message Sequence Graphs
We focus on the realizability problem of Message Sequence Graphs ( MSG ) , i.e. the problem whether a given MSG specification is correctly distributable among parallel components communicating via messages . This fundamental problem of MSG is known to be undecidable . We introduce a well motivated restricted class of MSG , so called controllable - choice MSG , and show that all its models are realizable and moreover it is decidable whether a given MSG model is a member of this class . In more detail , this class of MSG specifications admits a deadlock - free realization by overloading existing messages with additional bounded control data . We also show that the presented class is the largest known subclass of MSG that allows for deadlock - free realization .
Random strings and tt - degrees of Turing complete C.E. sets
We investigate the truth - table degrees of ( co-)c.e.\ sets , in particular , sets of random strings . It is known that the set of random strings with respect to any universal prefix - free machine is Turing complete , but that truth - table completeness depends on the choice of universal machine . We show that for such sets of random strings , any finite set of their truth - table degrees do not meet to the degree~0 , even within the c.e . truth - table degrees , but when taking the meet over all such truth - table degrees , the infinite meet is indeed~0 . The latter result proves a conjecture of Allender , Friedman and Gasarch . We also show that there are two Turing complete c.e . sets whose truth - table degrees form a minimal pair .
Towards a Feature mu - Calculus Targeting SPL Verification
The modal mu - calculus mu - L is a well - known fixpoint logic to express and model check properties interpreted over labeled transition systems . In this paper , we propose two variants of the mu - calculus , mu - Lf and mu - Lf ' , for feature transition systems . For this , we explicitly incorporate feature expressions into the logics , allowing operators to select transitions and behavior restricted to specific products and subfamilies . We provide semantics for mu - Lf and mu - Lf ' and relate the two new mu - calculi and mu - L to each other . Next , we focus on the analysis of SPL behavior and show how our formalism can be applied for product - based verification with mu - Lf as well as family - based verification with mu - Lf ' . We illustrate by means of a toy example how properties can be model checked , exploiting an embedding of mu - Lf ' into the mu - calculus with data .
Structural Multi - type Sequent Calculus for Inquisitive Logic
In this paper , we define a multi - type calculus for inquisitive logic , which is sound , complete and enjoys Belnap - style cut - elimination and subformula property . Inquisitive logic is the logic of inquisitive semantics , a semantic framework developed by Groenendijk , Roelofsen and Ciardelli which captures both assertions and questions in natural language . Inquisitive logic is sound and complete w.r.t . the so - called state semantics ( also known as team semantics ) . The Hilbert - style presentation of inquisitive logic is not closed under uniform substitution ; indeed , some occurrences of formulas are restricted to a certain subclass of formulas , called flat formulas . This and other features make the quest for analytic calculi for this logic not straightforward . We develop a certain algebraic and order - theoretic analysis of the team semantics , which provides the guidelines for the design of a multi - type environment which accounts for two domains of interpretation , for flat and for general formulas , as well as for their interaction . This multi - type environment in its turn provides the semantic environment for the multi - type calculus for inquisitive logic we introduce in this paper .
Parameter Synthesis for Markov Models : Faster Than Ever
We propose a simple technique for verifying probabilistic models whose transition probabilities are parametric . The key is to replace parametric transitions by nondeterministic choices of extremal values . Analysing the resulting parameter - free model using off - the - shelf means yields ( refinable ) lower and upper bounds on probabilities of regions in the parameter space . The technique outperforms the existing analysis of parametric Markov chains by several orders of magnitude regarding both run - time and scalability . Its beauty is its applicability to various probabilistic models . It in particular provides the first sound and feasible method for performing parameter synthesis of Markov decision processes .
Quantitative classical realizability
Introduced by Dal Lago and Hofmann , quantitative realizability is a technique used to define models for logics based on Multiplicative Linear Logic . A particularity is that functions are interpreted as bounded time computable functions . It has been used to give new and uniform proofs of soundness of several type systems with respect to certain time complexity classes . We propose a reformulation of their ideas in the setting of Krivine 's classical realizability . The framework obtained generalizes Dal Lago and Hofmann 's realizability , and reveals deep connections between quantitative realizability and a linear variant of Cohen 's forcing .
Coalgebraic Trace Semantics for Continuous Probabilistic Transition Systems
Coalgebras in a Kleisli category yield a generic definition of trace semantics for various types of labelled transition systems . In this paper we apply this generic theory to generative probabilistic transition systems , short PTS , with arbitrary ( possibly uncountable ) state spaces . We consider the sub - probability monad and the probability monad ( Giry monad ) on the category of measurable spaces and measurable functions . Our main contribution is that the existence of a final coalgebra in the Kleisli category of these monads is closely connected to the measure - theoretic extension theorem for sigma - finite pre - measures . In fact , we obtain a practical definition of the trace measure for both finite and infinite traces of PTS that subsumes a well - known result for discrete probabilistic transition systems . Finally we consider two example systems with uncountable state spaces and apply our theory to calculate their trace measures .
The Power of Well - Structured Systems
Well - structured systems , aka WSTSs , are computational models where the set of possible configurations is equipped with a well - quasi - ordering which is compatible with the transition relation between configurations . This structure supports generic decidability results that are important in verification and several other fields . This paper recalls the basic theory underlying well - structured systems and shows how two classic decision algorithms can be formulated as an exhaustive search for some " bad " sequences . This lets us describe new powerful techniques for the complexity analysis of WSTS algorithms . Recently , these techniques have been successful in precisely characterising the power , in a complexity - theoretical sense , of several important WSTS models like unreliable channel systems , monotonic counter machines , or networks of timed systems .
Verification of Markov Decision Processes using Learning Algorithms
We present a general framework for applying machine - learning algorithms to the verification of Markov decision processes ( MDPs ) . The primary goal of these techniques is to improve performance by avoiding an exhaustive exploration of the state space . Our framework focuses on probabilistic reachability , which is a core property for verification , and is illustrated through two distinct instantiations . The first assumes that full knowledge of the MDP is available , and performs a heuristic - driven partial exploration of the model , yielding precise lower and upper bounds on the required probability . The second tackles the case where we may only sample the MDP , and yields probabilistic guarantees , again in terms of both the lower and upper bounds , which provides efficient stopping criteria for the approximation . The latter is the first extension of statistical model - checking for unbounded properties in MDPs . In contrast with other related approaches , we do not restrict our attention to time - bounded ( finite - horizon ) or discounted properties , nor assume any particular properties of the MDP . We also show how our techniques extend to LTL objectives . We present experimental results showing the performance of our framework on several examples .
Robust Synchronization in Markov Decision Processes
We consider synchronizing properties of Markov decision processes ( MDP ) , viewed as generators of sequences of probability distributions over states . A probability distribution is p - synchronizing if the probability mass is at least p in some state , and a sequence of probability distributions is weakly p - synchronizing , or strongly p - synchronizing if respectively infinitely many , or all but finitely many distributions in the sequence are p - synchronizing . For each synchronizing mode , an MDP can be ( i ) sure winning if there is a strategy that produces a 1-synchronizing sequence ; ( ii ) almost - sure winning if there is a strategy that produces a sequence that is , for all { \epsilon } > 0 , a ( 1-{\epsilon})-synchronizing sequence ; ( iii ) limit - sure winning if for all { \epsilon } > 0 , there is a strategy that produces a ( 1-{\epsilon})-synchronizing sequence . For each synchronizing and winning mode , we consider the problem of deciding whether an MDP is winning , and we establish matching upper and lower complexity bounds of the problems , as well as the optimal memory requirement for winning strategies : ( a ) for all winning modes , we show that the problems are PSPACE - complete for weakly synchronizing , and PTIME - complete for strongly synchronizing ; ( b ) we show that for weakly synchronizing , exponential memory is sufficient and may be necessary for sure winning , and infinite memory is necessary for almost - sure winning ; for strongly synchronizing , linear - size memory is sufficient and may be necessary in all modes ; ( c ) we show a robustness result that the almost - sure and limit - sure winning modes coincide for both weakly and strongly synchronizing .
Strong Turing Degrees for Additive BSS RAM 's
For the additive real BSS machines using only constants 0 and 1 and order tests we consider the corresponding Turing reducibility and characterize some semi - decidable decision problems over the reals . In order to refine , step - by - step , a linear hierarchy of Turing degrees with respect to this model , we define several halting problems for classes of additive machines with different abilities and construct further suitable decision problems . In the construction we use methods of the classical recursion theory as well as techniques for proving bounds resulting from algebraic properties . In this way we extend a known hierarchy of problems below the halting problem for the additive machines using only equality tests and we present a further subhierarchy of semi - decidable problems between the halting problems for the additive machines using only equality tests and using order tests , respectively .
Parametrized Invariance for Infinite State Processes
We study the uniform verification problem for infinite state processes , which consists of proving that the parallel composition of an arbitrary number of processes satisfies a temporal property . Our practical motivation is to build a general framework for the temporal verification of concurrent datatypes . The contribution of this paper is a general method for the verification of safety properties of parametrized programs that manipulate complex local and global data , including mutable state in the heap . This method is based on the separation between two concerns : ( 1 ) the interaction between executing threads --- handled by novel parametrized invariance rules---,and the data being manipulated --- handled by specialized decision procedures . The proof rules discharge automatically a finite collection of verification conditions ( VCs ) , the number depending only on the size of the program description and the specification , but not on the number of processes in any given instance or on the kind of data manipulated . Moreover , all VCs are quantifier free , which eases the development of decision procedures for complex data - types on top of off - the - shelf SMT solvers . We discuss the practical verification ( of shape and also functional correctness properties ) of a concurrent list implementation based on the method presented in this paper . Our tool also all VCs using a decision procedure for a theory of list layouts in the heap built on top of state - of - the - art SMT solvers .
On - the - fly Fast Mean - Field Model - Checking : Extended Version
A novel , scalable , on - the - fly model - checking procedure is presented to verify bounded PCTL properties of selected individuals in the context of very large systems of independent interacting objects . The proposed procedure combines on - the - fly model checking techniques with deterministic mean - field approximation in discrete time . The asymptotic correctness of the procedure is shown and some results of the application of a prototype implementation of the FlyFast model - checker are presented .
Call - by - value non - determinism in a linear logic type discipline
We consider the call - by - value lambda - calculus extended with a may - convergent non - deterministic choice and a must - convergent parallel composition . Inspired by recent works on the relational semantics of linear logic and non - idempotent intersection types , we endow this calculus with a type system based on the so - called Girard 's second translation of intuitionistic logic into linear logic . We prove that a term is typable if and only if it is converging , and that its typing tree carries enough information to give a bound on the length of its lazy call - by - value reduction . Moreover , when the typing tree is minimal , such a bound becomes the exact length of the reduction .
Compatibility of Shelah and Stupp 's and Muchnik 's iteration with fragments of monadic second order logic
We investigate the relation between the theory of the iterations in the sense of Shelah - Stupp and of Muchnik , resp . , and the theory of the base structure for several logics . These logics are obtained from the restriction of set quantification in monadic second order logic to certain subsets like , e.g. , finite sets , chains , and finite unions of chains . We show that these theories of the Shelah - Stupp iteration can be reduced to corresponding theories of the base structure . This fails for Muchnik 's iteration .
Cardinality and counting quantifiers on omega - automatic structures
We investigate structures that can be represented by omega - automata , so called omega - automatic structures , and prove that relations defined over such structures in first - order logic expanded by the first - order quantifiers ` there exist at most $ \aleph_0 $ many ' , ' there exist finitely many ' and ' there exist $ k$ modulo $ m$ many ' are omega - regular . The proof identifies certain algebraic properties of omega - semigroups . As a consequence an omega - regular equivalence relation of countable index has an omega - regular set of representatives . This implies Blumensath 's conjecture that a countable structure with an $ \omega$-automatic presentation can be represented using automata on finite words . This also complements a very recent result of Hj\"orth , Khoussainov , Montalban and Nies showing that there is an omega - automatic structure which has no injective presentation .
Towards a formalization of budgets
We go into the need for , and the requirements on , a formal theory of budgets . We present a simple algebraic theory of rational budgets , i.e. , budgets in which amounts of money are specified by functions on the rational numbers . This theory is based on the tuplix calculus . We go into the importance of using totalized models for the rational numbers . We present a case study on the educational budget of a university department offering master programs .
An ExpTime Procedure for Description Logic $ \mathcal{ALCQI}$ ( Draft )
A worst - case ExpTime tableau - based decision procedure is outlined for the satisfiability problem in $ \mathcal{ALCQI}$ w.r.t . general axioms .
On the Completeness of Selective Unification in Concolic Testing of Logic Programs
Concolic testing is a popular dynamic validation technique that can be used for both model checking and automatic test case generation . We have recently introduced concolic testing in the context of logic programming . In contrast to previous approaches , the key ingredient in this setting is a technique to generate appropriate run - time goals by considering all possible ways an atom can unify with the heads of some program clauses . This is called " selective " unification . In this paper , we show that the existing algorithm is not complete and explore different alternatives in order to have a sound and complete algorithm for selective unification .
Relating Nominal and Higher - order Abstract Syntax Specifications
Nominal abstract syntax and higher - order abstract syntax provide a means for describing binding structure which is higher - level than traditional techniques . These approaches have spawned two different communities which have developed along similar lines but with subtle differences that make them difficult to relate . The nominal abstract syntax community has devices like names , freshness , name - abstractions with variable capture , and the new - quantifier , whereas the higher - order abstract syntax community has devices like lambda - binders , lambda - conversion , raising , and the nabla - quantifier . This paper aims to unify these communities and provide a concrete correspondence between their different devices . In particular , we develop a semantics - preserving translation from alpha - Prolog , a nominal abstract syntax based logic programming language , to G- , a higher - order abstract syntax based logic programming language . We also discuss higher - order judgments , a common and powerful tool for specifications with higher - order abstract syntax , and we show how these can be incorporated into G- . This establishes G- as a language with the power of higher - order abstract syntax , the fine - grained variable control of nominal specifications , and the desirable properties of higher - order judgments .
Categorical Models for a Semantically Linear Lambda - calculus
This paper is about a categorical approach to model a very simple Semantically Linear lambda calculus , named Sll - calculus . This is a core calculus underlying the programming language SlPCF . In particular , in this work , we introduce the notion of Sll - Category , which is able to describe a very large class of sound models of Sll - calculus . Sll - Category extends in the natural way Benton , Bierman , Hyland and de Paiva 's Linear Category , in order to soundly interpret all the constructs of Sll - calculus . This category is general enough to catch interesting models in Scott Domains and Coherence Spaces .
Resource - Bound Quantification for Graph Transformation
Graph transformation has been used to model concurrent systems in software engineering , as well as in biochemistry and life sciences . The application of a transformation rule can be characterised algebraically as construction of a double - pushout ( DPO ) diagram in the category of graphs . We show how intuitionistic linear logic can be extended with resource - bound quantification , allowing for an implicit handling of the DPO conditions , and how resource logic can be used to reason about graph transformation systems .
Labelled Lambda - calculi with Explicit Copy and Erase
We present two rewriting systems that define labelled explicit substitution lambda - calculi . Our work is motivated by the close correspondence between Levy 's labelled lambda - calculus and paths in proof - nets , which played an important role in the understanding of the Geometry of Interaction . The structure of the labels in Levy 's labelled lambda - calculus relates to the multiplicative information of paths ; the novelty of our work is that we design labelled explicit substitution calculi that also keep track of exponential information present in call - by - value and call - by - name translations of the lambda - calculus into linear logic proof - nets .
Expressiveness of Generic Process Shape Types
Shape types are a general concept of process types which work for many process calculi . We extend the previously published Poly * system of shape types to support name restriction . We evaluate the expressiveness of the extended system by showing that shape types are more expressive than an implicitly typed pi - calculus and an explicitly typed Mobile Ambients . We demonstrate that the extended system makes it easier to enjoy advantages of shape types which include polymorphism , principal typings , and a type inference implementation .
Modelling MAC - Layer Communications in Wireless Systems
We present a timed process calculus for modelling wireless networks in which individual stations broadcast and receive messages ; moreover the broadcasts are subject to collisions . Based on a reduction semantics for the calculus we define a contextual equivalence to compare the external behaviour of such wireless networks . Further , we construct an extensional LTS ( labelled transition system ) which models the activities of stations that can be directly observed by the external environment . Standard bisimulations in this LTS provide a sound proof method for proving systems contextually equivalence . We illustrate the usefulness of the proof methodology by a series of examples . Finally we show that this proof method is also complete , for a large class of systems .
Permission - Based Separation Logic for Multithreaded Java Programs
This paper presents a program logic for reasoning about multithreaded Java - like programs with dynamic thread creation , thread joining and reentrant object monitors . The logic is based on concurrent separation logic . It is the first detailed adaptation of concurrent separation logic to a multithreaded Java - like language . The program logic associates a unique static access permission with each heap location , ensuring exclusive write accesses and ruling out data races . Concurrent reads are supported through fractional permissions . Permissions can be transferred between threads upon thread starting , thread joining , initial monitor entrancies and final monitor exits . In order to distinguish between initial monitor entrancies and monitor reentrancies , auxiliary variables keep track of multisets of currently held monitors . Data abstraction and behavioral subtyping are facilitated through abstract predicates , which are also used to represent monitor invariants , preconditions for thread starting and postconditions for thread joining . Value - parametrized types allow to conveniently capture common strong global invariants , like static object ownership relations . The program logic is presented for a model language with Java - like classes and interfaces , the soundness of the program logic is proven , and a number of illustrative examples are presented .
Greatest solutions of equations in $ \text{CLL}_R$ and its application
This paper explores the process calculus $ \text{CLL}_R$ furtherly . First , we prove that for any equation $ X=_{RS } t_X$ such that $ X$ is strongly guarded in $ t_X$ , $ \langle X|X = t_X \rangle$ is the largest solution w.r.t $ \sqsubseteq_{RS}$. Second , we encode a fragment of action - based CTL in $ \text{CLL}_R$.
Discriminating Lambda - Terms Using Clocked Boehm Trees
As observed by Intrigila , there are hardly techniques available in the lambda - calculus to prove that two lambda - terms are not beta - convertible . Techniques employing the usual Boehm Trees are inadequate when we deal with terms having the same Boehm Tree ( BT ) . This is the case in particular for fixed point combinators , as they all have the same BT . Another interesting equation , whose consideration was suggested by Scott , is BY = BYS , an equation valid in the classical model P - omega of lambda - calculus , and hence valid with respect to BT - equality but nevertheless the terms are beta - inconvertible . To prove such beta - inconvertibilities , we employ ` clocked ' BT 's , with annotations that convey information of the tempo in which the data in the BT are produced . Boehm Trees are thus enriched with an intrinsic clock behaviour , leading to a refined discrimination method for lambda - terms . The corresponding equality is strictly intermediate between beta - convertibility and Boehm Tree equality , the equality in the model P - omega . An analogous approach pertains to Levy - Longo and Berarducci Trees . Our refined Boehm Trees find in particular an application in beta - discriminating fixed point combinators ( fpc 's ) . It turns out that Scott 's equation BY = BYS is the key to unlocking a plethora of fpc 's , generated by a variety of production schemes of which the simplest was found by Boehm , stating that new fpc 's are obtained by postfixing the term SI , also known as Smullyan 's Owl . We prove that all these newly generated fpc 's are indeed new , by considering their clocked BT 's . Even so , not all pairs of new fpc 's can be discriminated this way . For that purpose we increase the discrimination power by a precision of the clock notion that we call ` atomic clock ' .
DBGen User Manual
DBGen is a tool for Coq developers . It takes as input the definition of a term structure with bindings annotations and generates definitions and properties for lifting and substitution in the De Bruijn setting , up to the substitution lemma . It provides also a named syntax and a translation function to the De Bruijn syntax .
Congruence from the Operator 's Point of View : Compositionality Requirements on Process Semantics
One of the basic sanity properties of a behavioural semantics is that it constitutes a congruence with respect to standard process operators . This issue has been traditionally addressed by the development of rule formats for transition system specifications that define process algebras . In this paper we suggest a novel , orthogonal approach . Namely , we focus on a number of process operators , and for each of them attempt to find the widest possible class of congruences . To this end , we impose restrictions on sublanguages of Hennessy - Milner logic , so that a semantics whose modal characterization satisfies a given criterion is guaranteed to be a congruence with respect to the operator in question . We investigate action prefix , alternative composition , two restriction operators , and parallel composition .
Structural Decomposition of Reactions of Graph - Like Objects
Inspired by decomposition problems in rule - based formalisms in Computational Systems Biology and recent work on compositionality in graph transformation , this paper proposes to use arbitrary colimits to " deconstruct " models of reactions in which states are represented as objects of adhesive categories . The fundamental problem is the decomposition of complex reactions of large states into simpler reactions of smaller states . The paper defines the local decomposition problem for transformations . To solve this problem means to " reconstruct " a given transformation as the colimit of " smaller " ones where the shape of the colimit and the decomposition of the source object of the transformation are fixed in advance . The first result is the soundness of colimit decomposition for arbitrary double pushout transformations in any category , which roughly means that several " local " transformations can be combined into a single " global " one . Moreover , a solution for a certain class of local decomposition problems is given , which generalizes and clarifies recent work on compositionality in graph transformation .
Type Classes for Mathematics in Type Theory
The introduction of first - class type classes in the Coq system calls for re - examination of the basic interfaces used for mathematical formalization in type theory . We present a new set of type classes for mathematics and take full advantage of their unique features to make practical a particularly flexible approach formerly thought infeasible . Thus , we address both traditional proof engineering challenges as well as new ones resulting from our ambition to build upon this development a library of constructive analysis in which abstraction penalties inhibiting efficient computation are reduced to a minimum . The base of our development consists of type classes representing a standard algebraic hierarchy , as well as portions of category theory and universal algebra . On this foundation we build a set of mathematically sound abstract interfaces for different kinds of numbers , succinctly expressed using categorical language and universal algebra constructions . Strategic use of type classes lets us support these high - level theory - friendly definitions while still enabling efficient implementations unhindered by gratuitous indirection , conversion or projection . Algebra thrives on the interplay between syntax and semantics . The Prolog - like abilities of type class instance resolution allow us to conveniently define a quote function , thus facilitating the use of reflective techniques .
On Paraconsistent Weakening of Intuitionistic Negation
In [ 1 ] , systems of weakening of intuitionistic negation logic called Z_n and CZ_n were developed in the spirit of da Costa 's approach(c.f . [ 2 ] ) by preserving , differently from da Costa , its fundamental properties : antitonicity , inversion and additivity for distributive lattices . However , according to [ 3 ] , those systems turned out to be not paraconsistent but extensions of intuitionistic logic . Taking into account of this result , we shall here make some observations on the modified systems of Z_n and CZ_n , that are paraconsistent as well .
Stuttering Equivalence for Parity Games
We study the process theoretic notion of stuttering equivalence in the setting of parity games . We demonstrate that stuttering equivalent vertices have the same winner in the parity game . This means that solving a parity game can be accelerated by minimising the game graph with respect to stuttering equivalence . While , at the outset , it might not be clear that this strategy should pay off , our experiments using typical verification problems illustrate that stuttering equivalence speeds up solving parity games in many cases .
Time - bounded Reachability for Hybrid Automata : Complexity and Fixpoints
In this paper , we study thetime - bounded reachability problem for rectangular hybrid automata with non - negative rates ( RHA+ ) . This problem was recently shown to be decidable [ Brihaye et al , ICALP11 ] ( even though the unbounded reachability problem for even very simple classes of hybrid automata is well - known to be undecidable ) . However , [ Brihaye et al , ICALP11 ] does not provide a precise characterisation of the complexity of the time - bounded reachability problem . The contribution of the present paper is threefold . First , we provide a new NExpTime algorithm to solve the timed - bounded reachability problem on RHA+ . This algorithm improves on the one of [ Brihaye et al , ICALP11 ] by at least one exponential . Second , we show that this new algorithm is optimal , by establishing a matching lower bound : time - bounded reachability for RHA+ is therefore NExpTime - complete . Third , we extend these results in a practical direction , by showing that we can effectively compute fixpoints that characterise the sets of states that are reachable ( resp . co - reachable ) within T time units from a given starting state .
Proving Looping and Non - Looping Non - Termination by Finite Automata
A new technique is presented to prove non - termination of term rewriting . The basic idea is to find a non - empty regular language of terms that is closed under rewriting and does not contain normal forms . It is automated by representing the language by a tree automaton with a fixed number of states , and expressing the mentioned requirements in a SAT formula . Satisfiability of this formula implies non - termination . Our approach succeeds for many examples where all earlier techniques fail , for instance for the S - rule from combinatory logic .
Analyzing Alloy Formulas using an SMT Solver : A Case Study
This paper describes how Yices , a modern SAT Modulo theories solver , can be used to analyze the address - book problem expressed in Alloy , a first - order relational logic with transitive closure . Current analysis of Alloy models - as performed by the Alloy Analyzer - is based on SAT solving and thus , is done only with respect to finitized types . Our analysis generalizes this approach by taking advantage of the background theories available in Yices , and avoiding type finitization when possible . Consequently , it is potentially capable of proving that an assertion is a tautology - a capability completely missing from the Alloy Analyzer . This paper also reports on our experimental results that compare the performance of our analysis to that of the Alloy Analyzer for various versions of the address book problem .
On Minimal Corrections in ASP
As a programming paradigm , answer set programming ( ASP ) brings about the usual issue of the human error . Hence , it is desirable to provide automated techniques that could help the programmer to find the error . This paper addresses the question of computing a subset - minimal correction of a contradictory ASP program . A contradictory ASP program is often undesirable and we wish to provide an automated way of fixing it . We consider a minimal correction set of a contradictory program to be an irreducible set of rules whose removal makes the program consistent . In contrast to propositional logic , corrections of ASP programs behave non - monotonically . Nevertheless , we show that a variety of algorithms for correction set computation in propositional logic can be ported to ASP . An experimental evaluation was carried showing that having a portfolio of such algorithms is indeed of benefit .
First - order definable string transformations
The connection between languages defined by computational models and logic for languages is well - studied . Monadic second - order logic and finite automata are shown to closely correspond to each - other for the languages of strings , trees , and partial - orders . Similar connections are shown for first - order logic and finite automata with certain aperiodicity restriction . Courcelle in 1994 proposed a way to use logic to define functions over structures where the output structure is defined using logical formulas interpreted over the input structure . Engelfriet and Hoogeboom discovered the corresponding " automata connection " by showing that two - way generalised sequential machines capture the class of monadic - second order definable transformations . Alur and Cerny further refined the result by proposing a one - way deterministic transducer model with string variables --- called the streaming string transducers --- to capture the same class of transformations . In this paper we establish a transducer - logic correspondence for Courcelle 's first - order definable string transformations . We propose a new notion of transition monoid for streaming string transducers that involves structural properties of both underlying input automata and variable dependencies . By putting an aperiodicity restriction on the transition monoids , we define a class of streaming string transducers that captures exactly the class of first - order definable transformations .
Concurrent Kleene Algebra of Partial Strings
Concurrent Kleene Algebra ( CKA ) is a recently proposed algebraic structure by Hoare and collaborators that unifies the laws of concurrent programming . The unifying power of CKA rests largely on the so - called exchange law that describes how concurrent and sequential composition operators can be interchanged . Based on extensive theoretical work on true concurrency in the past , this paper extends Gischer 's pomset model with least fixed point operators and formalizes the program refinement relation by \'{E}sik 's monotonic bijective morphisms to construct a partial order model of CKA . The existence of such a model is relevant when we want to prove and disprove properties about concurrent programs with loops . In particular , it gives a foundation for the analysis of programs that concurrently access relaxed memory as shown in subsequent work .
Polynomial Interpretations over the Natural , Rational and Real Numbers Revisited
Polynomial interpretations are a useful technique for proving termination of term rewrite systems . They come in various flavors : polynomial interpretations with real , rational and integer coefficients . As to their relationship with respect to termination proving power , Lucas managed to prove in 2006 that there are rewrite systems that can be shown polynomially terminating by polynomial interpretations with real ( algebraic ) coefficients , but can not be shown polynomially terminating using polynomials with rational coefficients only . He also proved the corresponding statement regarding the use of rational coefficients versus integer coefficients . In this article we extend these results , thereby giving the full picture of the relationship between the aforementioned variants of polynomial interpretations . In particular , we show that polynomial interpretations with real or rational coefficients do not subsume polynomial interpretations with integer coefficients . Our results hold also for incremental termination proofs with polynomial interpretations .
Algebraic and relational models for a system based on a poset of two elements
The aim of this paper is to present a very simple set of conditions , necessary for the management of knowledge of a poset $ T$ of two agents , which are partially ordered by the capabilities available in the system . We build up a formal system and we elaborate suitable semantic models in order to derive information from the poset . The system is related to three - valued Heyting algebras with Boolean operators .
The DRAT format and DRAT - trim checker
This document describes the DRAT format for clausal proofs and the DRAT - trim proof checker .
On Sessions and Infinite Data
We investigate some subtle issues that arise when programming distributed computations over infinite data structures . To do this , we formalise a calculus that combines a call - by - name functional core with session - based communication primitives and that allows session operations to be performed " on demand " . We develop a typing discipline that guarantees both normalisation of expressions and progress of processes and that uncovers an unexpected interplay between evaluation and communication .
Compositional bisimulation metric reasoning with Probabilistic Process Calculi
We study which standard operators of probabilistic process calculi allow for compositional reasoning with respect to bisimulation metric semantics . We argue that uniform continuity ( generalizing the earlier proposed property of non - expansiveness ) captures the essential nature of compositional reasoning and allows now also to reason compositionally about recursive processes . We characterize the distance between probabilistic processes composed by standard process algebra operators . Combining these results , we demonstrate how compositional reasoning about systems specified by continuous process algebra operators allows for metric assume - guarantee like performance validation .
A Hybrid Hoare Logic for Gene Network Models
The main difficulty when modelling gene networks is the identification of the parameters that govern their dynamics . It is particularly difficult for models in which time is continuous : parameters have real values which can not be enumerated . The widespread idea is to infer new constraints that reduce the range of possible values . Here we present a new work based on a particular class of Hybrid automata ( inspired by Thomas discrete models ) where discrete parameters are replaced by signed celerities . We propose a new approach involving Hoare logic and weakest precondition calculus ( a la Dijkstra ) that generates constraints on the parameter values . Indeed , once proper specifications are extracted from biological traces with duration information ( found in the literature or biological experiments ) , they play a role similar to imperative programs in the classical Hoare logic . We illustrate our hybrid Hoare logic on a small model controlling the lacI repressor of the lactose operon .
Reactive Turing Machines with Infinite Alphabets
The notion of Reactive Turing machine ( RTM ) was proposed as an orthogonal extension of Turing machines with interaction . RTMs are used to define the notion of executable transition system in the same way as Turing machines are used to define the notion of computable function on natural numbers . RTMs inherited finiteness of all sets involved from Turing machines , and as a consequence , in a single step , an RTM can only communicate elements from a finite set of data . Some process calculi , such as the pi - calculus , essentially depend on an infinite alphabet of actions , and hence it immediately follows that transition systems specified in these calculi are not executable . On closer inspection , however , the pi - calculus does not appear to use the infinite data in a non - computable manner . In this paper , we investigate several ways to relax the finiteness requirement . We start by considering a variant of RTMs in which all sets are allowed to be countable , and we get a notion of infinitary RTM . Infinitary RTMs are extremely expressive such that we can hardly use them as a expressiveness criterion . Then , we refine the model by adding extra restrictions . As a result , we define a notion of RTM with atoms . It is a more restricted variant of RTMs in which the sets of actions and data symbols are still allowed to be infinite . We propose a notion of of nominal executability based on RTMs with atoms , and show that every effective transition system with atoms is nominally executable . It will follow that processes definable in the pi - calculus are nominally executable . In contrast , in the process specification language mCRL2 it is possible to specify processes that are not nominally executable . Thus , nominal executability provides a new expressiveness criterion for process calculi .
Unified Reasoning about Robustness Properties of Symbolic - Heap Separation Logic
We introduce heap automata , a formalism for automatic reasoning about robustness properties of the symbolic heap fragment of separation logic with user - defined inductive predicates . Robustness properties , such as satisfiability , reachability , and acyclicity , are important for a wide range of reasoning tasks in automated program analysis and verification based on separation logic . Previously , such properties have appeared in many places in the separation logic literature , but have not been studied in a systematic manner . In this paper , we develop an algorithmic framework based on heap automata that allows us to derive asymptotically optimal decision procedures for a wide range of robustness properties in a uniform way . We implemented a protoype of our framework and obtained promising results for all of the aforementioned robustness properties . Further , we demonstrate the applicability of heap automata beyond robustness properties . We apply our algorithmic framework to the model checking and the entailment problem for symbolic - heap separation logic .
Sequential decision problems , dependent types and generic solutions
We present a computer - checked generic implementation for solving finite - horizon sequential decision problems . This is a wide class of problems , including inter - temporal optimizations , knapsack , optimal bracketing , scheduling , etc . The implementation can handle time - step dependent control and state spaces , and monadic representations of uncertainty ( such as stochastic , non - deterministic , fuzzy , or combinations thereof ) . This level of genericity is achievable in a programming language with dependent types ( we have used both Idris and Agda ) . Dependent types are also the means that allow us to obtain a formalization and computer - checked proof of the central component of our implementation : Bellman 's principle of optimality and the associated backwards induction algorithm . The formalization clarifies certain aspects of backwards induction and , by making explicit notions such as viability and reachability , can serve as a starting point for a theory of controllability of monadic dynamical systems , commonly encountered in , e.g. , climate impact research .
Efficient Certified Resolution Proof Checking
We present a novel propositional proof tracing format that eliminates complex processing , thus enabling efficient ( formal ) proof checking . The benefits of this format are demonstrated by implementing a proof checker in C , which outperforms a state - of - the - art checker by two orders of magnitude . We then formalize the theory underlying propositional proof checking in Coq , and extract a correct - by - construction proof checker for our format from the formalization . An empirical evaluation using 280 unsatisfiable instances from the 2015 and 2016 SAT competitions shows that this certified checker usually performs comparably to a state - of - the - art non - certified proof checker . Using this format , we formally verify the recent 200 TB proof of the Boolean Pythagorean Triples conjecture .
Automation of separation logic using auto2
We present a new system of automation for separation logic in the interactive theorem prover Isabelle . The system is based on the recently developed auto2 prover , and follows a natural , saturation - based approach to reasoning about imperative programs . In addition to standard examples on linked lists and binary search trees , we apply the automation to red - black trees and indexed priority queues , showing that it provides a high degree of automation even on the more complicated data structures .
Full abstraction for fair testing in CCS ( expanded version )
In previous work with Pous , we defined a semantics for CCS which may both be viewed as an innocent form of presheaf semantics and as a concurrent form of game semantics . We define in this setting an analogue of fair testing equivalence , which we prove fully abstract w.r.t . standard fair testing equivalence . The proof relies on a new algebraic notion called playground , which represents the ` rule of the game ' . From any playground , we derive two languages equipped with labelled transition systems , as well as a strong , functional bisimulation between them .
Formal Design of Asynchronous Fault Detection and Identification Components using Temporal Epistemic Logic
Autonomous critical systems , such as satellites and space rovers , must be able to detect the occurrence of faults in order to ensure correct operation . This task is carried out by Fault Detection and Identification ( FDI ) components , that are embedded in those systems and are in charge of detecting faults in an automated and timely manner by reading data from sensors and triggering predefined alarms . The design of effective FDI components is an extremely hard problem , also due to the lack of a complete theoretical foundation , and of precise specification and validation techniques . In this paper , we present the first formal approach to the design of FDI components for discrete event systems , both in a synchronous and asynchronous setting . We propose a logical language for the specification of FDI requirements that accounts for a wide class of practical cases , and includes novel aspects such as maximality and trace - diagnosability . The language is equipped with a clear semantics based on temporal epistemic logic , and is proved to enjoy suitable properties . We discuss how to validate the requirements and how to verify that a given FDI component satisfies them . We propose an algorithm for the synthesis of correct - by - construction FDI components , and report on the applicability of the design approach on an industrial case - study coming from aerospace .
Compositional Verification for Timed Systems Based on Automatic Invariant Generation
We propose a method for compositional verification to address the state space explosion problem inherent to model - checking timed systems with a large number of components . The main challenge is to obtain pertinent global timing constraints from the timings in the components alone . To this end , we make use of auxiliary clocks to automatically generate new invariants which capture the constraints induced by the synchronisations between components . The method has been implemented in the RTD - Finder tool and successfully experimented on several benchmarks .
Multi - sorted logic , models and logical geometry
Let $ \Theta$ be a variety of algebras , $ ( H , \Psi , f)$ be a model , where $ H$ is an algebra from $ \Theta$ , $ \Psi$ is a set of relation symbols $ \varphi$ , $ f$ is an interpretation of all $ \varphi$ in $ H$. Let $ X^0 $ be an infinite set of variables , $ \Gamma$ be a collection of all finite subsets in $ X^0 $ ( collection of sorts ) , $ \widetilde\Phi$ be the multi - sorted algebra of formulas . These data define a knowledge base $ KB(H,\Psi , f)$. In the paper the notion of isomorphism of knowledge bases is considered . We give sufficient conditions which provide isomorphism of knowledge bases . We also study the problem of necessary and sufficient conditions for isomorphism of two knowledge bases .
On Selecting a Conjunction Operation in Probabilistic Soft Logic
Probabilistic Soft Logic has been proposed and used in several applications as an efficient way to deal with inconsistency , uncertainty and relational representation . In several applications , this approach has led to an adequate description of the corresponding human reasoning . In this paper , we provide a theoretical explanation for one of the semi - heuristic choices made in this approach : namely , we explain the choice of the corresponding conjunction operations . Our explanation leads to a more general family of operations which may be used in future applications of probabilistic soft logic .
Temporal Logics on Words with Multiple Data Values
The paper proposes and studies temporal logics for attributed words , that is , data words with a ( finite ) set of ( attribute , value)-pairs at each position . It considers a basic logic which is a semantical fragment of the logic $ LTL^\downarrow_1 $ of Demri and Lazic with operators for navigation into the future and the past . By reduction to the emptiness problem for data automata it is shown that this basic logic is decidable . Whereas the basic logic only allows navigation to positions where a fixed data value occurs , extensions are studied that also allow navigation to positions with different data values . Besides some undecidable results it is shown that the extension by a certain UNTIL - operator with an inequality target condition remains decidable .
From Total Assignment Enumeration to Modern SAT Solver
A new framework for presenting and analyzing the functionality of a modern DLL - based SAT solver is proposed . Our approach exploits the inherent relation between backtracking and resolution . We show how to derive the algorithm of a modern SAT solver from DLL step - by - step . We analyze the inference power of Boolean Constraint Propagation , Non - Chronological Backtracking and 1UIP - based Conflict - Directed Backjumping . Our work can serve as an introduction to a modern SAT solver functionality and as a basis for future work on the inference power of a modern SAT solver and on practical SAT solver design .
Computations by fly - automata beyond monadic second - order logic
We present logically based methods for constructing XP and FPT graph algorithms , parametrized by tree - width or clique - width . We will use fly - automata introduced in a previous article . They make possible to check properties that are not monadic second - order expressible because their states may include counters , so that their sets of states may be infinite . We equip these automata with output functions , so that they can compute values associated with terms or graphs . Rather than new algorithmic results we present tools for constructing easily certain dynamic programming algorithms by combining predefined automata for basic functions and properties .
Pervasive Parallelism in Highly - Trustable Interactive Theorem Proving Systems
This is an overview of the Paral - ITP project , which intents to make the proof assistants Isabelle and Coq fit for the multicore era .
Contract agreements via logic
We relate two contract models : one based on event structures and game theory , and the other one based on logic . In particular , we show that the notions of agreement and winning strategies in the game - theoretic model are related to that of provability in the logical model .
Adapting Real Quantifier Elimination Methods for Conflict Set Computation
The satisfiability problem in real closed fields is decidable . In the context of satisfiability modulo theories , the problem restricted to conjunctive sets of literals , that is , sets of polynomial constraints , is of particular importance . One of the central problems is the computation of good explanations of the unsatisfiability of such sets , i.e.\ obtaining a small subset of the input constraints whose conjunction is already unsatisfiable . We adapt two commonly used real quantifier elimination methods , cylindrical algebraic decomposition and virtual substitution , to provide such conflict sets and demonstrate the performance of our method in practice .
Full abstraction for probabilistic PCF
We present a probabilistic version of PCF , a well - known simply typed universal functional language . The type hierarchy is based on a single ground type of natural numbers . Even if the language is globally call - by - name , we allow a call - by - value evaluation for ground type arguments in order to provide the language with a suitable algorithmic expressiveness . We describe a denotational semantics based on probabilistic coherence spaces , a model of classical Linear Logic developed in previous works . We prove an adequacy and an equational full abstraction theorem showing that equality in the model coincides with a natural notion of observational equivalence .
Encoding ! -tensors as ! -graphs with neighbourhood orders
Diagrammatic reasoning using string diagrams provides an intuitive language for reasoning about morphisms in a symmetric monoidal category . To allow working with infinite families of string diagrams , ! -graphs were introduced as a method to mark repeated structure inside a diagram . This led to ! -graphs being implemented in the diagrammatic proof assistant Quantomatic . Having a partially automated program for rewriting diagrams has proven very useful , but being based on ! -graphs , only commutative theories are allowed . An enriched abstract tensor notation , called ! -tensors , has been used to formalise the notion of ! -boxes in non - commutative structures . This work - in - progress paper presents a method to encode ! -tensors as ! -graphs with some additional structure . This will allow us to leverage the existing code from Quantomatic and quickly provide various tools for non - commutative diagrammatic reasoning .
Quotient - Comprehension Chains
Quotients and comprehension are fundamental mathematical constructions that can be described via adjunctions in categorical logic . This paper reveals that quotients and comprehension are related to measurement , not only in quantum logic , but also in probabilistic and classical logic . This relation is presented by a long series of examples , some of them easy , and some also highly non - trivial ( esp . for von Neumann algebras ) . We have not yet identified a unifying theory . Nevertheless , the paper contributes towards such a theory by introducing the new quotient - and - comprehension perspective on measurement instruments , and by describing the examples on which such a theory should be built .
Equivalence Checking By Logic Relaxation
We introduce a new framework for Equivalence Checking ( EC ) of Boolean circuits based on a general technique called Logic Relaxation ( LoR ) . The essence of LoR is to relax the formula to be solved and compute a superset S of the set of new behaviors . Namely , S contains all new satisfying assignments that appeared due to relaxation and does not contain assignments satisfying the original formula . Set S is generated by a procedure called partial quantifier elimination . If all possible bad behaviors are in S , the original formula can not have them and so the property described by this formula holds . The appeal of EC by LoR is twofold . First , it facilitates generation of powerful inductive proofs . Second , proving inequivalence comes down to checking the presence of some bad behaviors in the relaxed formula i.e. in a simpler version of the original formula . We give some experimental evidence that supports our approach .
Parameterized Synthesis
We study the synthesis problem for distributed architectures with a parametric number of finite - state components . Parameterized specifications arise naturally in a synthesis setting , but thus far it was unclear how to detect realizability and how to perform synthesis in a parameterized setting . Using a classical result from verification , we show that for a class of specifications in indexed LTL\X , parameterized synthesis in token ring networks is equivalent to distributed synthesis in a network consisting of a few copies of a single process . Adapting a well - known result from distributed synthesis , we show that the latter problem is undecidable . We describe a semi - decision procedure for the parameterized synthesis problem in token rings , based on bounded synthesis . We extend the approach to parameterized synthesis in token - passing networks with arbitrary topologies , and show applicability on a simple case study . Finally , we sketch a general framework for parameterized synthesis based on cutoffs and other parameterized verification techniques .
Algorithmic Introduction of Quantified Cuts
We describe a method for inverting Gentzen 's cut - elimination in classical first - order logic . Our algorithm is based on first computign a compressed representation of the terms present in the cut - free proof and then cut - formulas that realize such a compression . Finally , a proof using these cut - formulas is constructed . This method allows an exponential compression of proof length . It can be applied to the output of automated theorem provers , which typically produce analytic proofs . An implementation is available on the web and described in this paper .
Analysis of Probabilistic Basic Parallel Processes
Basic Parallel Processes ( BPPs ) are a well - known subclass of Petri Nets . They are the simplest common model of concurrent programs that allows unbounded spawning of processes . In the probabilistic version of BPPs , every process generates other processes according to a probability distribution . We study the decidability and complexity of fundamental qualitative problems over probabilistic BPPs -- in particular reachability with probability 1 of different classes of target sets ( e.g. upward - closed sets ) . Our results concern both the Markov - chain model , where processes are scheduled randomly , and the MDP model , where processes are picked by a scheduler .
Weak MSO : Automata and Expressiveness Modulo Bisimilarity
We prove that the bisimulation - invariant fragment of weak monadic second - order logic ( WMSO ) is equivalent to the fragment of the modal $ \mu$-calculus where the application of the least fixpoint operator $ \mu p.\varphi$ is restricted to formulas $ \varphi$ that are continuous in $ p$. Our proof is automata - theoretic in nature ; in particular , we introduce a class of automata characterizing the expressive power of WMSO over tree models of arbitrary branching degree . The transition map of these automata is defined in terms of a logic $ \mathrm{FOE}_1^\infty$ that is the extension of first - order logic with a generalized quantifier $ \exists^\infty$ , where $ \exists^\infty x. \phi$ means that there are infinitely many objects satisfying $ \phi$. An important part of our work consists of a model - theoretic analysis of $ \mathrm{FOE}_1^\infty$.
On the Succinctness of Query Rewriting over OWL 2 QL Ontologies with Shallow Chases
We investigate the size of first - order rewritings of conjunctive queries over OWL 2 QL ontologies of depth 1 and 2 by means of hypergraph programs computing Boolean functions . Both positive and negative results are obtained . Conjunctive queries over ontologies of depth 1 have polynomial - size nonrecursive datalog rewritings ; tree - shaped queries have polynomial positive existential rewritings ; however , in the worst case , positive existential rewritings can only be of superpolynomial size . Positive existential and nonrecursive datalog rewritings of queries over ontologies of depth 2 suffer an exponential blowup in the worst case , while first - order rewritings are superpolynomial unless $ \text{NP } \subseteq \text{P}/\text{poly}$. We also analyse rewritings of tree - shaped queries over arbitrary ontologies and observe that the query entailment problem for such queries is fixed - parameter tractable .
What are the fundamental structures of concurrency ? We still do n't know !
Process algebra has been successful in many ways ; but we do n't yet see the lineaments of a fundamental theory . Some fleeting glimpses are sought from Petri Nets , physics and geometry .
Dialectica models of additive - free linear logic
This paper presents a construction which transforms categorical models of additive - free propositional linear logic , closely based on de Paiva 's dialectica categories and Oliva 's functional interpretations of classical linear logic . The construction is defined using dependent type theory , which proves to be a useful tool for reasoning about dialectica categories . Abstractly , we have a closure operator on the class of models : it preserves soundness and completeness and has a monad - like structure . When applied to categories of games we obtain ` games with bidding ' , which are hybrids of dialectica and game models , and we prove completeness theorems for two specific such models .
A Cut - Free ExpTime Tableau Decision Procedure for the Logic Extending Converse - PDL with Regular Inclusion Axioms
We give the first cut - free ExpTime ( optimal ) tableau decision procedure for the logic CPDLreg , which extends Converse - PDL with regular inclusion axioms characterized by finite automata . The logic CPDLreg is the combination of Converse - PDL and regular grammar logic with converse . Our tableau decision procedure uses global state caching and has been designed to increase efficiency and allow various optimization techniques , including on - the - fly propagation of local and global ( in)consistency .
Efficient Emptiness Check for Timed Buchi Automata ( Extended version )
The B\"uchi non - emptiness problem for timed automata refers to deciding if a given automaton has an infinite non - Zeno run satisfying the B\"uchi accepting condition . The standard solution to this problem involves adding an auxiliary clock to take care of the non - Zenoness . In this paper , it is shown that this simple transformation may sometimes result in an exponential blowup . A construction avoiding this blowup is proposed . It is also shown that in many cases , non - Zenoness can be ascertained without extra construction . An on - the - fly algorithm for the non - emptiness problem , using non - Zenoness construction only when required , is proposed . Experiments carried out with a prototype implementation of the algorithm are reported .
Resolution in Linguistic Propositional Logic based on Linear Symmetrical Hedge Algebra
The paper introduces a propositional linguistic logic that serves as the basis for automated uncertain reasoning with linguistic information . First , we build a linguistic logic system with truth value domain based on a linear symmetrical hedge algebra . Then , we consider G\"{o}del 's t - norm and t - conorm to define the logical connectives for our logic . Next , we present a resolution inference rule , in which two clauses having contradictory linguistic truth values can be resolved . We also give the concept of reliability in order to capture the approximative nature of the resolution inference rule . Finally , we propose a resolution procedure with the maximal reliability .
Interactive Logic Programming via Choice - Disjunctive Clauses
Adding interaction to logic programming is an essential task . Expressive logics such as linear logic provide a theoretical basis for such a mechanism . Unfortunately , none of the existing linear logic languages can model interactions with the user . This is because they uses provability as the sole basis for computation . We propose to use the game semantics instead of provability as the basis for computation to allow for more active participation from the user . We illustrate our idea via muprolog , an extension of Prolog with choice - disjunctive clauses .
Adding Priority to Event Structures
Event Structures ( ESs ) are mainly concerned with the representation of causal relationships between events , usually accompanied by other event relations capturing conflicts and disabling . Among the most prominent variants of ESs are Prime ESs , Bundle ESs , Stable ESs , and Dual ESs , which differ in their causality models and event relations . Yet , some application domains require further kinds of relations between events . Here , we add the possibility to express priority relationships among events . We exemplify our approach on Prime , Bundle , Extended Bundle , and Dual ESs . Technically , we enhance these variants in the same way . For each variant , we then study the interference between priority and the other event relations . From this , we extract the redundant priority pairs - notably differing for the types of ESs - that enable us to provide a comparison between the extensions . We also exhibit that priority considerably complicates the definition of partial orders in ESs .
Towards Meta - Reasoning in the Concurrent Logical Framework CLF
The concurrent logical framework CLF is an extension of the logical framework LF designed to specify concurrent and distributed languages . While it can be used to define a variety of formalisms , reasoning about such languages within CLF has proved elusive . In this paper , we propose an extension of LF that allows us to express properties of CLF specifications . We illustrate the approach with a proof of safety for a small language with a parallel semantics .
Formal Analysis of Soft Errors using Theorem Proving
Modeling and analysis of soft errors in electronic circuits has traditionally been done using computer simulations . Computer simulations can not guarantee correctness of analysis because they utilize approximate real number representations and pseudo random numbers in the analysis and thus are not well suited for analyzing safety - critical applications . In this paper , we present a higher - order logic theorem proving based method for modeling and analysis of soft errors in electronic circuits . Our developed infrastructure includes formalized continuous random variable pairs , their Cumulative Distribution Function ( CDF ) properties and independent standard uniform and Gaussian random variables . We illustrate the usefulness of our approach by modeling and analyzing soft errors in commonly used dynamic random access memory sense amplifier circuits .
Bounding normalization time through intersection types
Non - idempotent intersection types are used in order to give a bound of the length of the normalization beta - reduction sequence of a lambda term : namely , the bound is expressed as a function of the size of the term .
From formal proofs to mathematical proofs : a safe , incremental way for building in first - order decision procedures
We investigate here a new version of the Calculus of Inductive Constructions ( CIC ) on which the proof assistant Coq is based : the Calculus of Congruent Inductive Constructions , which truly extends CIC by building in arbitrary first - order decision procedures : deduction is still in charge of the CIC kernel , while computation is outsourced to dedicated first - order decision procedures that can be taken from the shelves provided they deliver a proof certificate . The soundness of the whole system becomes an incremental property following from the soundness of the certificate checkers and that of the kernel . A detailed example shows that the resulting style of proofs becomes closer to that of the working mathematician .
Practical Automated Partial Verification of Multi - Paradigm Real - Time Models
This article introduces a fully automated verification technique that permits to analyze real - time systems described using a continuous notion of time and a mixture of operational ( i.e. , automata - based ) and descriptive ( i.e. , logic - based ) formalisms . The technique relies on the reduction , under reasonable assumptions , of the continuous - time verification problem to its discrete - time counterpart . This reconciles in a viable and effective way the dense / discrete and operational / descriptive dichotomies that are often encountered in practice when it comes to specifying and analyzing complex critical systems . The article investigates the applicability of the technique through a significant example centered on a communication protocol . More precisely , concurrent runs of the protocol are formalized by parallel instances of a Timed Automaton , while the synchronization rules between these instances are specified through Metric Temporal Logic formulas , thus creating a multi - paradigm model . Verification tests run on this model using a bounded validity checker implementing the technique show consistent results and interesting performances .
An Embedding of the BSS Model of Computation in Light Affine Lambda - Calculus
This paper brings together two lines of research : implicit characterization of complexity classes by Linear Logic ( LL ) on the one hand , and computation over an arbitrary ring in the Blum - Shub - Smale ( BSS ) model on the other . Given a fixed ring structure K we define an extension of Terui 's light affine lambda - calculus typed in LAL ( Light Affine Logic ) with a basic type for K. We show that this calculus captures the polynomial time function class FP(K ) : every typed term can be evaluated in polynomial time and conversely every polynomial time BSS machine over K can be simulated in this calculus .
Calculating modules in contextual logic program refinement
The refinement calculus for logic programs is a framework for deriving logic programs from specifications . It is based on a wide - spectrum language that can express both specifications and code , and a refinement relation that models the notion of correct implementation . In this paper we extend and generalise earlier work on contextual refinement . Contextual refinement simplifies the refinement process by abstractly capturing the context of a subcomponent of a program , which typically includes information about the values of the free variables . This paper also extends and generalises module refinement . A module is a collection of procedures that operate on a common data type ; module refinement between a specification module A and an implementation module C allows calls to the procedures of A to be systematically replaced with calls to the corresponding procedures of C. Based on the conditions for module refinement , we present a method for calculating an implementation module from a specification module . Both contextual and module refinement within the refinement calculus have been generalised from earlier work and the results are presented in a unified framework .
Two Lower Bounds for BPA
Branching bisimilarity on normed Basic Process Algebra ( BPA ) was claimed to be EXPTIME - hard in previous papers without any explicit proof . Recently it is reminded by Jan\v{c}ar that the claim is not so dependable . In this paper , we develop a new complete proof for EXPTIME - hardness of branching bisimilarity on normed BPA . We also prove the associate regularity problem on normed BPA is PSPACE - hard and in EXPTIME . This improves previous P - hard and NEXPTIME result .
